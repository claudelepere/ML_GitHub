{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2fb48ca394c34676b3dd443355347713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cba1d8d459094c7eb45bfabde4526699",
              "IPY_MODEL_fc2097dbd31e4064a14e08553ce119df",
              "IPY_MODEL_6757b8243357457a8678769325afa3eb"
            ],
            "layout": "IPY_MODEL_33951ac34125485391656aa3aa3b0a81"
          }
        },
        "cba1d8d459094c7eb45bfabde4526699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b927a0581db54bffb0a2b8222defd26c",
            "placeholder": "​",
            "style": "IPY_MODEL_471955d2fc5943e98bc070c201a2bf87",
            "value": "Map: 100%"
          }
        },
        "fc2097dbd31e4064a14e08553ce119df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f36d0b834011426eb89ff7485e80b6a2",
            "max": 128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28fe5ede408e4afa90e7d95e43f33246",
            "value": 128
          }
        },
        "6757b8243357457a8678769325afa3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f6c4f665724404bdc979ec70e6721c",
            "placeholder": "​",
            "style": "IPY_MODEL_2ee4fd72276d4a21b16e75ea5d821696",
            "value": " 128/128 [00:00&lt;00:00, 317.90 examples/s]"
          }
        },
        "33951ac34125485391656aa3aa3b0a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b927a0581db54bffb0a2b8222defd26c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471955d2fc5943e98bc070c201a2bf87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f36d0b834011426eb89ff7485e80b6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28fe5ede408e4afa90e7d95e43f33246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30f6c4f665724404bdc979ec70e6721c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee4fd72276d4a21b16e75ea5d821696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f5f2acc05ef41c6a1bc8fe3f22ed3b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_53e449b02baf4762b0d5298cab8c7fdc",
              "IPY_MODEL_aa6d6e61a77543d595142472cb0343a2",
              "IPY_MODEL_6303670c5d4f407c8b0c48e8eb5c89c0"
            ],
            "layout": "IPY_MODEL_44393a2cafdd4451828ad70820f5a058"
          }
        },
        "53e449b02baf4762b0d5298cab8c7fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c9035dc122c4bd184a3afa94a6b8cd0",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d0e47eb670425dbd9c8650bdec8da5",
            "value": "Map: 100%"
          }
        },
        "aa6d6e61a77543d595142472cb0343a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17cfd3a30cd44e1f8f91b83ee37d2d3d",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d4e76edf624467e98ea14e59ea33d2c",
            "value": 18
          }
        },
        "6303670c5d4f407c8b0c48e8eb5c89c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125d81ae6c4a4c8a8485b4348488a082",
            "placeholder": "​",
            "style": "IPY_MODEL_1d636cafa5a24f29aa7e942988ef91c7",
            "value": " 18/18 [00:00&lt;00:00, 123.72 examples/s]"
          }
        },
        "44393a2cafdd4451828ad70820f5a058": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9035dc122c4bd184a3afa94a6b8cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d0e47eb670425dbd9c8650bdec8da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17cfd3a30cd44e1f8f91b83ee37d2d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d4e76edf624467e98ea14e59ea33d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "125d81ae6c4a4c8a8485b4348488a082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d636cafa5a24f29aa7e942988ef91c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bab633c625f64facac0aca495756dadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_259f441e65994390b83366d372eda013",
              "IPY_MODEL_4f92b0e235e344e8b9d1286b0dff01bf",
              "IPY_MODEL_9e56cbbaff2f4d64bd893941c51ba9f2"
            ],
            "layout": "IPY_MODEL_c8e9706de0df4ad7b78922f4130ca161"
          }
        },
        "259f441e65994390b83366d372eda013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8f693f336e040df86dcdb8daf600aeb",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4213843cd441b18851a3cb16a1bea0",
            "value": "Map: 100%"
          }
        },
        "4f92b0e235e344e8b9d1286b0dff01bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a202da50f64b0bbb72cb8e55db87e3",
            "max": 54,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09e1c74352d1409b99f9b5b452f86445",
            "value": 54
          }
        },
        "9e56cbbaff2f4d64bd893941c51ba9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a076dd57b34406a88e2185d7c5edde1",
            "placeholder": "​",
            "style": "IPY_MODEL_867e207447e14a70bf0b7c25452bf778",
            "value": " 54/54 [00:00&lt;00:00, 119.73 examples/s]"
          }
        },
        "c8e9706de0df4ad7b78922f4130ca161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8f693f336e040df86dcdb8daf600aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4213843cd441b18851a3cb16a1bea0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2a202da50f64b0bbb72cb8e55db87e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09e1c74352d1409b99f9b5b452f86445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a076dd57b34406a88e2185d7c5edde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867e207447e14a70bf0b7c25452bf778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudelepere/ML_GitHub/blob/main/Copy_of_Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLB3I4FKZ5Lr"
      },
      "source": [
        "# Fine-tuning BERT (and friends) for multi-label text classification\n",
        "\n",
        "In this notebook, we are going to fine-tune BERT to predict one or more labels for a given piece of text. Note that this notebook illustrates how to fine-tune a bert-base-uncased model, but you can also fine-tune a RoBERTa, DeBERTa, DistilBERT, CANINE, ... checkpoint in the same way.\n",
        "\n",
        "All of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n",
        "\n",
        "\n",
        "\n",
        "## Set-up environment\n",
        "\n",
        "First, we install the libraries which we'll use: HuggingFace Transformers and Datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIH9NP0MZ6-O"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "Next, let's download a multi-label text classification dataset from the [hub](https://huggingface.co/).\n",
        "\n",
        "At the time of writing, I picked a random one as follows:   \n",
        "\n",
        "* first, go to the \"datasets\" tab on huggingface.co\n",
        "* next, select the \"multi-label-classification\" tag on the left as well as the the \"1k<10k\" tag (fo find a relatively small dataset).\n",
        "\n",
        "Note that you can also easily load your local data (i.e. csv files, txt files, Parquet files, JSON, ...) as explained [here](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "HF_TOKEN = getpass(\"Enter your Hugging Face token: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dTfRJv_4EmP",
        "outputId": "f1431c34-8009-42e8-9c00-0bb4c5909bd4"
      },
      "execution_count": 104,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=HF_TOKEN, add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmXDZX9A4lZh",
        "outputId": "dddf736a-1362-4ca5-e724-a10aaa7899e4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd1LiXGjZ420",
        "outputId": "795cbb04-0bd7-4ed1-efa0-f9a1406c15f3"
      },
      "source": [
        "import os, sys, shutil\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "current_dir = os.getcwd()\n",
        "print(f\"The current directory is {current_dir}\")\n",
        "\n",
        "if os.path.isdir('ML_GitHub'):\n",
        "    shutil.rmtree('ML_GitHub')\n",
        "\n",
        "!git init\n",
        "!git branch -m main\n",
        "!git clone https://github.com/claudelepere/ML_GitHub.git\n",
        "print(f\"list /content: {os.listdir(current_dir)}\")\n",
        "print(f\"list /content/ML_GitHub: {os.listdir(current_dir + '/ML_GitHub')}\")\n",
        "!ls -la /content/ML_GitHub/datasetHF\n",
        "os.chdir(current_dir + '/ML_GitHub')\n",
        "\n",
        "#!pip install fsspec==2024.10.0\n",
        "!pip install -q transformers datasets\n",
        "from datasets import DatasetDict\n",
        "\n",
        "dataset = DatasetDict.load_from_disk('datasetHF')\n",
        "print(f\"dataset: {type(dataset)} {dataset.shape}\\n{dataset}\")"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current directory is /content\n",
            "Reinitialized existing Git repository in /content/.git/\n",
            "Cloning into 'ML_GitHub'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 62 (delta 27), reused 50 (delta 22), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (62/62), 9.97 MiB | 13.21 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "list /content: ['.config', 'ML_GitHub', '.git', 'sample_data']\n",
            "list /content/ML_GitHub: ['README.md', 'Copy_of_Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb', 'datasetHF', '.git']\n",
            "total 24\n",
            "drwxr-xr-x 5 root root 4096 Nov  6 12:43 .\n",
            "drwxr-xr-x 4 root root 4096 Nov  6 12:43 ..\n",
            "-rw-r--r-- 1 root root   43 Nov  6 12:43 dataset_dict.json\n",
            "drwxr-xr-x 2 root root 4096 Nov  6 12:43 test\n",
            "drwxr-xr-x 2 root root 4096 Nov  6 12:43 train\n",
            "drwxr-xr-x 2 root root 4096 Nov  6 12:43 validation\n",
            "dataset: <class 'datasets.dataset_dict.DatasetDict'> {'train': (128, 44), 'validation': (18, 44), 'test': (54, 44)}\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', '394', '142', '146', '147', '148', '149', '150', '151', '408', '409', '153', '154', '155', '156', '157', '158', '160', '152', '162', '165', '167', '168', '169', '170', '171', '685', '174', '686', '176', '689', '173', '356', '360', '361', '362', '364', '760', '756', '758', '375', '376', '761'],\n",
            "        num_rows: 128\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'text', '394', '142', '146', '147', '148', '149', '150', '151', '408', '409', '153', '154', '155', '156', '157', '158', '160', '152', '162', '165', '167', '168', '169', '170', '171', '685', '174', '686', '176', '689', '173', '356', '360', '361', '362', '364', '760', '756', '758', '375', '376', '761'],\n",
            "        num_rows: 18\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'text', '394', '142', '146', '147', '148', '149', '150', '151', '408', '409', '153', '154', '155', '156', '157', '158', '160', '152', '162', '165', '167', '168', '169', '170', '171', '685', '174', '686', '176', '689', '173', '356', '360', '361', '362', '364', '760', '756', '758', '375', '376', '761'],\n",
            "        num_rows: 54\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCL02vQgxYTO"
      },
      "source": [
        "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgS0wMWExcqP"
      },
      "source": [
        "Let's check the first example of the training split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unjuTtKUjZI3",
        "outputId": "380c3b6e-71e8-41cf-94b9-d30aa2c3e592"
      },
      "source": [
        "example = dataset['validation'][0]\n",
        "example"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 141545,\n",
              " 'text': 'Actiris - Scrum Master / Gestionnaire de Projets Scrum Master, Chef de Projets, .NET Actiris Le service développement d\\'Actiris est composé d\\'une trentaine de personnes qui travaillent essentiellement sur des projets nouveaux (dossier unique, plateforme pour la gestion des relations entre Actiris et les partenaires, plateforme pour la gestion des relations entre Actiris et les employeurs, mise en place d\\'un nouveau CRM, etc.). Votre rôle En tant que Scrum Master/gestionnaire de projets, vous initiez et coordonnez, dans un environnement Agile, des projets dans le cadre du développement de nos nouvelles plateformes core business et vous veillez à leur bonne réalisation dans les délais impartis. Vos responsabilités Vous collectez les informations nécessaires au bon déroulement du projet et êtes capable de discuter d\\'un backlog avec le métier ; Vous déterminez les étapes clés, planning et rétro-planning Highlevel sans forcément de requête auprès de l\\'équipe de développement ; Vous mettez en place un cadre collaboratif avec les acteurs concernés et assurez une communication régulière et constructive ; Vous communiquez régulièrement un feedback sur l\\'avancée du projet aux interlocuteurs concernés ; Vous êtes garant de la qualité du projet en utilisant ou en élaborant les outils nécessaires à son suivi et à son évaluation ; Vous animez et participez à des réunions, sprint planning et sprint review ; Vous vous tenez informé sur les sujets en lien avec le projet; Vous veillez à la progression du projet en effectuant les adaptations nécessaires, notamment en fonction des évolutions technologiques ; Vous rédigez les notes et rapports requis en adaptant le contenu et la technicité en fonction des destinataires. Vous développez des liaisons techniques et fonctionnelles avec l\\'environnement de travail ; Vous respectez les règles fournies par l\\'architecte ainsi que l\\'ensemble des contraintes de tous les services de l\\'informatique. Votre profil Vous êtes titulaire d\\'un diplôme de Master et avez minimum 2 ans d\\'expérience en tant que gestionnaire de projets informatiques et/ou Scrum Master. Vous vous reconnaissez dans le profil suivant : Excellent communicateur, vous vous exprimez aussi bien à l\\'oral qu\\'à l\\'écrit ; Orienté résultats, vous mettez tout en œuvre pour mener vos projets à bien et atteindre les objectifs ; Vous disposez d\\'un très bon esprit de collaboration ; Vous faites face aux imprévus et effectuez les changements nécessaires pour vous y adapter ; Vous gérez votre planning de manière efficace en tenant compte des impératifs de temps et des priorités. Compétences techniques : Connaissances des principaux langages de développement: Web : HTML, JavaScript, CSS, ASP.NET C#, Angular, ... Base de données : Oracle, SQL Server, ... Connaissance d\\'un ensemble de solutions applicatives : ERP, CRM, EAI,... Vous êtes capable de lire une analyse au format UML ; La maîtrise d\\'Azure DevOps est un atout ; Une connaissance de la seconde langue nationale et/ou de l\\'anglais est un atout. Pourquoi rejoindre Actiris? Nos collaborateurs reflètent la population de Bruxelles : la diversité au travail n\\'est pas seulement un de nos objectifs, c\\'est aussi notre réalité quotidienne. Dans un esprit de cohérence avec nos valeurs, nous accordons de l\\'importance à l\\'équilibre entre la vie privée, la vie professionnelle et le bien-être de nos collaborateurs. En tant qu\\'employeur : Nous veillons à l\\'équilibre optimal entre votre vie professionnelle et votre vie privée grâce aux 35 jours de congés annuels, à des horaires flexibles et la possibilité de travailler de la maison. Nous assurons votre développement personnel et professionnel en proposant 11 jours de formation par an, en lien avec votre métier, vos besoins et votre ambition. Nous sommes soucieux de l\\'environnement et d\\'une société durable, ainsi, vous pouvez facilement venir en bus, tram, train ou vélo au travail. Nous vous offrons un abonnement gratuit Villo, STIB, TEC, De Lijn, SNCB, une indemnité vélo et vous pouvez emprunter des vélos électriques sur votre lieu de travail. Nous vous proposons un cadre agréable et stimulant : un restaurant d\\'entreprise avec des menus diversifiés pour tous les goûts et tous les budgets, une salle de sport où sont donnés des cours de yoga, pilates, zumba ou d\\'autres activités en fonction du moment. Nous nous préoccupons de votre santé en organisant des dépistages et en proposant une intervention dans certains frais médicaux et paramédicaux, ainsi qu\\'une assurance hospitalisation et soins dentaires. Nous offrons également des avantages pour les enfants, nous organisons des initiatives visant l\\'économie de partage (bibliothèque, prêt de matériel divers), des activités culturelles à prix réduits, etc. Contrat et avantages Un contrat CDI temps plein Un salaire mensuel brut de 4715.59 pour 2 années d\\'ancienneté avec la possibilité de reconnaître des années d\\'expérience supplémentaires dès l\\'entrée en fonction Des chèques repas de 8€ La possibilité d\\'une prime linguistique allant de 340 à 450€ mensuels bruts Intéressé.e? Postulez maintenant! Cliquez sur le bouton \"postuler\" en lien avec cette offre d\\'emploi. Assurez-vous de joindre votre CV et lettre de motivation, ainsi que d\\'autres documents si vous le souhaitez. Votre candidature sera lue avec la plus grande attention et nous vous informerons de la suite qui lui sera donnée. Si elle est retenue nous vous inviterons à une présélection (entretien et/ou test). Les meilleurs candidats seront ensuite amenés à présenter une épreuve de jury. Actiris: du travail pour tous ! Nous sélectionnons nos collaborateurs sur base de leurs compétences. Nous ne faisons pas de distinction d\\'âge, d\\'orientation sexuelle, de couleur de peau, de croyance, de handicap, de conviction philosophique ou de nationalité. Vous êtes en situation de handicap ? Mentionnez-le lors de votre candidature ! Nous proposons d\\'éventuelles adaptations afin que vous puissiez facilement participer à la procédure de recrutement et travailler confortablement au sein de notre organisation. Documents Au fil de la procédure, les documents suivants devront impérativement être fournis Copie de votre diplôme. Vous avez obtenu votre diplôme dans un pays hors Benelux ? Joignez-y alors l\\'équivalence officielle. Extrait récent de casier judiciaire. Attestation d\\'expérience antérieure pour la valorisation d\\'expérience acquise.',\n",
              " '394': False,\n",
              " '142': False,\n",
              " '146': False,\n",
              " '147': False,\n",
              " '148': False,\n",
              " '149': False,\n",
              " '150': False,\n",
              " '151': False,\n",
              " '408': False,\n",
              " '409': False,\n",
              " '153': False,\n",
              " '154': False,\n",
              " '155': False,\n",
              " '156': False,\n",
              " '157': False,\n",
              " '158': False,\n",
              " '160': False,\n",
              " '152': False,\n",
              " '162': False,\n",
              " '165': False,\n",
              " '167': False,\n",
              " '168': False,\n",
              " '169': True,\n",
              " '170': True,\n",
              " '171': False,\n",
              " '685': False,\n",
              " '174': False,\n",
              " '686': False,\n",
              " '176': False,\n",
              " '689': False,\n",
              " '173': False,\n",
              " '356': False,\n",
              " '360': False,\n",
              " '361': False,\n",
              " '362': False,\n",
              " '364': False,\n",
              " '760': False,\n",
              " '756': False,\n",
              " '758': False,\n",
              " '375': True,\n",
              " '376': False,\n",
              " '761': False}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DV0Rtetxgd4"
      },
      "source": [
        "The dataset consists of texts, labeled with one or more skills.\n",
        "\n",
        "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5vZhQpvkE8s",
        "outputId": "e688496d-ac0a-46fa-9505-cc9516296ef0"
      },
      "source": [
        "labels = [label for label in dataset['train'].features.keys() if label not in ['id', 'text']]\n",
        "print(len(labels), list(enumerate(labels)))\n",
        "id2label = {idx:label for idx, label in enumerate(labels)}\n",
        "print(id2label)\n",
        "label2id = {label:idx for idx, label in enumerate(labels)}\n",
        "labels.sort()\n",
        "print(len(labels), labels)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 [(0, '394'), (1, '142'), (2, '146'), (3, '147'), (4, '148'), (5, '149'), (6, '150'), (7, '151'), (8, '408'), (9, '409'), (10, '153'), (11, '154'), (12, '155'), (13, '156'), (14, '157'), (15, '158'), (16, '160'), (17, '152'), (18, '162'), (19, '165'), (20, '167'), (21, '168'), (22, '169'), (23, '170'), (24, '171'), (25, '685'), (26, '174'), (27, '686'), (28, '176'), (29, '689'), (30, '173'), (31, '356'), (32, '360'), (33, '361'), (34, '362'), (35, '364'), (36, '760'), (37, '756'), (38, '758'), (39, '375'), (40, '376'), (41, '761')]\n",
            "{0: '394', 1: '142', 2: '146', 3: '147', 4: '148', 5: '149', 6: '150', 7: '151', 8: '408', 9: '409', 10: '153', 11: '154', 12: '155', 13: '156', 14: '157', 15: '158', 16: '160', 17: '152', 18: '162', 19: '165', 20: '167', 21: '168', 22: '169', 23: '170', 24: '171', 25: '685', 26: '174', 27: '686', 28: '176', 29: '689', 30: '173', 31: '356', 32: '360', 33: '361', 34: '362', 35: '364', 36: '760', 37: '756', 38: '758', 39: '375', 40: '376', 41: '761'}\n",
            "42 ['142', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '160', '162', '165', '167', '168', '169', '170', '171', '173', '174', '176', '356', '360', '361', '362', '364', '375', '376', '394', '408', '409', '685', '686', '689', '756', '758', '760', '761']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3Teyjmank2"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
        "\n",
        "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFWlSsbZaRLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba28894-1ecd-4d67-fdbd-fc6c7e1e42fc"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# examples and not example because batched=True => examples is a batch\n",
        "def preprocess_data(examples, indices):\n",
        "  # take a batch of texts\n",
        "  text = examples[\"text\"]\n",
        "  print(\"Indices:\", indices, \"Batch size:\", len(text), \"Num labels:\", len(labels))\n",
        "\n",
        "  # encode them\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=1024)\n",
        "\n",
        "  labels_batch = {label: np.zeros(len(text)) for label in labels}\n",
        "  # examples.keys(): all the column names (keys) in the batch dict \"examples\"\n",
        "  # for each k in labels, a new key-value pair k: examples[k] is added to labels_batch\n",
        "  labels_batch.update({k: examples[k] for k in examples.keys() if k in labels})\n",
        "\n",
        "  #print(f\"labels_batch: {type(labels_batch)} {len(labels_batch)} {labels_batch}\")\n",
        "  # create numpy array of shape (batch_size, num_labels)\n",
        "  labels_matrix = np.zeros((len(text), len(labels)))\n",
        "  # fill numpy array\n",
        "  for idx, label in enumerate(labels):\n",
        "    #print(\"idx=\", idx, label)\n",
        "    labels_matrix[:, idx] = labels_batch[label] # sets the idx-th column of labels_matrix with the values from labels_batch[label]\n",
        "\n",
        "  print(\"First row of labels_matrix:\", labels_matrix[0])\n",
        "\n",
        "  # Add labels to encoding\n",
        "  encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "  return encoding\n",
        "\n",
        "def preprocess_data_ONE(example):\n",
        "  # take a batch of texts\n",
        "  text = example[\"text\"]\n",
        "\n",
        "  # encode them\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=1024)\n",
        "  #print(encoding)\n",
        "\n",
        "  # add labels\n",
        "  labels_batch = {k: example[k] for k in example.keys() if k in labels} # examples.keys(): all the column names (keys) in the batch dict \"examples\"\n",
        "                                                                            # for each k in labels, a new key-value pair k: examples[k] is added to labels_batch\n",
        "  print(labels_batch)\n",
        "  # create numpy array of shape (batch_size, num_labels)\n",
        "  labels_matrix = np.zeros((len(text), len(labels)))\n",
        "  #print(labels_matrix.shape)\n",
        "  # fill numpy array\n",
        "  for idx, label in enumerate(labels):\n",
        "    labels_matrix[:, idx] = labels_batch[label]\n",
        "\n",
        "  #encoding[\"labels\"] = labels_matrix.tolist()\n",
        "\n",
        "  return encoding"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset.map(preprocess_data_ONE, batched=False)"
      ],
      "metadata": {
        "id": "_ARt9V7YePdE"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "2fb48ca394c34676b3dd443355347713",
            "cba1d8d459094c7eb45bfabde4526699",
            "fc2097dbd31e4064a14e08553ce119df",
            "6757b8243357457a8678769325afa3eb",
            "33951ac34125485391656aa3aa3b0a81",
            "b927a0581db54bffb0a2b8222defd26c",
            "471955d2fc5943e98bc070c201a2bf87",
            "f36d0b834011426eb89ff7485e80b6a2",
            "28fe5ede408e4afa90e7d95e43f33246",
            "30f6c4f665724404bdc979ec70e6721c",
            "2ee4fd72276d4a21b16e75ea5d821696",
            "8f5f2acc05ef41c6a1bc8fe3f22ed3b5",
            "53e449b02baf4762b0d5298cab8c7fdc",
            "aa6d6e61a77543d595142472cb0343a2",
            "6303670c5d4f407c8b0c48e8eb5c89c0",
            "44393a2cafdd4451828ad70820f5a058",
            "9c9035dc122c4bd184a3afa94a6b8cd0",
            "e9d0e47eb670425dbd9c8650bdec8da5",
            "17cfd3a30cd44e1f8f91b83ee37d2d3d",
            "8d4e76edf624467e98ea14e59ea33d2c",
            "125d81ae6c4a4c8a8485b4348488a082",
            "1d636cafa5a24f29aa7e942988ef91c7",
            "bab633c625f64facac0aca495756dadd",
            "259f441e65994390b83366d372eda013",
            "4f92b0e235e344e8b9d1286b0dff01bf",
            "9e56cbbaff2f4d64bd893941c51ba9f2",
            "c8e9706de0df4ad7b78922f4130ca161",
            "e8f693f336e040df86dcdb8daf600aeb",
            "8a4213843cd441b18851a3cb16a1bea0",
            "f2a202da50f64b0bbb72cb8e55db87e3",
            "09e1c74352d1409b99f9b5b452f86445",
            "6a076dd57b34406a88e2185d7c5edde1",
            "867e207447e14a70bf0b7c25452bf778"
          ]
        },
        "id": "i4ENBTdulBEI",
        "outputId": "a77ebbec-43e1-404e-905f-bbce02384e1c"
      },
      "source": [
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names, with_indices=True)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/128 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fb48ca394c34676b3dd443355347713"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127] Batch size: 128 Num labels: 42\n",
            "First row of labels_matrix: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/18 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f5f2acc05ef41c6a1bc8fe3f22ed3b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17] Batch size: 18 Num labels: 42\n",
            "First row of labels_matrix: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/54 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bab633c625f64facac0aca495756dadd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53] Batch size: 54 Num labels: 42\n",
            "First row of labels_matrix: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"encoded_dataset['train']: {type(encoded_dataset['train'])} {encoded_dataset['train'].shape}\")\n",
        "idx_list_14=[]\n",
        "idx_list_16=[]\n",
        "for i, row in enumerate(encoded_dataset['train']['labels']):\n",
        "  if (row[14] == 1.0 and sum(row)<2.0):\n",
        "    idx_list_14.append(i)\n",
        "    print(f\"Row {i}: {row}\")\n",
        "  if (row[16] == 1.0 and sum(row)<2.0):\n",
        "    idx_list_16.append(i)\n",
        "    print(f\"Row {i}: {row}\")\n",
        "print(f\"idx_list_14: {idx_list_14}\")\n",
        "print(f\"idx_list_16: {idx_list_16}\")\n",
        "\n",
        "example = encoded_dataset['train'][0]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "example = encoded_dataset['train'][44]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "example = encoded_dataset['train'][65]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "example = encoded_dataset['train'][66]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "example = encoded_dataset['train'][93]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "example = encoded_dataset['train'][100]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "print()\n",
        "example = encoded_dataset['train'][47]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n",
        "example = encoded_dataset['train'][90]\n",
        "print(tokenizer.decode(example['input_ids']))\n",
        "print(example['labels'])\n"
      ],
      "metadata": {
        "id": "lREx-4ZEOGQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69cf7a1-15a0-4d7d-ae45-0168c419a2a6"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoded_dataset['train']: <class 'datasets.arrow_dataset.Dataset'> (128, 4)\n",
            "Row 0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 44: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 47: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 65: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 66: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 90: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 93: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Row 100: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "idx_list_14: [0, 44, 65, 66, 93, 100]\n",
            "idx_list_16: [47, 90]\n",
            "[CLS] inetum - realdolmen - azure cloud engineer azure cloud inetum - realdolmen your function to support the exponential growth of our azure practice, we are looking for several azure cloud engineers. here's how you'll make impact : for larger projects you work in team with other azure cloud engineers, cloud solution architects and project managers to write a new success story. we can count on you for the professional implementation of the tasks entrusted to you. for smaller cloud projects you are in charge for the full engagement : you advise your client from the design until his solution is fully operational. in addition to consultancy, you also offer third - line support to customers and colleagues. automation is in your genes. you always strive to make your life and that of the operation engineers easier by automating everything. infrastructure - as - code does not sound weird to you. you test thoroughly, and you don't compromise on quality. you adhere to realdolmens best practices and play an active role in the continuous improvement by making suggestions and modifications based on your daily hands - on experience. you will be involved during pocs, pilots and proactive services inetum - realdolmen offers as a cloud managed services provider ( msp ), such a cost optimization, lifecycle management, architecture optimization,... you keep your work well - documented, clear and to the point. your profile you are experienced in azure as a system engineer you have a pretty good understanding of the azure infrastructure - as - a - service platform and can assess the added value of iaas components for clients'respective situations. you are eager to learn and ambitious. you also invest your own time in keeping your competencies up - to - date. you are a real team player, but you also get on just fine on your own. you are socially skilled and always willing to share knowledge with colleagues. you are flexible and resistant to stress. you work accurately and on a project basis, and you are not prepared to make compromises when it comes to quality. you speak fluently dutch and english or french and english. if that's you, come in and have a talk with us! our offer the opportunity to have a meaningful job where you can make a difference ; the chance to continuously evolve as a professional, coupled with a variety of training opportunities ; inetum - realdolmen wants you to find a balance between work and private life by offering flexible hours, satellite offices and home working ; 32 days of annual leave, because life isn't all about working ; forget about the miles : we provide you with a company car and a national fuel card ; group insurance and hospitalization insurance, because we care about you ; and of course, we also offer a gross salary. one which is optimized from a net perspective for our employees! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[CLS] bnp paribas fortis - linux system engineer linux network access bnp paribas fortis want to work with us to help the shift towards a more sustainable world? the bnp paribas fortis it department is currently working in agile mode, which offers a challenging and motivating environment where teams and employees are empowered to manage their own technical domain. you will work in the infrastructure & collaboration services tribe which is in it infrastructure the interface between business plus the rest of it and our datacenter service provider bp2i. do think you can live with the stress of this highly responsible job? do want to stay up - to - date and learn more on how you can protect the bank? do you like to work in a collaborating ( agile ) way? do you want to have fun by doing your job? if you have answered 3 time “ yes ” then it's time for you to consider the following challenge. your job our main partner bp2i is responsible for the engineering and operations of the system layer of the linux platform, for both physical, virtual and on - premises cloud infrastructure. in your role you will integrate the group services at bnppf, i. e. identify possible gaps between the group services offered and the actual needs of bnppf. ddesign and implement a solution to bridge the gap, and this for both infrastructure and applicative requirements. in this role your main responsibilities will be : assist and support our it clients to integrate their applications on the linux platforms by respecting and applying the bnpp fortis engineering and architecture rules and procedures and align these to the bp2i engineering and process rules. assure the correct application of the bnpp fortis and bp2i procedures in demand -, incident -, problem -, change -, security - and release management work with our stakeholders and infra - teams to understand their needs, priorities and constraints in terms of server and application delivery discuss the automation possibilities with the various group partners, negotiate with them what automation services can be available for bnppf support the existing linux & unix platforms & systems support the evolution to the cloud systems of our linux infra highlight your strengths the ideal candidate has following strengths : bachelor / master in it or equivalent by experience good knowledge of english is a must. good knowledge of dutch or / and french is a plus. mandatory : proven rhel application integration experience in a large enterprise it environment proven experience with shell scripting practical automation experience in ansible tower ldap itil preferable : practical automation experience in terraform or equivalent in a changing world, diversity and inclusion are core values for well - being and team performance. at bnp paribas fortis, we want to attract and retain all talent, whatever their gender, age, background or sexual orientation, and irrespective of whether they are living with a disability, as every person has their own experiences and their own identity. together, let's build the innovative, responsible and sustainable bank of tomorrow. all of our full - time vacancies are also open to candidates wishing to work on an 80 % or 90 % full - time equivalent basis. tempted by the challenge? interested in this role? apply online. you will hear back from us as soon as possible. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[CLS] cheops - system engineer system, engineering, intune cheops als je iemand bent die geen uitdaging uit de weg gaat en ervan houdt om uit je comfortzone te treden, dan ben je bij cheops aan het juiste adres. bij cheops kom je terecht in een great place to work® waar plaats is voor gedreven en betrokken mensen. de ideale plek om je carriere een boost te geven.. wat doe jij als system engineer? als system engineer sta je in voor het uittekenen, uitrollen en beheren van complexe it - oplossingen, met minimale impact op de business bij onze klanten. jouw uitdagingen je ontwikkelt de totale architectuur van systemen en netwerken van onze klanten. dat kan gaan van migraties van omgevingen, installaties, tot zeer stevige & impactvolle uitbreidingen. alles gebeurt steeds in relatie tot de noden van onze klanten. het resultaat : een minimale change impact op de dagelijkse business van onze klanten. je identificeert welke innovaties een echte meerwaarde bieden in de performantie van de it - omgeving van onze klanten. je bouwt vanuit ervaring inzichten op die je vertaalt naar schaalbare concepten. zo kan de totale meerwaarde die cheops aan haar klanten kan bieden'upgraden '. je bent een expert in jouw domeinen en zorgt voor bijkomende ondersteuning van collega engineers voor die domeinen waarin je eigen expertise ontbreekt. je beheert de planning, budgetten en andere middelen voor de projecten waarop je actief bent, en waarbij je zelf een rol hebt gespeeld bij het bepalen van de scope. je weegt de beperkingen van budget, performantie, scope en timing steeds af in overleg met project managers en / of andere stakeholders. jouw talent je plant met oog op het minimaliseren van de impact bij klanten en anticipeert op potentiele uitdagingen vanuit meerdere oplossingsmogelijkheden. must haves : expertise in een of meerdere domeinen : o365 - azure - vmware / hyperv - citrix - firewalling ( fortinet, checkpoint,... ) - load balancing - voice prince2 of andere projectmethodologie stressbestendig flexibel sterke communicatievaardigheden rijbewijs b heb jij ook dat ambitieuze karakter van cheops? met onze jarenlange ervaring is cheops niet alleen uitgegroeid tot een kwaliteitslabel in it & business technology services, maar ook tot een great place to work®. een terechte erkenning door onze collega's. het behalen van dit unieke certificaat is een bevestiging dat cheops een aangename werkplek is, waar onze medewerkers vertrouwen hebben in elkaar en in cheops. je komt terecht in een bedrijf dat wordt geleid door een heldere toekomstvisie en waar we steeds tot het uiterste gaan voor onze klanten. heb jij ook die gedrevenheid om samen vooruit te gaan? solliciteer dan vandaag. dynamische mensen verdienen dynamische voordelen wil jij je kennis ten volle kunnen benutten en blijven groeien in je job? dan is ons persoonlijk ontwikkelingstraject ideaal voor jou. je krijgt tijd en ruimte voor opleidingen, zodat je nog beter wordt. we stippelen samen een traject uit in het kader van jouw ambities en verwachtingen en beg [SEP]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[CLS] cheops - system administrator sccm, scom, o365 cheops als je iemand bent die geen uitdaging uit de weg gaat en ervan houdt om uit je comfortzone te treden, dan ben je bij cheops aan het juiste adres. bij cheops kom je terecht in een great place to work® waar plaats is voor gedreven en betrokken mensen. de ideale plek om je carriere een boost te geven wat doe jij als system administrator? als system administrator beheer en optimaliseer je de systemen van onze klanten, met oog op het verminderen van incidenten en het verbeteren van de performantie. zo help je klanten zich te focussen op hun core business. jouw uitdagingen je verbetert op een continue basis de gehele it ervaring bij onze klanten. je houdt de systemen in de lucht. je vertrekt van de status quo en voert optimalisaties uit. je verwerft daarvoor o. a. inzichten rond de structuur van incidenten en wijzigingen bij onze klanten. je brengt mogelijke oorzaken in kaart, onderzoekt hoe deze verband houden en anticipeert met de gepaste actie. je onderzoekt welke vernieuwingen de volledige'systeem'ervaring naar'the next level'kan brengen binnen de afwegingen en beperkingen van budget, performantie, scope en timing. je optimaliseert de systemen met oog op het verminderen van incidenten en verbeteren van performantie. je werkt nauw samen met engineers voor complexere problemen en je daagt de support collega's uit met feedback zodat ze zelf groeien en bijleren voor die incidenten die ze ook zelf zouden kunnen oplossen. je zorgt voor bijkomende budgetten door de betrokken partijen het belang te laten inzien van aanpassingen op de systemen. je behartigt de performantie van systemen ( ook ) voor de toekomstige noden door proactieve uitbreidingen, upgrades, updates,... te plannen en te organiseren. jouw talent je bent een krak in verbanden leggen tussen uitdagingen. je communicatie richt zich niet op het incident, maar op de uitdaging achter het incident. must haves : basiskennis netwerking en security enkele jaren ervaring basiskennis van een of meerdere technologieen : sccm / scom - virtualisatie - o365 - adfs - exchange - azure - powershell -... rijbewijs b drive en flexibiliteit sterke communicatievaardigheden nice to haves : mcsa windows server of gelijkwaardig door ervaring cloud affiniteit ( o365, azure ) heb jij ook dat ambitieuze karakter van cheops? met onze jarenlange ervaring is cheops niet alleen uitgegroeid tot een kwaliteitslabel in it & business technology services, maar ook tot een great place to work®. een terechte erkenning door onze collega's. het behalen van dit unieke certificaat is een bevestiging dat cheops een aangename werkplek is, waar onze medewerkers vertrouwen hebben in elkaar en in cheops. je komt terecht in een bedrijf dat wordt geleid door een heldere toekomstvisie en waar we steeds tot het uiterste gaan voor onze klanten. heb jij ook die gedrevenheid om samen vooruit te gaan? solliciteer dan vandaag. dynamische mensen verdienen dynamische voordelen wil jij je kennis ten volle kunnen benutten en blijven groeien in je job? dan is on [SEP]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[CLS] brunel - system engineer system, administrator, admin brunel introductie als systeem engineer kan je via brunel bij verschillende opdrachtgevers aan de slag. bij welke jij terechtkomt, hangt af van jouw voorkeur. maar een ding is zeker : alles wat je doet, begint bij goed klantcontact. de werknemers van jouw opdrachtgever kloppen namelijk regelmatig bij je aan met vragen en problemen. aan jou de taak om stevig door te vragen en met hen mee te denken, zodat je efficient tot een oplossing komt. soms komt er wat haast bij kijken, bijvoorbeeld als iemand tijdens zijn presentatie uit het netwerk is gezet. enige flexibiliteit en stressbestendigheid is dus geen overbodige luxe. daarnaast draag je samen met het team de zorg voor ( deel ) producten en diensten binnen van de opdrachtgever. je organiseert bijvoorbeeld geregeld updates, of je werkt aan nieuwe releases, documenteert over het functioneren van de systemen en treedt preventief op om storingen te voorkomen. bovendien doe je er alles aan om de systemen zo goed mogelijk te beschermen tegen malware. omschrijving het installeren, configureren en inbedrijfnemen van systemen het beheren en het verzorgen van de infrastructuur van onze klant troubleshooting op bestaande systemen, detectie en oplossing van problemen het geven van advies bij product - en projectoffertes het documenteren van de opgeleverde systemen het deelnemen aan teammeetings met betrekking tot de status van huidige projecten het ondersteunen van collega - systeemspecialisten vereisten first things first : wat mag je verwachten binnen jouw takenpakket? als systeem engineer is het uiteraard logisch dat je meer dan een beetje weet van ict. daarom heb je het liefst : + - 2 jaar ervaring binnen systeembeheer ( windows & linux ) bij voorkeur een diploma of getuigschrift in de richting informatica ( extra opleidingen of cursussen tellen ook mee ) voornamelijk ervaring met troubleshooting, cloud en virtualisatie kennis van vmware, citrix, azure, sccm, powershell, office365, tcp - ip vlot in het nederlands en engels ( frans is een pluspunt ) aanbod je kan rekenen op een vast maandloon, wagen en tankkaart en interessante extra's ( bv. hospitalisatie - en groepsverzekering, maaltijd - en ecocheques, 13e maand, premie pc200, leuke evenementen,... ). wanneer je als system engineer door brunel it ingezet wordt bij opdrachtgevers, betekent dit dat je in dienst treedt bij brunel. bij brunel it staat jouw loopbaan voorop. brunel biedt jou de mogelijkheid om je te ontwikkelen door middel van een persoonlijk ontwikkeltraject. je kunt hierbij denken aan het behalen van belangrijke en relevante certificaten. je hebt bij brunel niet alleen de zekerheid van een contract, maar ook van een carriere. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[CLS] ucm - administrateur systemes db2, oracle, postgresql ucm l'admin sys chez ucm : un vrai besoin! ucm comporte plusieurs departements informatiques au service d'environ 1000 utilisateurs repartis dans plusieurs succursales : un departement « transversal » et trois departements « metier » ( caisse d'allocations familiales, secretariat social, caisse d'assurances sociales / guichet d'entreprises ). ce poste concerne le departement « transversal » qui compte une trentaine de collegues it. ta mission assurer la gestion quotidienne de l'infrastructure informatique au sein du groupe ucm afin de garantir son fonctionnement, ses performances et sa disponibilite optimale. plus precisement : tu travailles sur l'ensemble des couches du systeme informatique allant de l'infrastructure virtualisee dans nos datacenters aux applications metiers ainsi qu'aux interconnexions entre les differents elements. tu veilles a obtenir une disponibilite maximale des systemes pour les utilisateurs finaux : analyse d'incidents, resolution de problemes, monitoring de performance, tuning et optimalisation de l'architecture, etc. tu participes au respect de plusieurs normes certifiees en suivant et maintenant des procedures strictes tu analyses et verifies l'impact de nouveaux releases et installations de logiciels tu participes a des projets propres aux equipes systemes et tu es amene a donner ton avis technique dans les projets de developpement assures par d'autres equipes tu es un maillon de la chaine de developpement logiciel et collabores avec l'ensemble des equipes et fonctions de celle - ci exemple de technologies utilisees : serveurs linux sous redhat virtualises sur vmware serveur web d'applications et de services : tomcat, apache, etc. base de donnees : db2, oracle, postgresql, mysql, etc. technologies devops et d'integration : elk, docker, jenkins, git, ansible, etc. langages de programmation / scripting : bash principalement outils collaboratifs : jira, confluence, etc. ordonnanceur ( tws ibm ) back - up ( tsm ibm ) etc. nous cherchons un profil professionnel tu as... un baccalaureat en informatique, oriente systemes des connaissances en anglais, au minimum technique un profil humain tu es... competent dans l'administration serveur linux en cli rigoureux, precis et capable de gerer des priorites un teamplayer tout en pouvant travailler de maniere autonome assertif, diplomate, capable de vous adapter a differents types d'interlocuteurs ; resolument oriente \" client \", ton sens du service te permet de percevoir avec pertinence les besoins et attentes et de reflechir a une solution adaptee motive a developper vos competences et connaissances techniques a la recherche d'un travail diversifie notre offre des avantages indeniables : un contrat temps plein, a duree indeterminee une opportunite de participer a un projet qui a du sens de superbes defis a relever au sein d'une societe en pleine evolution ou l'humain occupe une place centrale un package salarial complet, assorti de nombreux avantages extra - legaux 20 jours de conge legaux, 2 jours de vacances complementaires et 12 jours de rtt teletravail structurel 2 jours par semaine et flexibilite horaire assurances groupe et hospitalisation avantages adsl prime de fin d'annee cheques - repas anr cheque - cadeau de fin d'annee complement allocations familiales formations internes un environnement de travail propice a l'epanouissement des equipes soudees, qui n'hesitent pas a partager de nombreux moments conviviaux ( fete du personnel, teambuilding [SEP]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "[CLS] simac - medior network engineer network, ip, wi - fi simac start : asap duration : long term ( end of the year + possible extensions ) languages : french + english description network engineer establishes and maintains network performance. network engineer is responsible for analysing, installing, configuring, maintaining and repairing of network infrastructure. primary tasks & responsibilities installation, configuration and upgrading of network devices : switches, routers and wi - fi controllers and related hardware in an international environment. investigation, diagnostic, testing and resolution of ip network and wi - fi incidents monitoring performance, troubleshooting network problems and outages, scheduling upgrades. collaborating with network architect on network optimization. coordinating resources where necessary and serving as escalation point to operational teams. working in validated environment which implies writing and maintenance of technical documentation and procedures, and follow controlled change management process. network design is not part of the job. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[CLS] ucm - administrateur reseau support, reseau, securite, system ucm ta mission principale sous la responsabilite du support systems leader, tu seras plus particulierement rattache ( e ) a l'equipe « support systems administration », ou tu devras gerer avec efficacite et precision de multiples plateformes afin de proposer aux services internes un environnement de travail it de qualite. plus precisement : configuration du support et du deploiement des equipements reseau ( switches, routeurs, load balancers... ) et des technologies liees. participation a la gestion des equipements de securite. gestion des outils de communication et de collaboration. administration de l'ensemble des serveurs windows virtualises et gestion des comptes utilisateurs et droits d'acces. helpdesk de troisieme niveau. deploiements de packages logiciels au moyen de solutions centralisees. veille de la perennite des systemes au moyen de backups et de solutions de monitoring notre collegue ideal ( e ) possede au minimum un baccalaureat informatique ou une experience concrete equivalente ; exerce une fonction similaire depuis 2 ans minimum ; dispose des connaissances techniques suivantes : tcp / ip - lan / wan - qos - vlan - nac voip skype4b / teams active directory windows server 2016 / 2019 ms exchange onprem / online sharepoint vmware system center configuration manager developpement et maintenance de scripts d'administration powershell dhcp, dns, kms, wsus infrastructure wifi apprecie travailler en toute autonomie tout en s'integrant au sein d'une equipe. l'aspect relationnel de la fonction et la satisfaction du client sont d'ailleurs des priorites pour lui / elle ; est rigoureux ( se ), et possede egalement un bon sens de l'organisation et des priorites ; est oriente ( e ) solutions et resultats, la perseverance est egalement une de ses valeurs ; a une bonne connaissance de l'anglais technique. notre offre des avantages indeniables : un contrat temps plein, a duree indeterminee une opportunite de participer a un projet qui a du sens de superbes defis a relever au sein d'une societe en pleine evolution ou l'humain occupe une place centrale un package salarial complet, assorti de nombreux avantages extra - legaux : teletravail structurel 2 jours par semaine et flexibilite horaire assurances groupe et hospitalisation prime de fin d'annee cheque - cadeau de fin d'annee de 40 euros cheques - repas de 8 euros / jour complement au pecule de vacances 34 jours de conges par an complement d'allocations familiales formations internes un environnement de travail propice a l'epanouissement des equipes soudees, qui n'hesitent pas a partager de nombreux moments conviviaux ( fete du personnel, teambuildings... ) interesse ( e )? postule via le bouton ci - dessous, tu recevras une reponse a ta candidature quoiqu'il arrive. attention : merci de noter qu'aucune candidature envoyee par un bureau de recrutement non mandate expressement par ucm, ne sera retenue. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0enAb0W9o25W",
        "outputId": "b0ab1060-e396-4695-e09e-10fbb9e9dd50"
      },
      "source": [
        "example = encoded_dataset['train'][0]\n",
        "print(f\"example.keys(): {example.keys()}\")\n",
        "print(f\"example['input_ids']: {example['input_ids']}\")\n",
        "print(f\"example['token_type_ids']: {example['token_type_ids']}\")\n",
        "print(f\"example['attention_mask']: {example['attention_mask']}\")\n",
        "print(f\"example['labels']: {example['labels']}\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example.keys(): dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
            "example['input_ids']: [101, 1999, 3388, 2819, 1011, 2613, 3527, 13728, 2368, 1011, 24296, 6112, 3992, 24296, 6112, 1999, 3388, 2819, 1011, 2613, 3527, 13728, 2368, 2115, 3853, 2000, 2490, 1996, 27258, 3930, 1997, 2256, 24296, 3218, 1010, 2057, 2024, 2559, 2005, 2195, 24296, 6112, 6145, 1012, 2182, 1005, 1055, 2129, 2017, 1005, 2222, 2191, 4254, 1024, 2005, 3469, 3934, 2017, 2147, 1999, 2136, 2007, 2060, 24296, 6112, 6145, 1010, 6112, 5576, 8160, 1998, 2622, 10489, 2000, 4339, 1037, 2047, 3112, 2466, 1012, 2057, 2064, 4175, 2006, 2017, 2005, 1996, 2658, 7375, 1997, 1996, 8518, 18011, 2000, 2017, 1012, 2005, 3760, 6112, 3934, 2017, 2024, 1999, 3715, 2005, 1996, 2440, 8147, 1024, 2017, 18012, 2115, 7396, 2013, 1996, 2640, 2127, 2010, 5576, 2003, 3929, 6515, 1012, 1999, 2804, 2000, 24853, 1010, 2017, 2036, 3749, 2353, 1011, 2240, 2490, 2000, 6304, 1998, 8628, 1012, 19309, 2003, 1999, 2115, 9165, 1012, 2017, 2467, 29453, 2000, 2191, 2115, 2166, 1998, 2008, 1997, 1996, 3169, 6145, 6082, 2011, 8285, 18900, 2075, 2673, 1012, 6502, 1011, 2004, 1011, 3642, 2515, 2025, 2614, 6881, 2000, 2017, 1012, 2017, 3231, 12246, 1010, 1998, 2017, 2123, 1005, 1056, 12014, 2006, 3737, 1012, 2017, 25276, 2000, 2613, 3527, 13728, 6132, 2190, 6078, 1998, 2377, 2019, 3161, 2535, 1999, 1996, 7142, 7620, 2011, 2437, 15690, 1998, 12719, 2241, 2006, 2115, 3679, 2398, 1011, 2006, 3325, 1012, 2017, 2097, 2022, 2920, 2076, 13433, 6169, 1010, 8221, 1998, 4013, 19620, 2578, 1999, 3388, 2819, 1011, 2613, 3527, 13728, 2368, 4107, 2004, 1037, 6112, 3266, 2578, 10802, 1006, 5796, 2361, 1007, 1010, 2107, 1037, 3465, 20600, 1010, 2166, 23490, 2968, 1010, 4294, 20600, 1010, 1012, 1012, 1012, 2017, 2562, 2115, 2147, 2092, 1011, 8832, 1010, 3154, 1998, 2000, 1996, 2391, 1012, 2115, 6337, 2017, 2024, 5281, 1999, 24296, 2004, 1037, 2291, 3992, 2017, 2031, 1037, 3492, 2204, 4824, 1997, 1996, 24296, 6502, 1011, 2004, 1011, 1037, 1011, 2326, 4132, 1998, 2064, 14358, 1996, 2794, 3643, 1997, 24264, 3022, 6177, 2005, 7846, 1005, 7972, 8146, 1012, 2017, 2024, 9461, 2000, 4553, 1998, 12479, 1012, 2017, 2036, 15697, 2115, 2219, 2051, 1999, 4363, 2115, 5566, 14767, 2039, 1011, 2000, 1011, 3058, 1012, 2017, 2024, 1037, 2613, 2136, 2447, 1010, 2021, 2017, 2036, 2131, 2006, 2074, 2986, 2006, 2115, 2219, 1012, 2017, 2024, 14286, 10571, 1998, 2467, 5627, 2000, 3745, 3716, 2007, 8628, 1012, 2017, 2024, 12379, 1998, 13070, 2000, 6911, 1012, 2017, 2147, 14125, 1998, 2006, 1037, 2622, 3978, 1010, 1998, 2017, 2024, 2025, 4810, 2000, 2191, 12014, 2015, 2043, 2009, 3310, 2000, 3737, 1012, 2017, 3713, 19376, 2135, 3803, 1998, 2394, 2030, 2413, 1998, 2394, 1012, 2065, 2008, 1005, 1055, 2017, 1010, 2272, 1999, 1998, 2031, 1037, 2831, 2007, 2149, 999, 2256, 3749, 1996, 4495, 2000, 2031, 1037, 15902, 3105, 2073, 2017, 2064, 2191, 1037, 4489, 1025, 1996, 3382, 2000, 10843, 19852, 2004, 1037, 2658, 1010, 11211, 2007, 1037, 3528, 1997, 2731, 6695, 1025, 1999, 3388, 2819, 1011, 2613, 3527, 13728, 2368, 4122, 2017, 2000, 2424, 1037, 5703, 2090, 2147, 1998, 2797, 2166, 2011, 5378, 12379, 2847, 1010, 5871, 4822, 1998, 2188, 2551, 1025, 3590, 2420, 1997, 3296, 2681, 1010, 2138, 2166, 3475, 1005, 1056, 2035, 2055, 2551, 1025, 5293, 2055, 1996, 2661, 1024, 2057, 3073, 2017, 2007, 1037, 2194, 2482, 1998, 1037, 2120, 4762, 4003, 1025, 2177, 5427, 1998, 2902, 3989, 5427, 1010, 2138, 2057, 2729, 2055, 2017, 1025, 1998, 1997, 2607, 1010, 2057, 2036, 3749, 1037, 7977, 10300, 1012, 2028, 2029, 2003, 23569, 27605, 5422, 2013, 1037, 5658, 7339, 2005, 2256, 5126, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "example['token_type_ids']: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "example['attention_mask']: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "example['labels']: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "D0McCtJ8HRJY",
        "outputId": "7987dd3f-6405-4def-f79c-7b33c2134d73"
      },
      "source": [
        "tokenizer.decode(example['input_ids'])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] inetum - realdolmen - azure cloud engineer azure cloud inetum - realdolmen your function to support the exponential growth of our azure practice, we are looking for several azure cloud engineers. here's how you'll make impact : for larger projects you work in team with other azure cloud engineers, cloud solution architects and project managers to write a new success story. we can count on you for the professional implementation of the tasks entrusted to you. for smaller cloud projects you are in charge for the full engagement : you advise your client from the design until his solution is fully operational. in addition to consultancy, you also offer third - line support to customers and colleagues. automation is in your genes. you always strive to make your life and that of the operation engineers easier by automating everything. infrastructure - as - code does not sound weird to you. you test thoroughly, and you don't compromise on quality. you adhere to realdolmens best practices and play an active role in the continuous improvement by making suggestions and modifications based on your daily hands - on experience. you will be involved during pocs, pilots and proactive services inetum - realdolmen offers as a cloud managed services provider ( msp ), such a cost optimization, lifecycle management, architecture optimization,... you keep your work well - documented, clear and to the point. your profile you are experienced in azure as a system engineer you have a pretty good understanding of the azure infrastructure - as - a - service platform and can assess the added value of iaas components for clients'respective situations. you are eager to learn and ambitious. you also invest your own time in keeping your competencies up - to - date. you are a real team player, but you also get on just fine on your own. you are socially skilled and always willing to share knowledge with colleagues. you are flexible and resistant to stress. you work accurately and on a project basis, and you are not prepared to make compromises when it comes to quality. you speak fluently dutch and english or french and english. if that's you, come in and have a talk with us! our offer the opportunity to have a meaningful job where you can make a difference ; the chance to continuously evolve as a professional, coupled with a variety of training opportunities ; inetum - realdolmen wants you to find a balance between work and private life by offering flexible hours, satellite offices and home working ; 32 days of annual leave, because life isn't all about working ; forget about the miles : we provide you with a company car and a national fuel card ; group insurance and hospitalization insurance, because we care about you ; and of course, we also offer a gross salary. one which is optimized from a net perspective for our employees! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Dx95t2o6N9",
        "outputId": "c3114082-edb2-4109-d295-e7f956b35a64"
      },
      "source": [
        "example = encoded_dataset['train'][0]\n",
        "print(example[\"labels\"])\n"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LAyThO7Jnvj",
        "outputId": "a88fddee-905e-4b01-ea75-3ed75fee6c1a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['157']"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raise Exception(\"STOP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "AgsREtKnMA50",
        "outputId": "dad37d04-7eae-4b43-dbea-09887a34df95"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "STOP",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-66b14b1a1fb1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"STOP\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mException\u001b[0m: STOP"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgpKXDfvKBxn"
      },
      "source": [
        "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk6Cq9duKBkA"
      },
      "source": [
        "encoded_dataset.set_format(\"torch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5qSmCgWefWs"
      },
      "source": [
        "## Define model\n",
        "\n",
        "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
        "\n",
        "This is also printed by the warning.\n",
        "\n",
        "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XPL1Z_RegBF"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjJGEXShp7te"
      },
      "source": [
        "## Train the model!\n",
        "\n",
        "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things:\n",
        "\n",
        "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
        "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5a8_vIKqr7P"
      },
      "source": [
        "batch_size = 8\n",
        "metric_name = \"f1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR2GmpvDqbuZ"
      },
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"bert-finetuned-sem_eval-english\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    #push_to_hub=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_v2fPFFJ3-v"
      },
      "source": [
        "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "797b2WHJqUgZ"
      },
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def multi_label_metrics(predictions, labels, threshold=0.5):\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true = labels\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # return as dictionary\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'accuracy': accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions,\n",
        "            tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxNo4_TsvzDm"
      },
      "source": [
        "Let's verify a batch as well as a forward pass:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlOgGiojuWwG"
      },
      "source": [
        "encoded_dataset['train'][0]['labels'].type()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y41Kre_jvD7x"
      },
      "source": [
        "encoded_dataset['train']['input_ids'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxWcnZ8ku12V"
      },
      "source": [
        "#forward pass\n",
        "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0), labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
        "outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-X2brZcv0X6"
      },
      "source": [
        "Let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chq_3nUz73ib"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmFds8js6P8"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiloh9eMK91o"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "After training, we evaluate our model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMlebJ83LRYG"
      },
      "source": [
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nmvJp0pLq-3"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Let's test the model on a new sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fxjfr8PLD42"
      },
      "source": [
        "text = \"I'm happy I can finally train a model for multi-label classification\"\n",
        "\n",
        "encoding = tokenizer(text, return_tensors=\"pt\")\n",
        "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
        "\n",
        "outputs = trainer.model(**encoding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8THm5-XgNHPm"
      },
      "source": [
        "The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOBosj4UL2tU"
      },
      "source": [
        "logits = outputs.logits\n",
        "logits.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC4XdDaHNVcd"
      },
      "source": [
        "To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n",
        "\n",
        "Next, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEkAQleMMT0k"
      },
      "source": [
        "# apply sigmoid + threshold\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs = sigmoid(logits.squeeze().cpu())\n",
        "predictions = np.zeros(probs.shape)\n",
        "predictions[np.where(probs >= 0.5)] = 1\n",
        "# turn predicted id's into actual label names\n",
        "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
        "print(predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}