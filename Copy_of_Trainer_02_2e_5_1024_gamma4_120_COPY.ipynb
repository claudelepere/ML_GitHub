{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudelepere/ML_GitHub/blob/main/Copy_of_Trainer_02_2e_5_1024_gamma4_120_COPY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OIjOPWowcJq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a598179-f6b1-4dc1-f693-43cc47a897c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/143.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q scikit-learn\n",
        "\n",
        "# transformers and datasets are Hugging Face libraries\n",
        "!pip install -q transformers datasets\n",
        "\n",
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ync6uXy-wcJs"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgQnuPvUFNsY"
      },
      "outputs": [],
      "source": [
        "from datasets              import DatasetDict\n",
        "from google.colab          import auth, drive, files, userdata\n",
        "from huggingface_hub       import create_repo, login, upload_file, hf_hub_download\n",
        "from huggingface_hub.utils import RepositoryNotFoundError\n",
        "from sklearn.metrics       import accuracy_score, average_precision_score, classification_report, f1_score, precision_score, precision_recall_curve, precision_recall_fscore_support, recall_score, roc_auc_score\n",
        "from torch.utils.data      import DataLoader\n",
        "from tqdm.auto             import tqdm\n",
        "from transformers          import AdamW, EvalPrediction, LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.nn              import BCEWithLogitsLoss, Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dro6dkjyHNA7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab    import userdata\n",
        "from huggingface_hub import login, hf_hub_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNxYo9txwcJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc09a87-0d5d-49d2-a110-db067e4dcc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "# Hugging Face Authenticate\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")    # Store the key in os.environ\n",
        "hf_token               = os.environ.get('HF_TOKEN')\n",
        "login(token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDimlzpeMDyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8d640b-7e55-4dbd-8f3a-342f7b0b757a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "claudelepere\n"
          ]
        }
      ],
      "source": [
        "# Verify\n",
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtCrlJwnwcJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "c83b713f91774c0f8e75edbee6d7cebe",
            "91f0355cafa94df9b21d51c1ed476447",
            "ea715d4ef66b4fa3a1a0023174b4b810",
            "b860bb6be6914be5817c9e410bde25f3",
            "cb901312dc6545599dfead4177c07684",
            "f9ebab9db3fe4acc94c828132057d52e",
            "e45a1ca8f4fa40088492cd9959aa44d6",
            "d8052f6ab37f464e9e0578326e667dd4",
            "66092725306a46cd94eb13f50165cc8e",
            "b8e3d7f7652544399408ffcaad15d5cd",
            "7a114ef6802840edbc0946f387b11e54"
          ]
        },
        "outputId": "2d91dd07-4b8b-455e-f7f5-d259a05fdfd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test_model_eval_results.csv:   0%|          | 0.00/313k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c83b713f91774c0f8e75edbee6d7cebe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_path: /root/.cache/huggingface/hub/datasets--claudelepere--skill_classification/snapshots/503a858fbbe496641782676a9c1be44217478649/test_model_eval_results.csv\n"
          ]
        }
      ],
      "source": [
        "file_path = hf_hub_download(\n",
        "    repo_id   =\"claudelepere/skill_classification\",\n",
        "    repo_type = \"dataset\",\n",
        "    filename  = \"test_model_eval_results.csv\"\n",
        ")\n",
        "print(f\"file_path: {file_path}\")  # /root/.cache/huggingface/hub/datasets--claudelepere--skill_classification/snapshots/51ead81f69b1689fc19694b3f034585cde9f56e1/test_model_eval_results.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwEbNhC_wcJs"
      },
      "source": [
        "Next, open in Colab or download to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhAd6EZJwcJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0094a2f4-44a1-4b9d-8747-6c0cc1d60c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Check the Python version\n",
        "print(sys.version)\n",
        "print()\n",
        "\n",
        "# Get the installed packages (you can see that conda is not installed (do not install it))\n",
        "!pip list\n",
        "print()\n",
        "\n",
        "# Check system information\n",
        "!cat /etc/os-release\n",
        "!uname -m\n",
        "print()\n",
        "\n",
        "# Check the GPU details (only if the runtime type is T4 GPU)\n",
        "#!nvidia-smi\n",
        "#print()\n",
        "\n",
        "# Check RAM\n",
        "!free -h\n",
        "print()\n",
        "\n",
        "# Check disk space\n",
        "!df -h\n",
        "print()\n",
        "\n",
        "# Get environment variables\n",
        "for key, value in os.environ.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\"\"\"\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUTMN8SSwcJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9189b660-8989-4b12-d8af-219af481ee46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "currentdir: /content\n"
          ]
        }
      ],
      "source": [
        "print(f\"currentdir: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIUfehpkwcJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e71b568-eea0-4fe4-f42a-c7da99a9dd24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWgIYo5DwcJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282fa81b-220f-4ff9-e01d-ab9964bcccb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasetDict_zip_file_name: dataset_11_120.zip\n",
            "datasetDict_dir_name     : dataset_11_120\n",
            "\n"
          ]
        }
      ],
      "source": [
        "datasetDict_zip_file_name = \"dataset_11_120.zip\"\n",
        "datasetDict_dir_name      = os.path.splitext(datasetDict_zip_file_name)[0]\n",
        "print(f\"datasetDict_zip_file_name: {datasetDict_zip_file_name}\")\n",
        "print(f\"datasetDict_dir_name     : {datasetDict_dir_name}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq0JDT07wcJt"
      },
      "outputs": [],
      "source": [
        "# OOM: reduce batch size\n",
        "#      small sizes (1 to 32):            PROs: better generalization in some cases\n",
        "#                                        CONs: may produce noisier gradients\n",
        "#      large sizes (128, 256, or higer): PROs: gradients are smoother, leading to more stable training\n",
        "#                                        CONs: poorer generalization (overfitting) in some cases\n",
        "#      intermediate sizes (32, 64):      combines the benefits of small and large sizes\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nG0pflXGwcJt"
      },
      "outputs": [],
      "source": [
        "# OOM: enable gradient accumulation to compensate for smaller batch sizes by accumulating gradients over several steps\n",
        "#      effective batch size = per-device batch size x gradient accumulation steps;\n",
        "#      in each iteration, the model computes the gradients, these gradients are immediately used to update the model parameters\n",
        "gradient_accumulation_steps = 4  #<<<<<<<<<<<<<<<<<<< gradient_accumulation_steps may not be None => comment it in TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXrPvSWAwcJt"
      },
      "outputs": [],
      "source": [
        "# OOM: use PYTORCH_CUDA_ALLOC_CONF to handle memory fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKeGyFYHwcJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cebd59-4e9c-4011-bc0e-f8f428aa523a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root          74  2.8  0.0      0     0 ?        Z    21:25   0:18 [python3] <defunct>\n",
            "root          75  0.1  0.3  63656 49768 ?        S    21:25   0:00 python3 /usr/local/bin/colab-file\n",
            "root          92  0.9  0.9 366068 124432 ?       Sl   21:25   0:05 /usr/bin/python3 /usr/local/bin/j\n",
            "root         818  8.4  9.4 6162172 1250276 ?     Ssl  21:28   0:39 /usr/bin/python3 -m colab_kernel_\n",
            "root         857  0.2  0.1 545768 21576 ?        Sl   21:28   0:01 /usr/bin/python3 /usr/local/lib/p\n",
            "root        2809  0.0  0.0   7376  3596 ?        S    21:36   0:00 /bin/bash -c ps aux | grep python\n",
            "root        2811  0.0  0.0   6484  2352 ?        S    21:36   0:00 grep python\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `kill -9 <PID>'\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# OOM: check for zombie processes\n",
        "if torch.cuda.is_available():\n",
        "  !nvidia-smi\n",
        "  torch.cuda.memory_summary()\n",
        "!ps aux | grep python\n",
        "!kill -9 <PID>\n",
        "!nvidia-smi     # Checked if killed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbyMivrEwcJu"
      },
      "outputs": [],
      "source": [
        "# OOM: use fp16 (half precision) mixed precision training\n",
        "#      reduces memory requirements by up to 50%\n",
        "fp16 = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVhoxNtUwcJu"
      },
      "source": [
        "OOM: limit the number of GPU workers: 0 (default) or 1 in Colab\n",
        "dataloader_num_workers = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZOpDR5JwcJu"
      },
      "outputs": [],
      "source": [
        "# OOM: reduce model size or input tokens\n",
        "#      1) LongformerTokenizer.from_pretrained('allenai/longformer-base/large-4096'): large/base: 435M/149M parameters\n",
        "#      2) max_length: 4096 max for Longformer; 1 word can give several tokens, stop words are NOT discarded!\n",
        "#         word_text_length_counts_sorted: jobs count                 : 50000\n",
        "#                                         jobs count under  512 words: 44794  89.59%\n",
        "#                                         jobs count under  640 words: 47894  95.79%\n",
        "#                                         jobs count under  768 words: 49123  98.25%\n",
        "#                                         jobs count under  896 words: 49691  99.38%\n",
        "#                                         jobs count under 1024 words: 49917  99.83%\n",
        "#                                         jobs count under 2048 words: 50000 100.00%\n",
        "#                                         jobs count under 4096 words: 50000 100.00%\n",
        "#max_length =  768    #      37 min    #\n",
        "max_length = 1024    #      38 min    # GPU RAM: 12.2 / 40 GB\n",
        "#max_length = 2048    # 1 hr 10 min    # GPU RAM: 21.4 / 40 GB\n",
        "#max_length = 4096    # 2 hr 10 min    # GPU RAM: 39.5 / 40 GB => OutOfMemoryError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJNB5_2HwcJu"
      },
      "outputs": [],
      "source": [
        "# OOM: free up GPU memory\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YgjmWL7wcJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd6c00a-dfa9-4fbb-cb69-b5cef9f08713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nividia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# OOM: monitor GPU memory usage\n",
        "!nividia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KORJtBl7wcJu"
      },
      "outputs": [],
      "source": [
        "# 1 epoch is a complete pass through the entire training dataset;\n",
        "# with n datapoints and batch size = b, n/b iterations to complete 1 epoch;\n",
        "# 1 iteration is a single update of the model's parameters\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaoQWRXYwcJu"
      },
      "outputs": [],
      "source": [
        "# A common rule is to scale the learning rate proportionaly with the effective batch size\n",
        "# note: get_linear_schedule_with_warmup <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "learning_rate = 2e-5  # 1e-5 x 32/8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVi2_ymCwcJu"
      },
      "source": [
        "Reduce the number of transformers layers\n",
        "hidden_layers = 12    # 12 (default) or 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Dfm6lvwcJu"
      },
      "outputs": [],
      "source": [
        "# Threshold: 0.5 (default)\n",
        "threshold = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIihId9jwcJu"
      },
      "outputs": [],
      "source": [
        "if fp16:\n",
        "  _fp = \"fp16\"\n",
        "else:\n",
        "  _fp = \"fp32\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gweGUl--FNsZ",
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5051636-bb2f-41ff-cb92-a52fa4e1a4f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_name                 : Longformer-multilabel-dataset_11_120-length1024-batch8x4-epochs5-lr2e-05-fp16-threshold0.2\n"
          ]
        }
      ],
      "source": [
        "if 'gradient_accumulation_steps' not in globals():\n",
        "  run_name = f\"Longformer-multilabel-{datasetDict_dir_name}-length{max_length}-batch{batch_size}-epochs{epochs}-lr{learning_rate}-{_fp}-threshold{threshold}\"\n",
        "else:\n",
        "  run_name = f\"Longformer-multilabel-{datasetDict_dir_name}-length{max_length}-batch{batch_size}x{gradient_accumulation_steps}-epochs{epochs}-lr{learning_rate}-{_fp}-threshold{threshold}\"\n",
        "print(f\"run_name                 : {run_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvZTXW-_ZAJ-",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def upload_unzip_dataset(file_name=datasetDict_zip_file_name):\n",
        "  # Check if the file exists\n",
        "  if not os.path.exists(file_name):\n",
        "    print(f\"'{file_name}' not found in /content. Uploading...\")\n",
        "    uploaded_files = files.upload()                              # Prompt file upload dialog\n",
        "    if file_name not in uploaded_files:\n",
        "      raise FileNotFoundError(f\"'{file_name}' was not uploaded. Please try again.\")\n",
        "    print(f\"'{file_name}' successfully uploaded to /content\")\n",
        "    uploaded_file_name = list(uploaded_files.keys())[0]          # Get the name of the uploaded file\n",
        "\n",
        "    !unzip {uploaded_file_name}\n",
        "\n",
        "    unzipped_dir_name = os.path.splitext(uploaded_file_name)[0]\n",
        "    assert unzipped_dir_name==datasetDict_dir_name, \"unzipped_dir_name != datasetDict_dir_name\"\n",
        "  else:\n",
        "    print(f\"'{datasetDict_dir_name}' already exists in /content.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k70dawNeONH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "d50b09d4-dc5f-4251-85de-75451c0580af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'dataset_11_120.zip' not found in /content. Uploading...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c8ab07ef-c165-46f8-8e0d-11759bdcfdd2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c8ab07ef-c165-46f8-8e0d-11759bdcfdd2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_11_120.zip to dataset_11_120.zip\n",
            "'dataset_11_120.zip' successfully uploaded to /content\n",
            "Archive:  dataset_11_120.zip\n",
            "  inflating: dataset_11_120/dataset_dict.json  \n",
            "  inflating: dataset_11_120/test/data-00000-of-00001.arrow  \n",
            "  inflating: dataset_11_120/test/dataset_info.json  \n",
            "  inflating: dataset_11_120/test/state.json  \n",
            "  inflating: dataset_11_120/train/data-00000-of-00001.arrow  \n",
            "  inflating: dataset_11_120/train/dataset_info.json  \n",
            "  inflating: dataset_11_120/train/state.json  \n",
            "  inflating: dataset_11_120/validation/data-00000-of-00001.arrow  \n",
            "  inflating: dataset_11_120/validation/dataset_info.json  \n",
            "  inflating: dataset_11_120/validation/state.json  \n"
          ]
        }
      ],
      "source": [
        "upload_unzip_dataset(datasetDict_zip_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX-YLguewcJv"
      },
      "source": [
        "Hugging Face Authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6KDXp3OwcJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f6bef7-7a82-4074-bff3-f1388b3d3ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")    # Store the key in os.environ\n",
        "hf_token               = os.environ.get('HF_TOKEN')\n",
        "login(token=hf_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5Ziyt5IwcJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43f1583-dbc1-41c7-9673-9ec264c9438a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "claudelepere\n"
          ]
        }
      ],
      "source": [
        "# Verify\n",
        "!huggingface-cli whoami"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPBlVmE3wcJv"
      },
      "source": [
        "Create the skill_classification repo on the Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1haRyaUwcJv"
      },
      "outputs": [],
      "source": [
        "HF_name         = \"claudelepere/skill_classification\"\n",
        "repo_id_model   = HF_name\n",
        "repo_id_dataset = HF_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB2OYD2ywcJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ffe160-2324-4920-b188-8bfb170abb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo model url: https://huggingface.co/claudelepere/skill_classification created successfully as a private repo.\n"
          ]
        }
      ],
      "source": [
        "repo_model_url = create_repo(\n",
        "    repo_id   = repo_id_model,\n",
        "    repo_type = \"model\",\n",
        "    private   = True,\n",
        "    exist_ok  = True\n",
        ")\n",
        "print(f\"Repo model url: {repo_model_url} created successfully as a private repo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoWP5yVgwcJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23dd961b-624c-46d7-9973-11bf9305c6aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo datasets url: https://huggingface.co/datasets/claudelepere/skill_classification created successfully as a private repo.\n"
          ]
        }
      ],
      "source": [
        "repo_dataset_url = create_repo(\n",
        "    repo_id   = repo_id_dataset,\n",
        "    repo_type = \"dataset\",\n",
        "    private   = True,\n",
        "    exist_ok  = True\n",
        ")\n",
        "print(f\"Repo datasets url: {repo_dataset_url} created successfully as a private repo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OUzSg4AwcJv"
      },
      "outputs": [],
      "source": [
        "repo_id_dataset = f\"datasets/{HF_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lvx8Nh_Ms_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebcf6648-5414-4502-a7b5-3067572d8c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "repo_id_model: claudelepere/skill_classification\n",
            "repo_id_dataset: datasets/claudelepere/skill_classification\n"
          ]
        }
      ],
      "source": [
        "print(f\"repo_id_model: {repo_id_model}\")\n",
        "print(f\"repo_id_dataset: {repo_id_dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T90_cKa4wcJv"
      },
      "source": [
        "W&B initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giGsdqlUwcJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161603a1-080e-4526-b91d-884bffbc8383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclaudelepere\u001b[0m (\u001b[33mclaudelepere-c-cile-cy\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")        # Store the key in os.environ\n",
        "wandb_api_key               = os.environ.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYJMUPCONEiD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8465298c-1118-49ae-8406-efa5ba9bb629"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250125_213724-dxyktswv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification/runs/dxyktswv' target=\"_blank\">Longformer-multilabel-dataset_11_120-length1024-batch8x4-epochs5-lr2e-05-fp16-threshold0.2</a></strong> to <a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification' target=\"_blank\">https://wandb.ai/claudelepere-c-cile-cy/skill_classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification/runs/dxyktswv' target=\"_blank\">https://wandb.ai/claudelepere-c-cile-cy/skill_classification/runs/dxyktswv</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "  wandb.init(\n",
        "      project = \"skill_classification\",\n",
        "      name    = run_name,\n",
        "      entity  = \"claudelepere-c-cile-cy\",\n",
        "      config  = {\n",
        "          \"learning_rate\": learning_rate,\n",
        "          \"epochs\"       : 5,\n",
        "          \"batch_size\"   : batch_size\n",
        "      }\n",
        "  )\n",
        "except wandb.errors.CommError as err:\n",
        "  print(f\"CommError: {err}\")\n",
        "except Exception as exc:\n",
        "  print(f\"Exception: {exc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfBhdTN9wcJz"
      },
      "source": [
        "Create the dataset: 3 Hugging Face Dataset in a Hugging Face DatasetDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh_SgQD9wcJz"
      },
      "outputs": [],
      "source": [
        "datasetDict = DatasetDict.load_from_disk(datasetDict_dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcF4Gm8GFNsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05493123-aecc-4f68-bf0e-094da60397dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasetDict: <class 'datasets.dataset_dict.DatasetDict'> {'train': (96, 8), 'validation': (12, 8), 'test': (12, 8)}\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', '390', '135', '136', '137', '138', '139'],\n",
            "        num_rows: 96\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'text', '390', '135', '136', '137', '138', '139'],\n",
            "        num_rows: 12\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'text', '390', '135', '136', '137', '138', '139'],\n",
            "        num_rows: 12\n",
            "    })\n",
            "})\n",
            "datasetDict.keys(): dict_keys(['train', 'validation', 'test'])\n",
            "datasetDict['train']: <class 'datasets.arrow_dataset.Dataset'> (96, 8)\n",
            "datasetDict['validation']: <class 'datasets.arrow_dataset.Dataset'> (12, 8)\n",
            "datasetDict['test']: <class 'datasets.arrow_dataset.Dataset'> (12, 8)\n"
          ]
        }
      ],
      "source": [
        "print(f\"datasetDict: {type(datasetDict)} {datasetDict.shape}\\n{datasetDict}\")\n",
        "print(f\"datasetDict.keys(): {datasetDict.keys()}\")\n",
        "print(f\"datasetDict['train']: {type(datasetDict['train'])} {datasetDict['train'].shape}\")\n",
        "print(f\"datasetDict['validation']: {type(datasetDict['validation'])} {datasetDict['validation'].shape}\")\n",
        "print(f\"datasetDict['test']: {type(datasetDict['test'])} {datasetDict['test'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unjuTtKUjZI3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7169c71-2516-4010-c112-38e7ebfa7845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasetDict['train'][0]: <class 'dict'> dict_keys(['id', 'text', '390', '135', '136', '137', '138', '139'])\n",
            "{'id': 335833, 'text': \"Centric - Full Stack Java Developer Full Stack Java Developer Centric What you do Do you want to dive into multiple technologies and put them to work? Do you have a continuous improvement mindset? Does it give you energy to look for solutions for challenging problems? Answered Yes to these questions? Then you might be the Full Stack developer we are looking for in our team. Job tasks Developing applications on Blue CAP, our internal Cloud Application Platform. You'll be working with technologies like Java & Spring Framework, dockers on OpenShift (= Kubernetes by Red Hat), a fully automated build & deploy pipeline, GIT, continuous releasing, Kibana for log analysis, Prometheus for automated alert management... And you'll be working with a cloud-native development mindset. We also build the front-end for our applications using the Angular framework. How Bluecap works with a DevOps mindset; That means you'll be creating new features while also keeping tabs on the running applications. Occasional bugfixes and interaction with users are part of the job While you quickly fix any bugs that occur, you keep our (internal) users updated through Yammer. Assignments are tackled through the Agile methodology (and supported by Jira). Software is delivered in short iterations (sprints), allowing us to react quickly to new developments. We build high quality software. No feature is “done” until there's test cases for it and it is properly documented What you bring to the team Very good Java experience (full stack) Good experience with Spring Boot framework Knowledge of Hibernate Experienced with Angular framework Experience creating and using Dockers and OpenShift Experienced with Cloud computing Excellent knowledge of the English knowledge Able to work as a freelancer in the region of Brussels\", '390': False, '135': False, '136': False, '137': True, '138': True, '139': False}\n"
          ]
        }
      ],
      "source": [
        "example = datasetDict['train'][0]\n",
        "print(f\"datasetDict['train'][0]: {type(example)} {example.keys()}\\n{example}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEgARWcywcJz"
      },
      "source": [
        "Create the label list and the id2label and label2id mappings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKbNkGo_wcJz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ca79268a-0e08-44d1-f92d-a80b0094f2b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndataset 7_1000_125_125  ,  48 labels\\ndataset 7_128_18_54     ,  42 labels\\ndataset 8910_1087_68_204, 206 labels\\ndataset 11_1000         ,   6 labels\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "\"\"\"\n",
        "dataset 7_1000_125_125  ,  48 labels\n",
        "dataset 7_128_18_54     ,  42 labels\n",
        "dataset 8910_1087_68_204, 206 labels\n",
        "dataset 11_1000         ,   6 labels\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vv6FWVzRwcJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8835b23-b49f-4895-c45a-8764582d92fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels: <class 'list'> 6\n",
            "['135', '136', '137', '138', '139', '390']\n"
          ]
        }
      ],
      "source": [
        "labels = [label for label in datasetDict['train'].features.keys() if label not in ['id', 'text']]\n",
        "labels.sort()\n",
        "print(f\"labels: {type(labels)} {len(labels)}\\n{labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-xKopoHwcJz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ebda5e6-f9f4-489e-b328-e7b08c3238c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id2label: <class 'dict'> 6\n",
            "{0: '135', 1: '136', 2: '137', 3: '138', 4: '139', 5: '390'}\n"
          ]
        }
      ],
      "source": [
        "id2label = {idx: label for idx, label in enumerate(labels)}\n",
        "print(f\"id2label: {type(id2label)} {len(id2label)}\\n{id2label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5eYNbH5FNsd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0f0d0b-b65b-412d-ed4f-403e1643cf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: <class 'dict'> 6\n",
            "{'135': 0, '136': 1, '137': 2, '138': 3, '139': 4, '390': 5}\n"
          ]
        }
      ],
      "source": [
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "print(f\"label2id: {type(label2id)} {len(label2id)}\\n{label2id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_TdBZOGwcJ0"
      },
      "source": [
        "Load tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL1IlzvfwcJ0"
      },
      "outputs": [],
      "source": [
        "model_name = \"allenai/longformer-base-4096\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwKcOR8GwcJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "07fd9f8110d0482cb989d0af0d0e7658",
            "22d182030746416cbe5623db1aebc234",
            "55597f7f18a340929dc73fa18ed907c1",
            "53ee7ff4b7b44e7e9f6580cd073382c7",
            "ae9bb62a3a794fdab4361a43bcbdff5e",
            "9ed5defdeecb412aa485acfdaf51c123",
            "2279a1a9adb94b11be9ef5f57da70800",
            "a5a3b6d02b7e43958e015a7d8ab1c01f",
            "6f0c4b6f400c40fdac2b7eec128c97b2",
            "b0dc8a5c9ce649a79375de80ae9ae790",
            "2ceab4c6a24b4f87b44cc97146206922",
            "8f29314fc1c4459aa030917d08ffe339",
            "c4d1ededdb4e4f5a9f18d7a4b67ff32d",
            "57357093d9a140719572b2a6d4a82370",
            "a015cf63b0b547a0a7327c8ed79652fc",
            "e8f76ff47de34a849f5fa25192529463",
            "355d5edee71b4299b407e96de59d7fa4",
            "f13dc00d241347018dcf4fb379294280",
            "4f1db9010060443a9ab359913e52ba6f",
            "c3572e541cd04c179e75e3da8b27670e",
            "8f38c605c46c44aeb9a1b47846ea27d7",
            "be081775195c47539115a418cecba3d6",
            "830feebbc58243fb9621849be268c784",
            "e2c20087cb9e4832b501577570b73b7d",
            "0e02590af1464a1d8c6a97fe679f4a64",
            "5343842f9a554abeb15347b441ed5859",
            "cd802fd2912d4f8ab77b4bd3bd277840",
            "670f4956a75d41dd9cd03de52a0b7bcd",
            "bbd5fb45104c41ce94d04e3a6bd377bd",
            "3dd7d77e609a4b41bea05ff1393aad17",
            "ea1f364cc6ad4c268c6b8ff9366edfbf",
            "a9154e2043994fd38ac5fd2d77bce100",
            "abb9da3a73174f67bd4e8972bf7c73c9",
            "4f872725a1494aeb859a61d9831177a3",
            "a6e1cde677264cc8a1ece895da46d9bf",
            "6adfcc5bcb5548fe86fb81c0a6af0866",
            "ec45f3eab35c480b89d68742f60e2bc7",
            "573721a88e43454fb91f044dd7a15b0a",
            "5f9fa8c7bfc74ef8bca0f7ce4e9c5d1d",
            "7364598fef634658a0bc6492ed7f198f",
            "8bd6e7ccdab54aa0951c04499116d71f",
            "fa37bb5860c64ec49067990b9c113e2f",
            "92d93085b6dc4745b6fef6e9fb2a6f59",
            "d3ff5366ddee471383941df823ffc3fb"
          ]
        },
        "outputId": "c9dc1d70-eafd-40fb-fb0c-29be8196a16f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07fd9f8110d0482cb989d0af0d0e7658"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f29314fc1c4459aa030917d08ffe339"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "830feebbc58243fb9621849be268c784"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f872725a1494aeb859a61d9831177a3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = LongformerTokenizerFast.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTZ61-RUwcJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "4534e4d3a5d24871b9ae948ca5fdf6d2",
            "947161a4df554ed89216d49d00a70f7b",
            "41fdb4ce5527465ab32ba33695d564ed",
            "2b96210c811f4c2f8f20a03f528ecd70",
            "d5c81e6accb7493a88c1dbdd6cf4b00c",
            "3a66febd2a1e4128a6b6c780b0d3c88a",
            "7d3df09ca2d648ff943a0145811bbe5d",
            "7556e3d45cc240f4bf7c2a38dda37d2d",
            "34fe767096e44ef8901ba6cb8b2c556f",
            "eae6f11d1cbf49929bdd923991d902be",
            "114f2cbc529944818beab308454623cc"
          ]
        },
        "outputId": "8b6025e7-0dfc-4095-9a0c-a9ea7ab86ca1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4534e4d3a5d24871b9ae948ca5fdf6d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = LongformerForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels        = len(labels),\n",
        "#    num_hidden_layers = hidden_layers,\n",
        "    problem_type      = 'multi_label_classification')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-CmoMf9wcJ0"
      },
      "outputs": [],
      "source": [
        "# Configure attention window size\n",
        "model.config.attention_window = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjLO31SssqAM",
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38063ad6-405b-43e4-c659-bf09699f63a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTYt0hM5wcJ0"
      },
      "source": [
        "Tokenize ('input_ids' and 'attention_mask'), add 'global_attention_mask' (for Longformer), add 'labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFWlSsbZaRLc",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def preprocess_data(examples, indices):\n",
        "  # Step 1: Extract text and tokenize\n",
        "  text = examples['text']             # Batch of texts\n",
        "  encoding = tokenizer(\n",
        "      text,                           # Tokenize text\n",
        "      truncation     = True,\n",
        "      padding        = 'max_length',\n",
        "      max_length     = max_length,\n",
        "      return_tensors = 'pt'           # Return PyTorch tensors\n",
        "  )\n",
        "\n",
        "  # Step 2: Create and add the global attention mask\n",
        "  global_attention_mask             = torch.zeros_like(encoding['input_ids'])  # Initialize global attention mask with zeros (same shape as input_ids)\n",
        "  global_attention_mask[:, 0]       = 1                                        # Set global attention on the first token ([CLS], token ID=0) in each sequence\n",
        "  encoding['global_attention_mask'] = global_attention_mask                    # Add the global_attention_mask to the batch\n",
        "\n",
        "  # Step 3: Create and populate the label matrix\n",
        "  labels_matrix = torch.zeros((len(text), len(labels)), dtype=torch.float32)   # Create an empty label matrix\n",
        "  #print(f\"labels_matrix: {type(labels_matrix)} {labels_matrix.shape}\")\n",
        "  #---------Populate label matrix\n",
        "  for idx, label in enumerate(labels):\n",
        "    #print(f\"idx:{idx} label:{label}\")\n",
        "    if label in examples:\n",
        "      labels_matrix[:, idx] = torch.tensor(\n",
        "          [1.0 if val else 0.0 for val in examples[label]],\n",
        "          dtype=torch.float32\n",
        "          )\n",
        "  print(f\"labels_matrix: {type(labels_matrix)} {labels_matrix.shape}\")\n",
        "\n",
        "  encoding['labels'] = labels_matrix                                           # Add labels to the encoding\n",
        "  print(f\"encoding['labels']: {type(encoding['labels'])} {encoding['labels'].shape}\")\n",
        "\n",
        "  # encoding: <class 'transformers.tokenization_utils_base.BatchEncoding'> dict_keys(['input_ids', 'attention_mask', 'global_attention_mask', 'labels'])\n",
        "  #   'input_ids': tensor([[\n",
        "  #   'attention_mask': tensor([[\n",
        "  #   'global_attention_mask': tensor([[\n",
        "  #   'labels': tensor([[\n",
        "  #print(f\"1 preprocess_data call: encoding: {type(encoding)} {encoding.keys()}\")\n",
        "\n",
        "  return encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm9REDT_wcJ0"
      },
      "source": [
        "Create the 3 encoded datasets, train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxLcO0XDwcJ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "065f1e6db6534e90a14b2f8b7eccaff9",
            "fa444a5b3a12484ea6aba8741aa85de5",
            "23c08ae93b2749bbbbd710f111ffdd82",
            "8afdc87aabac4208b3cb678f904d7296",
            "d67f9eacb0ac4a2cb4185ded5b3586d4",
            "41e4f925b69947c1b0d2607eceb55012",
            "394ca2e82f0c4f978d7ae47300405749",
            "8814545d7e9d4857bb13eae7bd591f22",
            "f69c4b809e904fff84ca8b1a8502e552",
            "ae4d1b41f92e4c40a92c3eed43bb011f",
            "8976a9431cf4453fa34ba55391696a6c",
            "e526bbb000154b4dbac396afe1b5434c",
            "c41955b307dd4c3292250e0e46a99832",
            "7e2b1ab896e94f99917ecbadc8fa180c",
            "3cad9da685d6421d8c2a0aa69338e6de",
            "36d1c01038db41bb9103298cbc739dc4",
            "24d75f2b44e5472380ad15cd13a56688",
            "05dfff7b90c6488ba6cb39b32c5f1b9d",
            "5abd2fc2eebe4834beefbd99d3f4fa12",
            "1ee7d97a35eb4a35bca78c85dc7c0be6",
            "b7216409eb1546ef86e72afb1c2974c5",
            "e2fa15918a704d1ab29976e70d241376",
            "c7993144e8874dd6b58a84efee6e8790",
            "a848116e43004fa38e8a709fec15d3ff",
            "36e347699deb4a2c8923aa8c0b74706c",
            "2da18cd5c89c48c2b998489dd80cc0f4",
            "4113da81dbc7468285441758e66aa8ba",
            "a4a77e74d2ad4b008629cfc5fbbbc416",
            "01081396e09b4b7faa4eaf7ca1b1ebfc",
            "125071f4abc446ff9b073ffe8fb53945",
            "28e3908b587d4e5782a6301e621fee9e",
            "40734f4c4a7e4d3da6f4ebaaa0df4cee",
            "7b49d416e01941f0b38aa96849be7340"
          ]
        },
        "outputId": "c6dff458-80d9-44e7-f3e5-29e3e0be4c2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/96 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "065f1e6db6534e90a14b2f8b7eccaff9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_matrix: <class 'torch.Tensor'> torch.Size([96, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([96, 6])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e526bbb000154b4dbac396afe1b5434c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_matrix: <class 'torch.Tensor'> torch.Size([12, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([12, 6])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7993144e8874dd6b58a84efee6e8790"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_matrix: <class 'torch.Tensor'> torch.Size([12, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([12, 6])\n"
          ]
        }
      ],
      "source": [
        "encoded_dataset = datasetDict.map(\n",
        "    preprocess_data,\n",
        "    batched        = True,\n",
        "    remove_columns = datasetDict['train'].column_names,\n",
        "    with_indices   = True\n",
        ")\n",
        "#train_dataset      = encoded_dataset['train']\n",
        "#validation_dataset = encoded_dataset['validation']\n",
        "#test_dataset       = encoded_dataset['test']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2-_oy2YwcJ0"
      },
      "source": [
        "train_labels_list_of_lists = train_dataset['labels'].tolist()\n",
        "print(\"=============================================\")\n",
        "print(f\"encoded_dataset: {type(encoded_dataset)} {encoded_dataset.shape}\\n{encoded_dataset}\")\n",
        "print(f\"train_dataset: {type(train_dataset)} {train_dataset.shape} {train_dataset.features}\\n{train_dataset}\")\n",
        "print(f\"validation_dataset: {type(validation_dataset)} {validation_dataset.shape} {validation_dataset.features}\")\n",
        "print(f\"test_dataset: {type(test_dataset)} {test_dataset.shape} {test_dataset.features}\")\n",
        "print(\"---\")\n",
        "print(f\"train_dataset['labels']: {type(train_dataset['labels'])} len={len(train_dataset['labels'])}\\n{train_dataset['labels']}\")\n",
        "print(\"---\")\n",
        "print(f\"train_dataset[0]['input_ids']: {type(train_dataset[0]['input_ids'])} {len(train_dataset[0]['input_ids'])}\\n{train_dataset['input_ids'][0]}\")\n",
        "print(f\"train_dataset[0]['attention_mask']: {type(train_dataset[0]['attention_mask'])} {len(train_dataset[0]['attention_mask'])}\\n{train_dataset['attention_mask'][0]}\")\n",
        "print(f\"train_dataset[0]['global_attention_mask']: {type(train_dataset[0]['global_attention_mask'])} {len(train_dataset[0]['global_attention_mask'])}\\n{train_dataset['global_attention_mask'][0]}\")\n",
        "print(f\"train_dataset[0]['labels']: {type(train_dataset[0]['labels'])} {len(train_dataset[0]['labels'])} {train_dataset[0]['labels']}\")\n",
        "print(f\"train_dataset['labels'][0]: {type(train_dataset['labels'][0])} {len(train_dataset['labels'][0])}\\n{train_dataset['labels'][0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuft8rJe2Q03",
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b620cbda-5de3-405c-c31d-f0751cf1aad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_tensor: <class 'datasets.arrow_dataset.Dataset'> (96, 4) {'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'global_attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'global_attention_mask', 'labels'],\n",
            "    num_rows: 96\n",
            "})\n",
            "train_dataset_tensor['input_ids']:             <class 'torch.Tensor'>             len=96             shape=torch.Size([96, 1024])            \n",
            "train_dataset_tensor['attention_mask']:        <class 'torch.Tensor'>        len=96        shape=torch.Size([96, 1024])       \n",
            "train_dataset_tensor['global_attention_mask']: <class 'torch.Tensor'> len=96 shape=torch.Size([96, 1024])\n",
            "train_dataset_tensor['labels']:                <class 'torch.Tensor'>                len=96                shape=torch.Size([96, 6])               \n"
          ]
        }
      ],
      "source": [
        "encoded_dataset.set_format('torch')\n",
        "train_dataset      = encoded_dataset['train']\n",
        "validation_dataset = encoded_dataset['validation']\n",
        "test_dataset       = encoded_dataset['test']\n",
        "print(f\"train_dataset_tensor: {type(train_dataset)} {train_dataset.shape} {train_dataset.features}\\n{train_dataset}\")\n",
        "print(f\"train_dataset_tensor['input_ids']:             {type(train_dataset['input_ids'])}             len={len(train_dataset['input_ids'])}             shape={train_dataset['input_ids'].shape}            \") #\\n{train_dataset['input_ids']}\")\n",
        "print(f\"train_dataset_tensor['attention_mask']:        {type(train_dataset['attention_mask'])}        len={len(train_dataset['attention_mask'])}        shape={train_dataset['attention_mask'].shape}       \") #\\n{train_dataset['attention_mask']}\")\n",
        "print(f\"train_dataset_tensor['global_attention_mask']: {type(train_dataset['global_attention_mask'])} len={len(train_dataset['global_attention_mask'])} shape={train_dataset['global_attention_mask'].shape}\") #\\n{train_dataset['global_attention_mask']}\")\n",
        "print(f\"train_dataset_tensor['labels']:                {type(train_dataset['labels'])}                len={len(train_dataset['labels'])}                shape={train_dataset['labels'].shape}               \") #\\n{train_dataset['labels']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynwZnA55wcJ1"
      },
      "source": [
        "Truncated part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brkRdqdjN-Ur",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def get_truncated_part(text):\n",
        "  tokens = tokenizer(\n",
        "      text,\n",
        "      truncation                = True,\n",
        "      padding                   = 'max_length',\n",
        "      max_length                = max_length,\n",
        "      return_overflowing_tokens = True,\n",
        "      return_tensors            = None\n",
        "      )\n",
        "  print(f\"tokens.keys(): {tokens.keys()}\")\n",
        "\n",
        "  # Get the truncated tokens\n",
        "  truncated_ids = tokens[\"input_ids\"][0]\n",
        "  print(f\"truncated_ids: {type(truncated_ids)} {truncated_ids}\")\n",
        "  #overflow_ids  = tokens[\"overflow_to_sample_mapping\"][0]\n",
        "  #print(f\"overflow_ids: {type(overflow_ids)} {overflow_ids}\")\n",
        "\n",
        "  # Decode the tokens back to text\n",
        "  truncated_text = tokenizer.decode(truncated_ids, skip_special_tokens=True)\n",
        "  #overflow_text  = tokenizer.decode(overflow_ids, skip_special_tokens=True)\n",
        "\n",
        "  print(f\"original_text :\\n{text}\")\n",
        "  print(f\"truncated_text:\\n{truncated_text}\")\n",
        "  #print(f\"overflow_text:\\n{overflow_text}\")\n",
        "\n",
        "  original_tokens  = tokenizer.tokenize(text)\n",
        "  truncated_tokens = tokenizer.tokenize(truncated_text)\n",
        "  #overflow_tokens  = tokenizer.tokenize(overflow_text)\n",
        "\n",
        "  print(f\"original_tokens count : {len(original_tokens)}\")\n",
        "  print(f\"truncated_tokens count: {len(truncated_tokens)}\")\n",
        "  #print(f\"overflow_tokens count: {len(overflow_tokens)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD_bjwTfRiQO"
      },
      "outputs": [],
      "source": [
        "example_text = datasetDict['train'][0]['text']\n",
        "#get_truncated_part(example_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFiZ4mYmwcJ1"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    example_text,\n",
        "    truncation     = True,\n",
        "    padding        = 'max_length',\n",
        "    max_length     = max_length,\n",
        "    return_tensors = 'pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUNknGBLwcJ1"
      },
      "source": [
        "inputs: <class 'transformers.tokenization_utils_base.BatchEncoding'> dict_keys(['input_ids', 'attention_mask'])\n",
        "  {'input_ids': tensor([[\n",
        "  'attention_mask': tensor([[\n",
        "print(f\"inputs: {type(inputs)} {inputs.keys()}\") #\\n{inputs}\")\n",
        "print(f\"inputs_ids: {type(inputs.input_ids)} {inputs.input_ids.shape}\\n{inputs.input_ids}\")\n",
        "print(f\"attention_mask: {type(inputs.attention_mask)} {inputs.attention_mask.shape}\\n{inputs.attention_mask}\")\n",
        "print(f\"labels: {inputs.labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTh2E_8iwcJ1"
      },
      "source": [
        "4. Forward pass for multi-label classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_aIPMHuwcJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e98290-5c8c-4f64-bf67-32a2a4986e45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Initializing global attention on CLS token...\n"
          ]
        }
      ],
      "source": [
        "outputs = model(\n",
        "    input_ids      = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxWcnZ8ku12V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb5e34d-7ad7-46b0-963d-922acb585b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs: <class 'transformers.models.longformer.modeling_longformer.LongformerSequenceClassifierOutput'> odict_keys(['logits'])\n",
            "LongformerSequenceClassifierOutput(loss=None, logits=tensor([[ 0.1371,  0.0693,  0.1034,  0.0124, -0.1051, -0.1115]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None, global_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "islk-kFSs0t8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decbcf78-262d-4761-ea23-5993527ad115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: <class 'torch.Tensor'> torch.Size([1, 6])\n",
            "tensor([[ 0.1371,  0.0693,  0.1034,  0.0124, -0.1051, -0.1115]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Logits (= raw model outputs)\n",
        "logits = outputs.logits\n",
        "print(f\"logits: {type(logits)} {logits.shape}\\n{logits}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMscqNTXuY8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7f43f8-ef7b-4910-ee24-388cf3828a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs: <class 'torch.Tensor'> torch.Size([1, 6])\n",
            "tensor([[0.5342, 0.5173, 0.5258, 0.5031, 0.4737, 0.4722]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Convert logits to probabilities\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs   = sigmoid(logits)\n",
        "print(f\"probs: {type(probs)} {probs.shape}\\n{probs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZtO3uQkwcJ2"
      },
      "outputs": [],
      "source": [
        "example = encoded_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0enAb0W9o25W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e9c76d-3f72-408f-ac64-2e69504dbe00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example: <class 'dict'> dict_keys(['input_ids', 'attention_mask', 'global_attention_mask', 'labels'])\n",
            "{'input_ids': tensor([    0, 31230,  4063,  ...,     1,     1,     1]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'global_attention_mask': tensor([1, 0, 0,  ..., 0, 0, 0]), 'labels': tensor([0., 0., 1., 1., 0., 0.])}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"example: {type(example)} {example.keys()}\\n{example}\")\n",
        "print()\n",
        "#print(f\"example['input_ids']: {type(example['input_ids'])} {len(example['input_ids'])}\\n{example['input_ids']}\")\n",
        "#print(f\"example['attention_mask']: {type(example['attention_mask'])} {len(example['attention_mask'])}\\n{example['attention_mask']}\")\n",
        "#print(f\"example['labels']:  {type(example['labels'])} {len(example['labels'])}\\n{example['labels']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0McCtJ8HRJY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "6979044e-c722-4b5c-f014-250ade854d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s>Centric - Full Stack Java Developer Full Stack Java Developer Centric What you do Do you want to dive into multiple technologies and put them to work? Do you have a continuous improvement mindset? Does it give you energy to look for solutions for challenging problems? Answered Yes to these questions? Then you might be the Full Stack developer we are looking for in our team. Job tasks Developing applications on Blue CAP, our internal Cloud Application Platform. You'll be working with technologies like Java & Spring Framework, dockers on OpenShift (= Kubernetes by Red Hat), a fully automated build & deploy pipeline, GIT, continuous releasing, Kibana for log analysis, Prometheus for automated alert management... And you'll be working with a cloud-native development mindset. We also build the front-end for our applications using the Angular framework. How Bluecap works with a DevOps mindset; That means you'll be creating new features while also keeping tabs on the running applications. Occasional bugfixes and interaction with users are part of the job While you quickly fix any bugs that occur, you keep our (internal) users updated through Yammer. Assignments are tackled through the Agile methodology (and supported by Jira). Software is delivered in short iterations (sprints), allowing us to react quickly to new developments. We build high quality software. No feature is “done” until there's test cases for it and it is properly documented What you bring to the team Very good Java experience (full stack) Good experience with Spring Boot framework Knowledge of Hibernate Experienced with Angular framework Experience creating and using Dockers and OpenShift Experienced with Cloud computing Excellent knowledge of the English knowledge Able to work as a freelancer in the region of Brussels</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "tokenizer.decode(example['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LAyThO7Jnvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441602a2-87e7-45f2-ef23-2acdcf564657"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['137', '138']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHCJcLKGwcJ2"
      },
      "source": [
        "Set PyTorch format to ensures correctness and compatibility with PyTorch pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4ENBTdulBEI"
      },
      "outputs": [],
      "source": [
        "# The 3 Hugging Face Dataset are formatted as PyTorch Dataset\n",
        "encoded_dataset.set_format('torch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5a8_vIKqr7P"
      },
      "outputs": [],
      "source": [
        "batch_size  = batch_size\n",
        "metric_name = \"f1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR2GmpvDqbuZ",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir                  = './training_results',  # where model predictions and checkpoints will be written during training\n",
        "    overwrite_output_dir        = True,\n",
        "    logging_dir                 = './logs',\n",
        "    logging_steps               = 50,\n",
        "    save_steps                  = 500,\n",
        "    save_total_limit            = 2,\n",
        "    eval_strategy               = 'epoch',\n",
        "    save_strategy               = 'epoch',\n",
        "    learning_rate               = learning_rate,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size  = batch_size,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "    num_train_epochs            = epochs,\n",
        "    weight_decay                = 0.01,\n",
        "    load_best_model_at_end      = True,\n",
        "    metric_for_best_model       = metric_name,\n",
        "    run_name                    = run_name,\n",
        "    fp16                        = fp16,\n",
        "    #dataloader_num_workers      = dataloader_num_workers,\n",
        "    report_to                  = 'wandb'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Zt-m0QpwcJ3"
      },
      "source": [
        "Metrics\n",
        "  source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LaQCQoJFNsi",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def multi_label_metrics(logits, true_labels):\n",
        "  \"\"\"\n",
        "  logits => sigmoid => probabilities => predictions\n",
        "\n",
        "  Args:\n",
        "    logits     : raw, unnormalized scores outputted by the model  (numpy array of shape (batch_size, num_labels))\n",
        "    true_labels: actual labels for the data                       (numpy array of shape (batch_size, num_labels))\n",
        "\n",
        "  Returns:\n",
        "    metrics: dictionary of scores\n",
        "  \"\"\"\n",
        "  average = 'micro'    # 'micro' or 'weighted'\n",
        "\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  probs   = sigmoid(torch.Tensor(logits))\n",
        "  # next, use threshold to turn them into integer predictions\n",
        "  preds = np.zeros(probs.shape)\n",
        "  preds[np.where(probs > threshold)] = 1\n",
        "\n",
        "  # compute metrics\n",
        "  f1                   = f1_score               (y_true=true_labels, y_pred=preds,  average=average)    #, zero_division=1)\n",
        "  precision            = precision_score        (y_true=true_labels, y_pred=preds,  average=average)    #, zero_division=1)\n",
        "  recall               = recall_score           (y_true=true_labels, y_pred=preds,  average=average)    #, zero_division=1)\n",
        "  roc_auc              = roc_auc_score          (y_true=true_labels, y_score=probs, average=average)\n",
        "  precision_recall_auc = average_precision_score(y_true=true_labels, y_score=probs, average=average)\n",
        "  accuracy             = accuracy_score         (y_true=true_labels, y_pred=preds)\n",
        "\n",
        "  metrics = {\n",
        "\n",
        "      'f1'                  : f1,\n",
        "      'precision'           : precision,\n",
        "      'recall'              : recall,\n",
        "      'roc_auc'             : roc_auc,\n",
        "      'precision_recall_auc': precision_recall_auc,\n",
        "      'accuracy'            : accuracy\n",
        "  }\n",
        "\n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "797b2WHJqUgZ",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "  result = multi_label_metrics(logits=preds,true_labels=p.label_ids)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STMWGSJDwcJ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6438928a-fe7c-4128-a199-21e32eea391d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Let's verify a batch as well as a forward pass:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "\"\"\"Let's verify a batch as well as a forward pass:\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adTwB7XvFNsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79aca7ed-3645-401f-bd1b-7e3d33949b03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids:              <class 'torch.Tensor'>\ttorch.Size([1024])\n",
            "attention_mask:         <class 'torch.Tensor'>\ttorch.Size([1024])\n",
            "global_attention_mask:  <class 'torch.Tensor'>\ttorch.Size([1024])\n",
            "labels:                 <class 'torch.Tensor'>\ttorch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "print(f\"input_ids:              {type(encoded_dataset['train']['input_ids'][0])}\\t{encoded_dataset['train']['input_ids'][0].shape}\")\n",
        "print(f\"attention_mask:         {type(encoded_dataset['train']['attention_mask'][0])}\\t{encoded_dataset['train']['attention_mask'][0].shape}\")\n",
        "print(f\"global_attention_mask:  {type(encoded_dataset['train']['global_attention_mask'][0])}\\t{encoded_dataset['train']['global_attention_mask'][0].shape}\")\n",
        "print(f\"labels:                 {type(encoded_dataset['train'][0]['labels'])}\\t{encoded_dataset['train'][0]['labels'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCGdbfNJwcJ4"
      },
      "source": [
        "Execute a forward pass for debugging or verification purposes (cf. BERT_3_1 in Notion BERT database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN-sEDggwcJ4"
      },
      "outputs": [],
      "source": [
        "outputs = model(\n",
        "    input_ids      = encoded_dataset['train']['input_ids'][0].unsqueeze(0),\n",
        "    attention_mask = encoded_dataset['train']['attention_mask'][0].unsqueeze(0),\n",
        "    labels         = encoded_dataset['train'][0]['labels'].unsqueeze(0)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtEd6KmRwcJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e06e4b0-7a4b-430d-d28f-ce6a8a0482f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs: <class 'transformers.models.longformer.modeling_longformer.LongformerSequenceClassifierOutput'> odict_keys(['loss', 'logits'])\n",
            "LongformerSequenceClassifierOutput(loss=tensor(0.6839, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.1371,  0.0693,  0.1034,  0.0124, -0.1051, -0.1115]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None, global_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "vqxhHkT1wcJ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1554ce69-d8cc-4f05-de04-942085162dd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Define the weighted loss function\\n\\nclass_weights = torch.tensor([7.68, 2.15, 0.61, 0.47, 0.68, 6.26], dtype=torch.float32).to(device)\\nloss_fn       = BCEWithLogitsLoss(pos_weight=class_weights)  # For multi-label classification (binary classification per label)\\n\\n## Class supports, class weigths, weighted loss function\\n\\nReminder:\\n*   df_jobs      : <class \\'pandas.core.frame.DataFrame\\'>\\n*   df_jobs[\\'id\\']: <class \\'pandas.core.series.Series\\'>\\n\\ndataset = Dataset.from_pandas(df_jobs)\\n*   dataset      : <class \\'datasets.arrow_dataset.Dataset\\'>\\n*   dataset[\\'id\\']: <class \\'list\\'>\\n\\n*   dataset_dict_jobs : <class \\'datasets.dataset_dict.DatasetDict\\'>\\n*   train_dataset     : <class \\'datasets.arrow_dataset.Dataset\\'>\\n*   validation_dataset: <class \\'datasets.arrow_dataset.Dataset\\'>\\n*   test_dataset      : <class \\'datasets.arrow_dataset.Dataset\\'>\\n\\n\\nWe calculate the class supports for the train, validation and test datasets; the class weights and the weighted loss function are used for training only; the class supports of validation_dataset and test_dataset are calculated for information only.\\n\\ndef get_train_class_weights(datasetDict, labels):\\n  print(f\"datasetDict: {type(datasetDict)} shape={datasetDict.shape}\\n{datasetDict}\")\\n  print(f\"labels: {type(labels)} len={len(labels)}\\n{labels}\")\\n\\n  dataset_train      = datasetDict[\\'train\\']\\n  dataset_validation = datasetDict[\\'validation\\']\\n  dataset_test       = datasetDict[\\'test\\']\\n\\n  def calculate_class_supports(dataset, labels):\\n    class_supports = dataset.map(\\n        lambda example: {col: example[col] for col in labels},\\n        batched=True\\n    ).to_pandas()[labels].sum(axis=0)\\n    return class_supports\\n\\n  class_supports = {}\\n\\n  for split_name, split_dataset in datasetDict.items():\\n    class_supports[split_name] = calculate_class_supports(split_dataset, labels)\\n\\n  for split_name, split_class_supports in class_supports.items():\\n    print(f\"{split_name}: {type(split_class_supports)} len={len(split_class_supports)}\\n{split_class_supports}\")\\n\\n  train_class_supports_list = class_supports[\\'train\\'].tolist()\\n  print(f\"train_class_supports_list: {type(train_class_supports_list)} len={len(train_class_supports_list)} {train_class_supports_list}\")\\n\\n  train_class_supports_tensor = torch.tensor(train_class_supports_list, dtype=torch.float32)\\n  print(f\"train_class_supports_tensor: {type(train_class_supports_tensor)} len={len(train_class_supports_tensor)} {train_class_supports_tensor}\")\\n\\n  train_total_samples = dataset_train.num_rows\\n  print(f\"train_total_samples: {train_total_samples}\")\\n\\n  number_of_classes = len(labels)\\n  print(f\"number_of_classes: {number_of_classes}\")\\n\\n  train_class_weights = train_total_samples / (number_of_classes * train_class_supports_tensor)\\n  print(f\"train_class_weights: {type(train_class_weights)} len={len(train_class_weights)} {train_class_weights}\")\\n\\n  train_class_weights_sum = train_class_weights.sum()\\n  print(f\"train_class_weights_sum: {train_class_weights_sum}\")\\n\\n  normalized_train_class_weights = (train_class_weights / train_class_weights_sum) * number_of_classes\\n  print(f\"normalized_train_class_weights: {type(normalized_train_class_weights)} len={len(normalized_train_class_weights)} {normalized_train_class_weights}\")\\n\\n  # Positives samples per label\\n  supports = train_class_supports_tensor\\n  print(f\"supports: {type(supports)} {len(supports)} {supports}\")\\n\\n  # Negatives samples per label\\n  negatives = train_total_samples - supports\\n  print(f\"negatives: {type(negatives)} {len(negatives)} {negatives}\")\\n\\n  # pos_weights = negative to positive ratios\\n  pos_weights = negatives/supports\\n  print(f\"pos_weights: {type(pos_weights)} {len(pos_weights)} {pos_weights}\")\\n\\n  # Normalize using min-max scaling\\n  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\\n  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\\n\\n  # Normalize using z-score standardization\\n  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\\n  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\\n\\n  # Normalize using min-max scaling\\n  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\\n  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\\n\\n  # Normalize using z-score standardization\\n  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\\n  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\\n\\n  # Normalize using sum-to-one\\n  normalized_pos_weights_sum1 = pos_weights / pos_weights.sum()\\n  print(f\"normalized_pos_weights_sum1: {type(normalized_pos_weights_sum1)} {len(normalized_pos_weights_sum1)} {normalized_pos_weights_sum1}\")\\n\\n  return normalized_pos_weights_minmax\\n  #return normalized_pos_weights_zscore\\n  #return normalized_pos_weights_sum1\\n\\npos_weights = get_train_class_weights(datasetDict, labels)\\n\\nloss_fn = BCEWithLogitsLoss(pos_weight=pos_weights.to(device))  # For multi-label classification (binary classification per label)\\nprint(f\"loss_fn: {type(loss_fn)} {loss_fn}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "\"\"\"# Define the weighted loss function\n",
        "\n",
        "class_weights = torch.tensor([7.68, 2.15, 0.61, 0.47, 0.68, 6.26], dtype=torch.float32).to(device)\n",
        "loss_fn       = BCEWithLogitsLoss(pos_weight=class_weights)  # For multi-label classification (binary classification per label)\n",
        "\n",
        "## Class supports, class weigths, weighted loss function\n",
        "\n",
        "Reminder:\n",
        "*   df_jobs      : <class 'pandas.core.frame.DataFrame'>\n",
        "*   df_jobs['id']: <class 'pandas.core.series.Series'>\n",
        "\n",
        "dataset = Dataset.from_pandas(df_jobs)\n",
        "*   dataset      : <class 'datasets.arrow_dataset.Dataset'>\n",
        "*   dataset['id']: <class 'list'>\n",
        "\n",
        "*   dataset_dict_jobs : <class 'datasets.dataset_dict.DatasetDict'>\n",
        "*   train_dataset     : <class 'datasets.arrow_dataset.Dataset'>\n",
        "*   validation_dataset: <class 'datasets.arrow_dataset.Dataset'>\n",
        "*   test_dataset      : <class 'datasets.arrow_dataset.Dataset'>\n",
        "\n",
        "\n",
        "We calculate the class supports for the train, validation and test datasets; the class weights and the weighted loss function are used for training only; the class supports of validation_dataset and test_dataset are calculated for information only.\n",
        "\n",
        "def get_train_class_weights(datasetDict, labels):\n",
        "  print(f\"datasetDict: {type(datasetDict)} shape={datasetDict.shape}\\n{datasetDict}\")\n",
        "  print(f\"labels: {type(labels)} len={len(labels)}\\n{labels}\")\n",
        "\n",
        "  dataset_train      = datasetDict['train']\n",
        "  dataset_validation = datasetDict['validation']\n",
        "  dataset_test       = datasetDict['test']\n",
        "\n",
        "  def calculate_class_supports(dataset, labels):\n",
        "    class_supports = dataset.map(\n",
        "        lambda example: {col: example[col] for col in labels},\n",
        "        batched=True\n",
        "    ).to_pandas()[labels].sum(axis=0)\n",
        "    return class_supports\n",
        "\n",
        "  class_supports = {}\n",
        "\n",
        "  for split_name, split_dataset in datasetDict.items():\n",
        "    class_supports[split_name] = calculate_class_supports(split_dataset, labels)\n",
        "\n",
        "  for split_name, split_class_supports in class_supports.items():\n",
        "    print(f\"{split_name}: {type(split_class_supports)} len={len(split_class_supports)}\\n{split_class_supports}\")\n",
        "\n",
        "  train_class_supports_list = class_supports['train'].tolist()\n",
        "  print(f\"train_class_supports_list: {type(train_class_supports_list)} len={len(train_class_supports_list)} {train_class_supports_list}\")\n",
        "\n",
        "  train_class_supports_tensor = torch.tensor(train_class_supports_list, dtype=torch.float32)\n",
        "  print(f\"train_class_supports_tensor: {type(train_class_supports_tensor)} len={len(train_class_supports_tensor)} {train_class_supports_tensor}\")\n",
        "\n",
        "  train_total_samples = dataset_train.num_rows\n",
        "  print(f\"train_total_samples: {train_total_samples}\")\n",
        "\n",
        "  number_of_classes = len(labels)\n",
        "  print(f\"number_of_classes: {number_of_classes}\")\n",
        "\n",
        "  train_class_weights = train_total_samples / (number_of_classes * train_class_supports_tensor)\n",
        "  print(f\"train_class_weights: {type(train_class_weights)} len={len(train_class_weights)} {train_class_weights}\")\n",
        "\n",
        "  train_class_weights_sum = train_class_weights.sum()\n",
        "  print(f\"train_class_weights_sum: {train_class_weights_sum}\")\n",
        "\n",
        "  normalized_train_class_weights = (train_class_weights / train_class_weights_sum) * number_of_classes\n",
        "  print(f\"normalized_train_class_weights: {type(normalized_train_class_weights)} len={len(normalized_train_class_weights)} {normalized_train_class_weights}\")\n",
        "\n",
        "  # Positives samples per label\n",
        "  supports = train_class_supports_tensor\n",
        "  print(f\"supports: {type(supports)} {len(supports)} {supports}\")\n",
        "\n",
        "  # Negatives samples per label\n",
        "  negatives = train_total_samples - supports\n",
        "  print(f\"negatives: {type(negatives)} {len(negatives)} {negatives}\")\n",
        "\n",
        "  # pos_weights = negative to positive ratios\n",
        "  pos_weights = negatives/supports\n",
        "  print(f\"pos_weights: {type(pos_weights)} {len(pos_weights)} {pos_weights}\")\n",
        "\n",
        "  # Normalize using min-max scaling\n",
        "  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\n",
        "  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\n",
        "\n",
        "  # Normalize using z-score standardization\n",
        "  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\n",
        "  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\n",
        "\n",
        "  # Normalize using min-max scaling\n",
        "  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\n",
        "  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\n",
        "\n",
        "  # Normalize using z-score standardization\n",
        "  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\n",
        "  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\n",
        "\n",
        "  # Normalize using sum-to-one\n",
        "  normalized_pos_weights_sum1 = pos_weights / pos_weights.sum()\n",
        "  print(f\"normalized_pos_weights_sum1: {type(normalized_pos_weights_sum1)} {len(normalized_pos_weights_sum1)} {normalized_pos_weights_sum1}\")\n",
        "\n",
        "  return normalized_pos_weights_minmax\n",
        "  #return normalized_pos_weights_zscore\n",
        "  #return normalized_pos_weights_sum1\n",
        "\n",
        "pos_weights = get_train_class_weights(datasetDict, labels)\n",
        "\n",
        "loss_fn = BCEWithLogitsLoss(pos_weight=pos_weights.to(device))  # For multi-label classification (binary classification per label)\n",
        "print(f\"loss_fn: {type(loss_fn)} {loss_fn}\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "YqMipSpowcJ5"
      },
      "outputs": [],
      "source": [
        "def get_class_weights(labels=encoded_dataset['train']['labels']):\n",
        "  print(f\"labels: {type(labels)} len={len(labels)} shape={labels.shape}\\n{labels}\")\n",
        "\n",
        "  num_samples, num_labels = labels.shape\n",
        "  print(f\"num_samples: {type(num_samples)} {num_samples}\")\n",
        "  print(f\"num_labels:  {type(num_labels)}  {num_labels}\")\n",
        "\n",
        "  class_counts = labels.sum(dim=0)\n",
        "  print(f\"class_counts: {type(class_counts)} len={len(class_counts)}\\n{class_counts}\")\n",
        "\n",
        "  pos_weights = (num_samples-class_counts) / class_counts\n",
        "  print(f\"pos_weights: {type(pos_weights)} len={len(pos_weights)}\\n{pos_weights}\")\n",
        "\n",
        "  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\n",
        "  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\n",
        "\n",
        "  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\n",
        "  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\n",
        "\n",
        "  normalized_pos_weights_sum1 = pos_weights / pos_weights.sum()\n",
        "  print(f\"normalized_pos_weights_sum1: {type(normalized_pos_weights_sum1)} {len(normalized_pos_weights_sum1)} {normalized_pos_weights_sum1}\")\n",
        "\n",
        "  #return pos_weights\n",
        "  #return normalized_pos_weights_minmax\n",
        "  #return normalized_pos_weights_zscore\n",
        "  return normalized_pos_weights_sum1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bh-gAHGwcJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bc9a1eb-7710-4ca5-999c-1a860b60f3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels: <class 'torch.Tensor'> len=96 shape=torch.Size([96, 6])\n",
            "tensor([[0., 0., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 1., 1., 0., 0., 1.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 1.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 1., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 1., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 1., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 1., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 1., 0.]])\n",
            "num_samples: <class 'int'> 96\n",
            "num_labels:  <class 'int'>  6\n",
            "class_counts: <class 'torch.Tensor'> len=6\n",
            "tensor([ 3.,  9., 53., 86., 63.,  3.])\n",
            "pos_weights: <class 'torch.Tensor'> len=6\n",
            "tensor([31.0000,  9.6667,  0.8113,  0.1163,  0.5238, 31.0000])\n",
            "normalized_pos_weights_minmax: <class 'torch.Tensor'> 6 tensor([1.0000, 0.3092, 0.0225, 0.0000, 0.0132, 1.0000])\n",
            "normalized_pos_weights_zscore: <class 'torch.Tensor'> 6 tensor([ 1.2540, -0.1680, -0.7582, -0.8045, -0.7774,  1.2540])\n",
            "normalized_pos_weights_sum1: <class 'torch.Tensor'> 6 tensor([0.4240, 0.1322, 0.0111, 0.0016, 0.0072, 0.4240])\n"
          ]
        }
      ],
      "source": [
        "pos_weights = get_class_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "4d36Km6_wcJ5"
      },
      "outputs": [],
      "source": [
        "loss_fn = BCEWithLogitsLoss(pos_weight=pos_weights.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbAeCoewcJ5"
      },
      "source": [
        "raise Exception(\"Stop here\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "OPRpdL8fwcJ5"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(Module):\n",
        "  \"\"\"\n",
        "  Focal Loss implementation\n",
        "  \"\"\"\n",
        "  def __init__(self, alpha=1.0, gamma=2.0, logits=False, reduce=True):\n",
        "    super(FocalLoss, self).__init__()\n",
        "    self.alpha   = alpha\n",
        "    self.gamma   = gamma\n",
        "    self.logits  = logits  # This flag is to indicate whether input is logits or probability\n",
        "    self.reduce  = reduce\n",
        "\n",
        "  # inputs  = model's predictions: PyTorch tensor, shape=(batch_size, num_classes)\n",
        "  # targets = ground truth labels: PyTorch tensor, shape=same as inputs shape\n",
        "  def forward(self, inputs, targets):\n",
        "    # Here, we check if input is probability or logits\n",
        "    if self.logits:\n",
        "      # Input is logits\n",
        "      BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "    else:\n",
        "      # Input is probability\n",
        "      BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
        "    pt = torch.exp(-BCE_loss)\n",
        "    F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "    if self.reduce:\n",
        "      return torch.mean(F_loss)\n",
        "    else:\n",
        "      return F_loss\n",
        "\n",
        "  def __repr__(self):\n",
        "    return f\"FocalLoss(alpha={self.alpha}, gamma={self.gamma}, logits={self.logits}, reduce={self.reduce})\"\n",
        "\n",
        "  def __str__(self):\n",
        "    return f\"FocalLoss(alpha={self.alpha}, gamma={self.gamma}, logits={self.logits}, reduce={self.reduce})\"\n",
        "\n",
        "  def __call__(self, inputs, targets):\n",
        "    return self.forward(inputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zknwQWsEb7oP",
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aad3fd1-c7f3-4275-dc15-073e9879c7b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "focal_loss_fn: <class '__main__.FocalLoss'> FocalLoss(alpha=0.5, gamma=4.0, logits=True, reduce=True)\n"
          ]
        }
      ],
      "source": [
        "focal_loss_fn = FocalLoss(alpha=0.5, gamma=4.0, logits=True, reduce=True)\n",
        "print(f\"focal_loss_fn: {type(focal_loss_fn)} {focal_loss_fn}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CpbfGBwwcJ5"
      },
      "source": [
        "CustomTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isb6aMV2bWJ8",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "\n",
        "  def __init__(self, *args, loss_fn=None, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.loss_fn = loss_fn\n",
        "\n",
        "  \"\"\"\n",
        "  # No print in compute_loss because out of memory because prints are batch per batch\n",
        "  def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "\n",
        "    #print(f\"inputs passed to compute_loss: {inputs.keys()}\")\n",
        "    #input_ids             = inputs['input_ids']                        # shape: batch_size, sequence_length\n",
        "    #attention_mask        = inputs['attention_mask']                   # shape: batch_size, sequence_length\n",
        "    #global_attention_mask = inputs.get('global_attention_mask', None)  # shape: batch_size, sequence_length; optional as LongFormer specific\n",
        "    labels                = inputs.pop('labels', None)                 # shape: batch_size, num_labels; needed for loss computation, not required by the model\n",
        "\n",
        "    #outputs = model(**inputs, global_attention_mask=global_attention_mask)  # Forward pass\n",
        "    # Forward pass\n",
        "    #outputs = model(\n",
        "    #    input_ids             = input_ids,\n",
        "    #    attention_mask        = attention_mask,\n",
        "    #    global_attention_mask = global_attention_mask,\n",
        "    #    labels                = labels\n",
        "    #)\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    #print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")\n",
        "    logits = outputs.logits  # shape: (batch_size, num_labels)\n",
        "\n",
        "    # If labels are provided, compute loss\n",
        "    if labels is not None:\n",
        "      # Use the custom loss function if provided\n",
        "      if self.loss_fn is not None:\n",
        "        loss = self.loss_fn(logits, labels)  # Compute weighted loss\n",
        "      else:\n",
        "        # Default loss: BCEWithLogitsLoss\n",
        "        loss_fn = BCEWithLogitsLoss()\n",
        "        loss    = loss_fn(logits, labels)    # Compute loss\n",
        "      return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    # If no labels, return outputs only, for evaluation or inference\n",
        "    return outputs\n",
        "    \"\"\"\n",
        "  def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "    labels  = inputs.pop('labels', None)\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    logits  = outputs.logits\n",
        "\n",
        "    if labels is not None:\n",
        "      if self.loss_fn is not None:\n",
        "        loss = self.loss_fn(logits, labels)\n",
        "      else:\n",
        "        loss_fn = BCEWithLogitsLoss()\n",
        "        loss    = loss_fn(logits, labels)\n",
        "      return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2elPEoowcJ6"
      },
      "source": [
        "Create a Hugging Face's transformers trainer (which abstracts the training loop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chq_3nUz73ib"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "trainer = CustomTrainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    train_dataset   = encoded_dataset[\"train\"],\n",
        "    eval_dataset    = encoded_dataset[\"validation\"],\n",
        "    compute_metrics = compute_metrics,                # Optional: custom metrics function\n",
        "    loss_fn         = focal_loss_fn,\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "trainer = Trainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    train_dataset   = encoded_dataset[\"train\"],\n",
        "    eval_dataset    = encoded_dataset[\"validation\"],\n",
        "    compute_metrics = compute_metrics,                # Optional: custom metrics function\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy7jlzubwcJ6"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "predictions_output: <class 'transformers.trainer_utils.PredictionOutput'> len=3:\n",
        "- predictions: np.ndarray          raw model outputs = logits\n",
        "- label_ids  : np.ndarray or None: true labels corresponding to the predictions, if available\n",
        "- metrics    : dict              : metrics computed during prediction step\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "predictions_output = trainer.predict(test_dataset)\n",
        "print(f\"predictions_output: {type(predictions_output)} len={len(predictions_output)}\\n{predictions_output}\")  # <class 'transformers.trainer_utils.PredictionOutput'> len=3\n",
        "logits = predictions_output.predictions\n",
        "print(f\"logits: {type(logits)} len={len(logits)} shape={logits.shape}\\n{logits}\")\n",
        "\n",
        "\n",
        "raise Exception(\"I'm here\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cVs8D9geXHqK",
        "outputId": "ec5dd896-91a7-4af4-8c20-a1b6d4a7b556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions_output: <class 'transformers.trainer_utils.PredictionOutput'> len=3\n",
            "PredictionOutput(predictions=array([[ 0.08431626,  0.13837406,  0.06834591, -0.01528215, -0.07136969,\n",
            "        -0.0829616 ],\n",
            "       [ 0.13858847,  0.07530968,  0.1049381 ,  0.00214297, -0.10017487,\n",
            "        -0.08596286],\n",
            "       [ 0.11209582,  0.08112872,  0.10707777,  0.00695259, -0.10099337,\n",
            "        -0.0954905 ],\n",
            "       [ 0.12880123,  0.06931554,  0.10318145, -0.0028471 , -0.09585442,\n",
            "        -0.11382724],\n",
            "       [ 0.1309944 ,  0.06708381,  0.09466859,  0.00361897, -0.09376115,\n",
            "        -0.10096277],\n",
            "       [ 0.09766711,  0.07702871,  0.11392777, -0.00147916, -0.08229625,\n",
            "        -0.10746085],\n",
            "       [ 0.13434936,  0.06367508,  0.10389383,  0.00602324, -0.10260259,\n",
            "        -0.09177059],\n",
            "       [ 0.1069045 ,  0.06728075,  0.10263138,  0.00079291, -0.09848891,\n",
            "        -0.1001168 ],\n",
            "       [ 0.11659762,  0.08612563,  0.1114157 , -0.00528597, -0.09730304,\n",
            "        -0.10845746],\n",
            "       [ 0.12104946,  0.06438444,  0.11447793, -0.00210956, -0.08654015,\n",
            "        -0.10733641],\n",
            "       [ 0.13354942,  0.07321818,  0.09602703,  0.01064792, -0.10122345,\n",
            "        -0.10036404],\n",
            "       [ 0.11116137,  0.25119007,  0.23452409,  0.12013806, -0.07164931,\n",
            "        -0.09973892]], dtype=float32), label_ids=array([[0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 1., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 1., 1., 0., 0.],\n",
            "       [0., 0., 0., 0., 1., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.],\n",
            "       [0., 0., 1., 1., 0., 0.],\n",
            "       [0., 0., 0., 1., 1., 0.]], dtype=float32), metrics={'test_loss': 0.7114145159721375, 'test_model_preparation_time': 0.0098, 'test_f1': 0.4842105263157895, 'test_precision': 0.3194444444444444, 'test_recall': 1.0, 'test_roc_auc': 0.3469387755102041, 'test_precision_recall_auc': 0.24808824535412663, 'test_accuracy': 0.0, 'test_runtime': 102.3606, 'test_samples_per_second': 0.117, 'test_steps_per_second': 0.02})\n",
            "logits: <class 'numpy.ndarray'> len=12\n",
            "[[ 0.08431626  0.13837406  0.06834591 -0.01528215 -0.07136969 -0.0829616 ]\n",
            " [ 0.13858847  0.07530968  0.1049381   0.00214297 -0.10017487 -0.08596286]\n",
            " [ 0.11209582  0.08112872  0.10707777  0.00695259 -0.10099337 -0.0954905 ]\n",
            " [ 0.12880123  0.06931554  0.10318145 -0.0028471  -0.09585442 -0.11382724]\n",
            " [ 0.1309944   0.06708381  0.09466859  0.00361897 -0.09376115 -0.10096277]\n",
            " [ 0.09766711  0.07702871  0.11392777 -0.00147916 -0.08229625 -0.10746085]\n",
            " [ 0.13434936  0.06367508  0.10389383  0.00602324 -0.10260259 -0.09177059]\n",
            " [ 0.1069045   0.06728075  0.10263138  0.00079291 -0.09848891 -0.1001168 ]\n",
            " [ 0.11659762  0.08612563  0.1114157  -0.00528597 -0.09730304 -0.10845746]\n",
            " [ 0.12104946  0.06438444  0.11447793 -0.00210956 -0.08654015 -0.10733641]\n",
            " [ 0.13354942  0.07321818  0.09602703  0.01064792 -0.10122345 -0.10036404]\n",
            " [ 0.11116137  0.25119007  0.23452409  0.12013806 -0.07164931 -0.09973892]]\n",
            "logits: (12, 6)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "I'm here",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-1946a50faf2f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#rint(f\"predictions_output: {predictions_output.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"logits: {logits.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I'm here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mException\u001b[0m: I'm here"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V_k5uxpKwcJ6"
      },
      "outputs": [],
      "source": [
        "trainer_train = trainer.train()\n",
        "print(f\"trainer_train: {type(trainer_train)} len={len(trainer_train)}\\n{trainer_train}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvhT1c_h_oul"
      },
      "outputs": [],
      "source": [
        "file_path = \"trainer_train.json\"\n",
        "with open(file_path, \"w\") as f:\n",
        "  json.dump(trainer_train, f)\n",
        "print(f\"Train output successfully saved to {file_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2SMR-lI8Y8r"
      },
      "outputs": [],
      "source": [
        "print(\"Training successfully completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzSkwPcXwcJ6"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Upload model, tokenizer, train results, evaluate results\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVQXo7SvwcJ7"
      },
      "source": [
        "Upload the tokenizer and the model to the Hugging Face Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSAz3pspFNsm"
      },
      "outputs": [],
      "source": [
        "# Push the tokenizer and the model\n",
        "tokenizer.push_to_hub(repo_id_model)\n",
        "model.push_to_hub(repo_id_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the Upload"
      ],
      "metadata": {
        "id": "T3W9-Xdo_egG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tokenizer and the model from the Hugging Face Hub\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(repo_id_model)\n",
        "model     = LongformerForSequenceClassification.from_pretrained(repo_id_model)\n",
        "\n",
        "# Test the tokenizer and the model\n",
        "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\", truncation=True, padding=True)\n",
        "outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "Vrs9lNbS-uh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd6B9IXFwcJ7"
      },
      "source": [
        "Upload Train results to HF repo_id_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCxHpgmT5meA"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "upload_file(\n",
        "    path_or_fileobj = 'trainer_train.json',\n",
        "    path_in_repo    = 'trainer_train.json',\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "lines_to_next_cell": 1,
        "id": "W3tCujNQwcJ7"
      },
      "outputs": [],
      "source": [
        "\"\"\"To Get Results of Evaluation and Test\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS9EbjVmVpjg",
        "lines_to_next_cell": 1
      },
      "outputs": [],
      "source": [
        "def get_results(model, dataset, batch_size, threshold, phase):\n",
        "  # Clear GPU cache\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # Set the model to evaluation mode to disable dropout and other training-specific behaviors\n",
        "  model.eval()\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "\n",
        "  dataLoader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  all_preds       = []\n",
        "  all_probs       = []\n",
        "  all_true_labels = []\n",
        "\n",
        "  for batch in tqdm(dataLoader):\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**batch)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Convert logits to probabilities and probabilities to predictions\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs   = sigmoid(logits).cpu().numpy()    # Convert to Numpy\n",
        "    preds   = (probs > threshold).astype(int)  # Convert to binary Numpy array; convert the boolean result to int (0 or 1)\n",
        "\n",
        "    # Accumulate probabilities, predictions and labels\n",
        "    all_probs.append(probs)\n",
        "    all_preds.append(preds)\n",
        "    all_true_labels.append(batch['labels'].cpu().numpy())\n",
        "\n",
        "  # Concatenate results from all batches\n",
        "  all_probs       = np.concatenate(all_probs, axis=0)        # shape: [num_samples, num_labels]\n",
        "  all_preds       = np.concatenate(all_preds, axis=0)        # shape: [num_samples, num_labels]\n",
        "  all_true_labels = np.concatenate(all_true_labels, axis=0)  # shape: [num_samples, num_labels]\n",
        "\n",
        "  print(f\"all_probs:       {type(all_probs)} {all_probs.shape}\")\n",
        "  print(f\"all_preds:       {type(all_preds)} {all_preds.shape}\")\n",
        "  print(f\"all_true_labels: {type(all_true_labels)} {all_true_labels.shape}\")\n",
        "  results_df = pd.DataFrame({\n",
        "      'predictions'  : [list(pred)  for pred  in all_preds],\n",
        "      'probabilities': [list(prob)  for prob  in all_probs],\n",
        "      'true_labels'  : [list(label) for label in all_true_labels]\n",
        "  })\n",
        "  results_file_path = f\"{phase}_results.csv\"\n",
        "  results_df.to_csv(results_file_path, index=False)\n",
        "\n",
        "  # Classification report for precision, recall, F1 score\n",
        "  report = classification_report(\n",
        "      y_true        = all_true_labels,\n",
        "      y_pred        = all_preds,\n",
        "      target_names  = labels,\n",
        "      zero_division = 0,\n",
        "      output_dict   = True\n",
        "  )\n",
        "  print(f\"Classification Report:\\n{report}\")\n",
        "\n",
        "  # ROC AUC for multi-label classification\n",
        "  roc_auc = roc_auc_score(\n",
        "      y_true  = all_true_labels,\n",
        "      y_score = all_probs,\n",
        "      average = 'micro'\n",
        "  )\n",
        "  print(f\"ROC AUC: {roc_auc}\")\n",
        "\n",
        "  metrics = {\n",
        "      'classification_report': report,\n",
        "      'roc_auc'              : roc_auc\n",
        "  }\n",
        "  metrics_file_path = f\"{phase}_metrics.json\"\n",
        "  with open(metrics_file_path, \"w\") as f:\n",
        "    json.dump(metrics, f, indent=4)\n",
        "\n",
        "  print(f\"{phase} Results Saved to {results_file_path}\")\n",
        "  print(f\"{phase} Metrics Saved to {metrics_file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results_with_threshold_tuning(model, dataset, batch_size, average, tune_thresholds=False, phase='eval'):\n",
        "  \"\"\"\n",
        "  Evaluates a model on a given dataset and optionally tunes thresholds for multi-label classification.\n",
        "\n",
        "  Args:\n",
        "    model          : The trained model to evaluate.\n",
        "    dataset        : The dataset to evaluate (validation or test).\n",
        "    batch_size     : Batch size for DataLoader.\n",
        "    tune_thresholds: Whether to tune thresholds per label (default = False).\n",
        "    average        : The averaging method for metrics ('micro', 'macro', 'weighted', etc.).\n",
        "    phase          : The phase (eval or test) for saving results (default = 'eval').\n",
        "\n",
        "  Returns:\n",
        "    A dictionary with metrics and optionally tuned thresholds.\n",
        "  \"\"\"\n",
        "\n",
        "  # Clear GPU cache\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  # Set the model to eval mode to disable dropout and other training-specific behaviors\n",
        "  model.eval\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model.to(device)\n",
        "\n",
        "  # Create DataLoader\n",
        "  dataLoader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  all_preds       = []\n",
        "  all_probs       = []\n",
        "  all_true_labels = []\n",
        "\n",
        "  for batch in tqdm(dataLoader):\n",
        "    batch = {k: v.to(device) for k, v in batch.items()}\n",
        "    with torch.no_grad():\n",
        "      outputs = model(**batch)\n",
        "    logits = outputs.logits\n",
        "\n",
        "  # Convert logits to probabilities\n",
        "  sigmoid = torch.nn.Sigmoid()\n",
        "  probs   = sigmoid(logits).cpu().numpy()    # Convert to Numpy\n",
        "  all_probs.append(probs)\n",
        "  all_true_labels.append(batch['labels'].cpu().numpy())\n",
        "\n",
        "  # Concatenate results from all batches\n",
        "  all_probs       = np.concatenate(all_probs, axis=0)        # shape: [num_samples, num_labels]\n",
        "  all_true_labels = np.concatenate(all_true_labels, axis=0)  # shape: [num_samples, num_labels]\n",
        "\n",
        "  # Initialize thresholds (default = 0.5)\n",
        "  thresholds = np.full(all_probs.shape[1], 0.5)  # shape: [num_samples]\n",
        "\n",
        "  # Thresholds tuning (if enabled)\n",
        "  if tune_thresholds:\n",
        "    # Tune thresholds for each label\n",
        "    print(f\"Tuning thresholds for {phase} phase\")\n",
        "    for label_idx in range(all_probs.shape[1]):                           # Iterate over labels\n",
        "      precision, recall, thresholds_label = precision_recall_curve(all_true_labels[:, label_idx], all_probs[:, label_idx])\n",
        "      f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)  # Avoid division by zero\n",
        "      best_threshold_idx = np.argmax(f1_scores)\n",
        "      thresholds[label_idx] = thresholds_label[best_threshold_idx]        # Set the best threshold for this label\n",
        "\n",
        "  # Apply thresholds to probabilities to generate predictions\n",
        "  all_preds = (all_probs > thresholds).astype(int)                        # Convert to binary Numpy array; convert the boolean result to int (0 or 1\n",
        "\n",
        "  # Save predictions, probabilities, and true labels to a DataFrame\n",
        "  results_df = pd.DataFrame({\n",
        "      'predictions'  : [list(pred)  for pred  in all_preds],\n",
        "      'probabilities': [list(prob)  for prob  in all_probs],\n",
        "      'true_labels'  : [list(label) for label in all_true_labels]\n",
        "  })\n",
        "  results_file_path = f\"{phase}_results.csv\"\n",
        "  results_df.to_csv(results_file_path, index=False)\n",
        "\n",
        "  # Compute metrics\n",
        "  print(f\"Computing metrics for {phase} phase\")\n",
        "  classification_report_dict = classification_report(\n",
        "      y_true        = all_true_labels,\n",
        "      y_pred        = all_preds,\n",
        "      target_names  = labels,\n",
        "      zero_division = 0,\n",
        "      output_dict   = True\n",
        "  )\n",
        "\n",
        "  # Compute roc_auc\n",
        "  roc_auc = roc_auc_score(\n",
        "      y_true  = all_true_labels,\n",
        "      y_score = all_probs,\n",
        "      average = average\n",
        "  )\n",
        "\n",
        "  # Computer precision_recall_auc\n",
        "  precision_recall_auc = average_precision_score(all_true_labels, all_probs, average=average)\n",
        "\n",
        "  #precision, recall, _ = precision_recall_curve(all_true_labels, all_probs)\n",
        "  #precision_recall_auc = auc(recall, precision)\n",
        "\n",
        "  metrics = {\n",
        "      'classification_report': classification_report_dict,\n",
        "      'roc_auc'              : roc_auc,\n",
        "      'precision_recall_auc' : precision_recall_auc,\n",
        "      'thresholds'           : thresholds.tolist() if tune_thresholds else \"Default (0.5)\",  # Convert numpy array to list\n",
        "  }\n",
        "\n",
        "  metrics_file_path = f\"{phase}_metrics.json\"\n",
        "  with open(metrics_file_path, \"w\") as f:\n",
        "    json.dump(metrics, f, indent=4)\n",
        "\n",
        "  print(f\"{phase} Results Saved to {results_file_path}\")\n",
        "  print(f\"{phase} Metrics Saved to {metrics_file_path}\")\n",
        "\n",
        "  return metrics\n"
      ],
      "metadata": {
        "id": "6qWc2wL8-cQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_thresholds(true_labels, probs, id2label):\n",
        "  \"\"\"\n",
        "  Tune thresholds for each label to maximize F1 alone, as F1 balances precision and recall into a single metric.\n",
        "\n",
        "  Args:\n",
        "    true_labels: actual labels for the data                                      (numpy array of shape (num_samples, num_labels))\n",
        "    probs      : predicted probabilities                                         (numpy array of shape (num_samples, num_labels))\n",
        "    id2label   : dictionary mapping label indices (int) to label names (string)\n",
        "\n",
        "  Returns:\n",
        "    best_thresholds: best threshold for each label                                                      (numpy array of shape (num_labels,))\n",
        "    best_metrics   : dictionary of best F1, precision_for_best_f1 and recall_for_best_f1 for each label (dictionary of numpy arrays)\n",
        "  \"\"\"\n",
        "  thresholds      = np.linspace(0.1, 0.9, 9)\n",
        "  best_thresholds = np.zeros(len(id2label))\n",
        "  best_metrics    = {label: {'f1': 0.0, 'precision': 0.0, 'recall': 0.0} for label in id2label.values()}\n",
        "\n",
        "  for label_idx, label in id2label.items():\n",
        "    for threshold in thresholds:\n",
        "      pred                     = (probs[:, label_idx] > threshold).astype(int)\n",
        "      precision, recall, f1, _ = precision_recall_fscore_support(true_labels[:, label_idx], pred, average='binary', zero_division=0)\n",
        "      if f1 > best_metrics[label]['f1']:\n",
        "        best_thresholds[label_idx]       = threshold\n",
        "        best_metrics[label]['f1']        = f1\n",
        "        best_metrics[label]['precision'] = precision\n",
        "        best_metrics[label]['recall']    = recall\n",
        "\n",
        "  return best_thresholds, best_metrics\n"
      ],
      "metadata": {
        "id": "NlcRxeCycBg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics_with_threshold(eval_preds: EvalPrediction, thresholds, id2label):\n",
        "  \"\"\"\n",
        "  Compute metrics during evaluation, by applying tuned thresholds DURING EVALUATION AND TEST\n",
        "  \"\"\"\n",
        "  logits  = eval_preds.predictions\n",
        "  labels  = eval_preds.label_ids\n",
        "  sigmoid = torch.nn.Sigmoid               # create sigmoid instance\n",
        "  probs   = sigmoid(logits).cpu().numpy()\n",
        "  preds   = np.zeros_like(probs)\n",
        "\n",
        "  # Apply threshold per label\n",
        "  for label_idx in id2label.keys():\n",
        "    preds[:, label_idx] = (probs[:, label_idx] > thresholds[label_idx]).astype(int)\n",
        "\n",
        "  # Compute metrics\n",
        "  f1                    = f1_score               (labels, preds, average='micro')\n",
        "  precision             = precision_score        (labels, preds, average='micro')\n",
        "  recall                = recall_score           (labels, preds, average='micro')\n",
        "  accuracy              = accuracy_score         (labels, preds)\n",
        "  roc_auc               = roc_auc_score          (labels, probs, average='micro')\n",
        "  precision_recall_auc  = average_precision_score(labels, probs, average='micro')\n",
        "\n",
        "  # Use id2label for target_names\n",
        "  classification_report = classification_report(labels, preds, target_names=id2label.values(), zero_division=0)\n",
        "\n",
        "  metrics = {\n",
        "      'f1'                   : f1,\n",
        "      'precision'            : precision,\n",
        "      'recall'               : recall,\n",
        "      'accuracy'             : accuracy,\n",
        "      'roc_auc'              : roc_auc,\n",
        "      'precision_recall_auc' : precision_recall_auc,\n",
        "      'thresholds'           : thresholds.tolist(),\n",
        "      'classification_report': classification_report\n",
        "  }\n",
        "\n",
        "  return metrics\n"
      ],
      "metadata": {
        "id": "8_-dGUEkJqDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_thresholds(trainer, dataset, threshold_tuning=False, thresholds=None):\n",
        "    \"\"\"\n",
        "    Predicts using trainer.predict(), with optional threshold tuning.\n",
        "\n",
        "    Parameters:\n",
        "    - trainer         : Hugging Face Trainer or CustomTrainer instance\n",
        "    - dataset         : dataset to predict on\n",
        "    - threshold_tuning: boolean to enable threshold tuning\n",
        "    - thresholds      : custom thresholds for classification (optional)\n",
        "\n",
        "    Returns:\n",
        "    - predictions                               : final binary predictions\n",
        "    - true_labels                               : ground truth labels from the dataset\n",
        "    - best_thresholds (if threshold_tuning=True): optimized thresholds\n",
        "    \"\"\"\n",
        "    # Predict\n",
        "    predictions_output = trainer.predict(dataset)\n",
        "    logits             = predictions_output.predictions\n",
        "    true_labels        = predictions_output.label_ids\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probabilities = 1 / (1 + np.exp(-logits))\n",
        "\n",
        "    # Optimize thresholds for each label\n",
        "    if threshold_tuning:\n",
        "        num_labels = probabilities.shape[1]\n",
        "        best_thresholds = []\n",
        "        for label_idx in range(num_labels):\n",
        "            best_f1 = 0\n",
        "            best_threshold = 0.5\n",
        "            for threshold in np.linspace(0.1, 0.9, 9):\n",
        "                preds = (probabilities[:, label_idx] >= threshold).astype(int)\n",
        "                precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                    true_labels[:, label_idx], preds, average=\"binary\", zero_division=0\n",
        "                )\n",
        "                if f1 > best_f1:\n",
        "                    best_f1 = f1\n",
        "                    best_threshold = threshold\n",
        "            best_thresholds.append(best_threshold)\n",
        "        return probabilities, true_labels, best_thresholds\n",
        "\n",
        "    # Apply provided thresholds (or default to 0.5)\n",
        "    if thresholds is None:\n",
        "        thresholds = [0.5] * probabilities.shape[1]\n",
        "    predictions = (probabilities >= np.array(thresholds)).astype(int)\n",
        "\n",
        "    return predictions, true_labels\n"
      ],
      "metadata": {
        "id": "mKN-7CwsgX7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGKK2rYhwcJ8"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Evaluate\n",
        "\n",
        "After training, we evaluate our model on the validation set.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiloh9eMK91o"
      },
      "source": [
        "First evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhnKJcVVwcJ8"
      },
      "outputs": [],
      "source": [
        "phase_evaluate = 'evaluate_model_eval'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoJpTASkY8De"
      },
      "outputs": [],
      "source": [
        "get_results(\n",
        "    model      = model,\n",
        "    dataset    = validation_dataset,\n",
        "    batch_size = batch_size,\n",
        "    threshold  = threshold,\n",
        "    phase      = phase_evaluate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRVTBgrPVJ8L"
      },
      "outputs": [],
      "source": [
        "print(\"First evaluation successfully completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbgMYXu3wcJ8"
      },
      "source": [
        "Second evaluate results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kc70J63wcJ8"
      },
      "outputs": [],
      "source": [
        "trainer_evaluate = trainer.evaluate()\n",
        "print(f\"trainer_evaluate: {type(trainer_evaluate)} len={len(trainer_evaluate)}\\n{trainer_evaluate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMlebJ83LRYG"
      },
      "outputs": [],
      "source": [
        "file_path = \"trainer_evaluate.json\"\n",
        "with open(file_path, \"w\") as f:\n",
        "  json.dump(trainer_evaluate, f)\n",
        "print(f\"Evaluate output successfully saved to {file_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QwshIQGSFxg"
      },
      "outputs": [],
      "source": [
        "print(\"Second evaluation successfully completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQzo6qeGwcJ8"
      },
      "source": [
        "Upload Evaluate Results to HF repo_id_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYmURgAz4Xk-"
      },
      "outputs": [],
      "source": [
        "upload_file(\n",
        "    path_or_fileobj = f\"{phase_evaluate}_results.csv\",\n",
        "    path_in_repo    = f\"{phase_evaluate}_results.csv\",\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj = f\"{phase_evaluate}_metrics.json\",\n",
        "    path_in_repo    = f\"{phase_evaluate}_metrics.json\",\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj = 'trainer_evaluate.json',\n",
        "    path_in_repo    = 'trainer_evaluate.json',\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_H-pjMiiwcJ9"
      },
      "outputs": [],
      "source": [
        "\"\"\"## Test\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwO6_V_lYcJg"
      },
      "source": [
        "First test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X0r_TALwcJ9"
      },
      "outputs": [],
      "source": [
        "phase_test = 'test_model_eval'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPHcZrdsEARs"
      },
      "outputs": [],
      "source": [
        "get_results(\n",
        "    model      = model,\n",
        "    dataset    = test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    threshold  = threshold,\n",
        "    phase      = phase_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yibAPgTaVljm"
      },
      "outputs": [],
      "source": [
        "print(\"First test successfully completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMtMjR-WwcJ9"
      },
      "source": [
        "Second test results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX1sWMZywcJ9"
      },
      "outputs": [],
      "source": [
        "trainer_predict = trainer.predict(test_dataset)\n",
        "print(f\"trainer_predict: {type(trainer_predict)} len={len(trainer_predict)}\\n{trainer_predict}\")\n",
        "print(f\"trainer_predict.predictions: {type(trainer_predict.predictions)} shape={trainer_predict.predictions.shape}\")  # Model logits\n",
        "print(f\"trainer_predict.label_ids: {type(trainer_predict.label_ids)} shape={trainer_predict.label_ids.shape}\")        # Ground truth labels\n",
        "print(f\"trainer_predict.metrics: {type(trainer_predict.metrics)} len={len(trainer_predict.metrics)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY42YauKwcJ9"
      },
      "outputs": [],
      "source": [
        "trainer_predict_json_serializable = {\n",
        "    'predictions': trainer_predict.predictions.tolist(),  # Convert Numpy array to list\n",
        "    'label_ids'  : trainer_predict.label_ids.tolist(),    # Convert Numpy array to list\n",
        "    'metrics'    : trainer_predict.metrics                # Dictionary is already serializable\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39vYrXt4HSaO"
      },
      "outputs": [],
      "source": [
        "file_path = \"trainer_predict.json\"\n",
        "with open(file_path, \"w\") as f:\n",
        "  json.dump(trainer_predict_json_serializable, f)\n",
        "print(f\"Test output successfully saved to {file_path}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F1Y8Hve8qsa"
      },
      "outputs": [],
      "source": [
        "print(\"Second test successfully completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4ckvP9rwcJ9"
      },
      "source": [
        "Upload Test Results to HF repo_id_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSy9v4OL7iPa"
      },
      "outputs": [],
      "source": [
        "upload_file(\n",
        "    path_or_fileobj = f\"{phase_test}_results.csv\",\n",
        "    path_in_repo    = f\"{phase_test}_results.csv\",\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj = f\"{phase_test}_metrics.json\",\n",
        "    path_in_repo    = f\"{phase_test}_metrics.json\",\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")\n",
        "upload_file(\n",
        "    path_or_fileobj = 'trainer_predict.json',\n",
        "    path_in_repo    = 'trainer_predict.json',\n",
        "    repo_id         = HF_name,\n",
        "    repo_type       = 'dataset'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvh_jDvdBt26"
      },
      "outputs": [],
      "source": [
        "print(\"It's the end\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "formats": "ipynb,py:nomarker"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c83b713f91774c0f8e75edbee6d7cebe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91f0355cafa94df9b21d51c1ed476447",
              "IPY_MODEL_ea715d4ef66b4fa3a1a0023174b4b810",
              "IPY_MODEL_b860bb6be6914be5817c9e410bde25f3"
            ],
            "layout": "IPY_MODEL_cb901312dc6545599dfead4177c07684"
          }
        },
        "91f0355cafa94df9b21d51c1ed476447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ebab9db3fe4acc94c828132057d52e",
            "placeholder": "​",
            "style": "IPY_MODEL_e45a1ca8f4fa40088492cd9959aa44d6",
            "value": "test_model_eval_results.csv: 100%"
          }
        },
        "ea715d4ef66b4fa3a1a0023174b4b810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8052f6ab37f464e9e0578326e667dd4",
            "max": 312620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66092725306a46cd94eb13f50165cc8e",
            "value": 312620
          }
        },
        "b860bb6be6914be5817c9e410bde25f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8e3d7f7652544399408ffcaad15d5cd",
            "placeholder": "​",
            "style": "IPY_MODEL_7a114ef6802840edbc0946f387b11e54",
            "value": " 313k/313k [00:00&lt;00:00, 1.96MB/s]"
          }
        },
        "cb901312dc6545599dfead4177c07684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ebab9db3fe4acc94c828132057d52e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e45a1ca8f4fa40088492cd9959aa44d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8052f6ab37f464e9e0578326e667dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66092725306a46cd94eb13f50165cc8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8e3d7f7652544399408ffcaad15d5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a114ef6802840edbc0946f387b11e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07fd9f8110d0482cb989d0af0d0e7658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22d182030746416cbe5623db1aebc234",
              "IPY_MODEL_55597f7f18a340929dc73fa18ed907c1",
              "IPY_MODEL_53ee7ff4b7b44e7e9f6580cd073382c7"
            ],
            "layout": "IPY_MODEL_ae9bb62a3a794fdab4361a43bcbdff5e"
          }
        },
        "22d182030746416cbe5623db1aebc234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed5defdeecb412aa485acfdaf51c123",
            "placeholder": "​",
            "style": "IPY_MODEL_2279a1a9adb94b11be9ef5f57da70800",
            "value": "vocab.json: 100%"
          }
        },
        "55597f7f18a340929dc73fa18ed907c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a3b6d02b7e43958e015a7d8ab1c01f",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f0c4b6f400c40fdac2b7eec128c97b2",
            "value": 898823
          }
        },
        "53ee7ff4b7b44e7e9f6580cd073382c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0dc8a5c9ce649a79375de80ae9ae790",
            "placeholder": "​",
            "style": "IPY_MODEL_2ceab4c6a24b4f87b44cc97146206922",
            "value": " 899k/899k [00:00&lt;00:00, 27.6MB/s]"
          }
        },
        "ae9bb62a3a794fdab4361a43bcbdff5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ed5defdeecb412aa485acfdaf51c123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2279a1a9adb94b11be9ef5f57da70800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5a3b6d02b7e43958e015a7d8ab1c01f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f0c4b6f400c40fdac2b7eec128c97b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0dc8a5c9ce649a79375de80ae9ae790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ceab4c6a24b4f87b44cc97146206922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f29314fc1c4459aa030917d08ffe339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4d1ededdb4e4f5a9f18d7a4b67ff32d",
              "IPY_MODEL_57357093d9a140719572b2a6d4a82370",
              "IPY_MODEL_a015cf63b0b547a0a7327c8ed79652fc"
            ],
            "layout": "IPY_MODEL_e8f76ff47de34a849f5fa25192529463"
          }
        },
        "c4d1ededdb4e4f5a9f18d7a4b67ff32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_355d5edee71b4299b407e96de59d7fa4",
            "placeholder": "​",
            "style": "IPY_MODEL_f13dc00d241347018dcf4fb379294280",
            "value": "merges.txt: 100%"
          }
        },
        "57357093d9a140719572b2a6d4a82370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f1db9010060443a9ab359913e52ba6f",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3572e541cd04c179e75e3da8b27670e",
            "value": 456318
          }
        },
        "a015cf63b0b547a0a7327c8ed79652fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f38c605c46c44aeb9a1b47846ea27d7",
            "placeholder": "​",
            "style": "IPY_MODEL_be081775195c47539115a418cecba3d6",
            "value": " 456k/456k [00:00&lt;00:00, 2.84MB/s]"
          }
        },
        "e8f76ff47de34a849f5fa25192529463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355d5edee71b4299b407e96de59d7fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13dc00d241347018dcf4fb379294280": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f1db9010060443a9ab359913e52ba6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3572e541cd04c179e75e3da8b27670e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f38c605c46c44aeb9a1b47846ea27d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be081775195c47539115a418cecba3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "830feebbc58243fb9621849be268c784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c20087cb9e4832b501577570b73b7d",
              "IPY_MODEL_0e02590af1464a1d8c6a97fe679f4a64",
              "IPY_MODEL_5343842f9a554abeb15347b441ed5859"
            ],
            "layout": "IPY_MODEL_cd802fd2912d4f8ab77b4bd3bd277840"
          }
        },
        "e2c20087cb9e4832b501577570b73b7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_670f4956a75d41dd9cd03de52a0b7bcd",
            "placeholder": "​",
            "style": "IPY_MODEL_bbd5fb45104c41ce94d04e3a6bd377bd",
            "value": "tokenizer.json: 100%"
          }
        },
        "0e02590af1464a1d8c6a97fe679f4a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd7d77e609a4b41bea05ff1393aad17",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1f364cc6ad4c268c6b8ff9366edfbf",
            "value": 1355863
          }
        },
        "5343842f9a554abeb15347b441ed5859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9154e2043994fd38ac5fd2d77bce100",
            "placeholder": "​",
            "style": "IPY_MODEL_abb9da3a73174f67bd4e8972bf7c73c9",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 4.10MB/s]"
          }
        },
        "cd802fd2912d4f8ab77b4bd3bd277840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670f4956a75d41dd9cd03de52a0b7bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd5fb45104c41ce94d04e3a6bd377bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dd7d77e609a4b41bea05ff1393aad17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea1f364cc6ad4c268c6b8ff9366edfbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9154e2043994fd38ac5fd2d77bce100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb9da3a73174f67bd4e8972bf7c73c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f872725a1494aeb859a61d9831177a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6e1cde677264cc8a1ece895da46d9bf",
              "IPY_MODEL_6adfcc5bcb5548fe86fb81c0a6af0866",
              "IPY_MODEL_ec45f3eab35c480b89d68742f60e2bc7"
            ],
            "layout": "IPY_MODEL_573721a88e43454fb91f044dd7a15b0a"
          }
        },
        "a6e1cde677264cc8a1ece895da46d9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f9fa8c7bfc74ef8bca0f7ce4e9c5d1d",
            "placeholder": "​",
            "style": "IPY_MODEL_7364598fef634658a0bc6492ed7f198f",
            "value": "config.json: 100%"
          }
        },
        "6adfcc5bcb5548fe86fb81c0a6af0866": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bd6e7ccdab54aa0951c04499116d71f",
            "max": 694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa37bb5860c64ec49067990b9c113e2f",
            "value": 694
          }
        },
        "ec45f3eab35c480b89d68742f60e2bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d93085b6dc4745b6fef6e9fb2a6f59",
            "placeholder": "​",
            "style": "IPY_MODEL_d3ff5366ddee471383941df823ffc3fb",
            "value": " 694/694 [00:00&lt;00:00, 40.1kB/s]"
          }
        },
        "573721a88e43454fb91f044dd7a15b0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f9fa8c7bfc74ef8bca0f7ce4e9c5d1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7364598fef634658a0bc6492ed7f198f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bd6e7ccdab54aa0951c04499116d71f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa37bb5860c64ec49067990b9c113e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92d93085b6dc4745b6fef6e9fb2a6f59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ff5366ddee471383941df823ffc3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4534e4d3a5d24871b9ae948ca5fdf6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_947161a4df554ed89216d49d00a70f7b",
              "IPY_MODEL_41fdb4ce5527465ab32ba33695d564ed",
              "IPY_MODEL_2b96210c811f4c2f8f20a03f528ecd70"
            ],
            "layout": "IPY_MODEL_d5c81e6accb7493a88c1dbdd6cf4b00c"
          }
        },
        "947161a4df554ed89216d49d00a70f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a66febd2a1e4128a6b6c780b0d3c88a",
            "placeholder": "​",
            "style": "IPY_MODEL_7d3df09ca2d648ff943a0145811bbe5d",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "41fdb4ce5527465ab32ba33695d564ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7556e3d45cc240f4bf7c2a38dda37d2d",
            "max": 597257159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34fe767096e44ef8901ba6cb8b2c556f",
            "value": 597257159
          }
        },
        "2b96210c811f4c2f8f20a03f528ecd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eae6f11d1cbf49929bdd923991d902be",
            "placeholder": "​",
            "style": "IPY_MODEL_114f2cbc529944818beab308454623cc",
            "value": " 597M/597M [00:05&lt;00:00, 145MB/s]"
          }
        },
        "d5c81e6accb7493a88c1dbdd6cf4b00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a66febd2a1e4128a6b6c780b0d3c88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d3df09ca2d648ff943a0145811bbe5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7556e3d45cc240f4bf7c2a38dda37d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34fe767096e44ef8901ba6cb8b2c556f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eae6f11d1cbf49929bdd923991d902be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114f2cbc529944818beab308454623cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "065f1e6db6534e90a14b2f8b7eccaff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa444a5b3a12484ea6aba8741aa85de5",
              "IPY_MODEL_23c08ae93b2749bbbbd710f111ffdd82",
              "IPY_MODEL_8afdc87aabac4208b3cb678f904d7296"
            ],
            "layout": "IPY_MODEL_d67f9eacb0ac4a2cb4185ded5b3586d4"
          }
        },
        "fa444a5b3a12484ea6aba8741aa85de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41e4f925b69947c1b0d2607eceb55012",
            "placeholder": "​",
            "style": "IPY_MODEL_394ca2e82f0c4f978d7ae47300405749",
            "value": "Map: 100%"
          }
        },
        "23c08ae93b2749bbbbd710f111ffdd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8814545d7e9d4857bb13eae7bd591f22",
            "max": 96,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f69c4b809e904fff84ca8b1a8502e552",
            "value": 96
          }
        },
        "8afdc87aabac4208b3cb678f904d7296": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae4d1b41f92e4c40a92c3eed43bb011f",
            "placeholder": "​",
            "style": "IPY_MODEL_8976a9431cf4453fa34ba55391696a6c",
            "value": " 96/96 [00:00&lt;00:00, 311.71 examples/s]"
          }
        },
        "d67f9eacb0ac4a2cb4185ded5b3586d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e4f925b69947c1b0d2607eceb55012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394ca2e82f0c4f978d7ae47300405749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8814545d7e9d4857bb13eae7bd591f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69c4b809e904fff84ca8b1a8502e552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae4d1b41f92e4c40a92c3eed43bb011f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8976a9431cf4453fa34ba55391696a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e526bbb000154b4dbac396afe1b5434c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c41955b307dd4c3292250e0e46a99832",
              "IPY_MODEL_7e2b1ab896e94f99917ecbadc8fa180c",
              "IPY_MODEL_3cad9da685d6421d8c2a0aa69338e6de"
            ],
            "layout": "IPY_MODEL_36d1c01038db41bb9103298cbc739dc4"
          }
        },
        "c41955b307dd4c3292250e0e46a99832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d75f2b44e5472380ad15cd13a56688",
            "placeholder": "​",
            "style": "IPY_MODEL_05dfff7b90c6488ba6cb39b32c5f1b9d",
            "value": "Map: 100%"
          }
        },
        "7e2b1ab896e94f99917ecbadc8fa180c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5abd2fc2eebe4834beefbd99d3f4fa12",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ee7d97a35eb4a35bca78c85dc7c0be6",
            "value": 12
          }
        },
        "3cad9da685d6421d8c2a0aa69338e6de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7216409eb1546ef86e72afb1c2974c5",
            "placeholder": "​",
            "style": "IPY_MODEL_e2fa15918a704d1ab29976e70d241376",
            "value": " 12/12 [00:00&lt;00:00, 110.08 examples/s]"
          }
        },
        "36d1c01038db41bb9103298cbc739dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24d75f2b44e5472380ad15cd13a56688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05dfff7b90c6488ba6cb39b32c5f1b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5abd2fc2eebe4834beefbd99d3f4fa12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee7d97a35eb4a35bca78c85dc7c0be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7216409eb1546ef86e72afb1c2974c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2fa15918a704d1ab29976e70d241376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7993144e8874dd6b58a84efee6e8790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a848116e43004fa38e8a709fec15d3ff",
              "IPY_MODEL_36e347699deb4a2c8923aa8c0b74706c",
              "IPY_MODEL_2da18cd5c89c48c2b998489dd80cc0f4"
            ],
            "layout": "IPY_MODEL_4113da81dbc7468285441758e66aa8ba"
          }
        },
        "a848116e43004fa38e8a709fec15d3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a77e74d2ad4b008629cfc5fbbbc416",
            "placeholder": "​",
            "style": "IPY_MODEL_01081396e09b4b7faa4eaf7ca1b1ebfc",
            "value": "Map: 100%"
          }
        },
        "36e347699deb4a2c8923aa8c0b74706c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125071f4abc446ff9b073ffe8fb53945",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28e3908b587d4e5782a6301e621fee9e",
            "value": 12
          }
        },
        "2da18cd5c89c48c2b998489dd80cc0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40734f4c4a7e4d3da6f4ebaaa0df4cee",
            "placeholder": "​",
            "style": "IPY_MODEL_7b49d416e01941f0b38aa96849be7340",
            "value": " 12/12 [00:00&lt;00:00, 115.29 examples/s]"
          }
        },
        "4113da81dbc7468285441758e66aa8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4a77e74d2ad4b008629cfc5fbbbc416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01081396e09b4b7faa4eaf7ca1b1ebfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "125071f4abc446ff9b073ffe8fb53945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28e3908b587d4e5782a6301e621fee9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40734f4c4a7e4d3da6f4ebaaa0df4cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b49d416e01941f0b38aa96849be7340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}