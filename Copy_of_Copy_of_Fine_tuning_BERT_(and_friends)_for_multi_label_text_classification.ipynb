{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudelepere/ML_GitHub/blob/main/Copy_of_Copy_of_Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLB3I4FKZ5Lr"
      },
      "source": [
        "# Fine-tuning BERT (and friends) for multi-label text classification\n",
        "\n",
        "In this notebook, we are going to fine-tune BERT to predict one or more labels for a given piece of text. Note that this notebook illustrates how to fine-tune a bert-base-uncased model, but you can also fine-tune a RoBERTa, DeBERTa, DistilBERT, CANINE, ... checkpoint in the same way.\n",
        "\n",
        "All of those work in the same way: they add a linear layer on top of the base model, which is used to produce a tensor of shape (batch_size, num_labels), indicating the unnormalized scores for a number of labels for every example in the batch.\n",
        "\n",
        "\n",
        "\n",
        "## Set-up environment\n",
        "\n",
        "First, we install the libraries which we'll use: HuggingFace Transformers and Datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIH9NP0MZ6-O"
      },
      "source": [
        "## Load dataset\n",
        "\n",
        "Next, let's download a multi-label text classification dataset from the [hub](https://huggingface.co/).\n",
        "\n",
        "At the time of writing, I picked a random one as follows:   \n",
        "\n",
        "* first, go to the \"datasets\" tab on huggingface.co\n",
        "* next, select the \"multi-label-classification\" tag on the left as well as the the \"1k<10k\" tag (fo find a relatively small dataset).\n",
        "\n",
        "Note that you can also easily load your local data (i.e. csv files, txt files, Parquet files, JSON, ...) as explained [here](https://huggingface.co/docs/datasets/loading.html#local-and-remote-files).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sfxHIZ_GAaA"
      },
      "source": [
        "file1 = open(r\"C:\\tmp\\BERT_results\\zazu.txt\", 'w')\n",
        "L = [\"This is Delhi\\n\", \"This is Paris\\n\", \"This is London\\n\"]\n",
        "s = \"Hello\\n\"\n",
        "file1.write(s)\n",
        "file1.writelines(L)\n",
        "file1.close()\n",
        "file1 = open(r\"C:\\tmp\\BERT_results\\zazu.txt\", 'r')\n",
        "print(file1.read())\n",
        "file1.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Axit_kMNUg1"
      },
      "source": [
        "!pwd\n",
        "!cd /..\n",
        "!pwd\n",
        "!ls -la /content/ML_GitHub/BERT_results/checkpoint-80\n",
        "!cat /content/ML_GitHub/BERT_results/checkpoint-80/trainer_state.json\n",
        "from google.colab import files\n",
        "files.download(r\"/content/ML_GitHub/BERT_results/checkpoint-80/trainer_state.json\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd1LiXGjZ420",
        "outputId": "871aec9a-0ccc-4a85-f441-812afa51cfd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The current directory is /content\n",
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n",
            "Cloning into 'ML_GitHub'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 102 (delta 52), reused 55 (delta 24), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (102/102), 10.04 MiB | 19.26 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "list /content: ['.config', 'my_model.zip', '.git', 'ML_GitHub', 'eval_metrics.json', 'training_metrics.json', 'my_model_unzip', 'sample_data']\n",
            "list /content/ML_GitHub: ['.git', 'Copy_of_Fine_tuning_BERT_(and_friends)_for_multi_label_text_classification.ipynb', 'datasetHF', 'README.md']\n",
            "total 24\n",
            "drwxr-xr-x 5 root root 4096 Nov 12 18:08 .\n",
            "drwxr-xr-x 4 root root 4096 Nov 12 18:08 ..\n",
            "-rw-r--r-- 1 root root   43 Nov 12 18:08 dataset_dict.json\n",
            "drwxr-xr-x 2 root root 4096 Nov 12 18:08 test\n",
            "drwxr-xr-x 2 root root 4096 Nov 12 18:08 train\n",
            "drwxr-xr-x 2 root root 4096 Nov 12 18:08 validation\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mdataset: <class 'datasets.dataset_dict.DatasetDict'> {'train': (128, 44), 'validation': (18, 44), 'test': (54, 44)}\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', '394', '142', '146', '147', '148', '149', '150', '151', '408', '409', '153', '154', '155', '156', '157', '158', '160', '152', '162', '165', '167', '168', '169', '170', '171', '685', '174', '686', '176', '689', '173', '356', '360', '361', '362', '364', '760', '756', '758', '375', '376', '761'],\n",
            "        num_rows: 128\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'text', '394', '142', '146', '147', '148', '149', '150', '151', '408', '409', '153', '154', '155', '156', '157', '158', '160', '152', '162', '165', '167', '168', '169', '170', '171', '685', '174', '686', '176', '689', '173', '356', '360', '361', '362', '364', '760', '756', '758', '375', '376', '761'],\n",
            "        num_rows: 18\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'text', '394', '142', '146', '147', '148', '149', '150', '151', '408', '409', '153', '154', '155', '156', '157', '158', '160', '152', '162', '165', '167', '168', '169', '170', '171', '685', '174', '686', '176', '689', '173', '356', '360', '361', '362', '364', '760', '756', '758', '375', '376', '761'],\n",
            "        num_rows: 54\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import os, sys, shutil\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "current_dir = os.getcwd()\n",
        "print(f\"The current directory is {current_dir}\")\n",
        "\n",
        "if os.path.isdir('ML_GitHub'):\n",
        "    shutil.rmtree('ML_GitHub')\n",
        "\n",
        "!git init\n",
        "!git branch -m main\n",
        "!git clone https://github.com/claudelepere/ML_GitHub.git\n",
        "print(f\"list /content: {os.listdir(current_dir)}\")\n",
        "print(f\"list /content/ML_GitHub: {os.listdir(current_dir + '/ML_GitHub')}\")\n",
        "!ls -la /content/ML_GitHub/datasetHF\n",
        "os.chdir(current_dir + '/ML_GitHub')\n",
        "\n",
        "#!pip install fsspec==2024.10.0\n",
        "!pip install -q transformers datasets\n",
        "from datasets import DatasetDict\n",
        "\n",
        "dataset = DatasetDict.load_from_disk('datasetHF')    # from disk does not mean from local disk\n",
        "print(f\"dataset: {type(dataset)} {dataset.shape}\\n{dataset}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCL02vQgxYTO"
      },
      "source": [
        "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgS0wMWExcqP"
      },
      "source": [
        "Let's check the first example of the training split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unjuTtKUjZI3"
      },
      "outputs": [],
      "source": [
        "example = dataset['validation'][0]\n",
        "#example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DV0Rtetxgd4"
      },
      "source": [
        "The dataset consists of texts, labeled with one or more skills.\n",
        "\n",
        "Let's create a list that contains the labels, as well as 2 dictionaries that map labels to integers and back."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5vZhQpvkE8s",
        "outputId": "4eeb921c-5295-4c1f-ff38-77957b16431e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42 [(0, '142'), (1, '146'), (2, '147'), (3, '148'), (4, '149'), (5, '150'), (6, '151'), (7, '152'), (8, '153'), (9, '154'), (10, '155'), (11, '156'), (12, '157'), (13, '158'), (14, '160'), (15, '162'), (16, '165'), (17, '167'), (18, '168'), (19, '169'), (20, '170'), (21, '171'), (22, '173'), (23, '174'), (24, '176'), (25, '356'), (26, '360'), (27, '361'), (28, '362'), (29, '364'), (30, '375'), (31, '376'), (32, '394'), (33, '408'), (34, '409'), (35, '685'), (36, '686'), (37, '689'), (38, '756'), (39, '758'), (40, '760'), (41, '761')]\n",
            "{0: '142', 1: '146', 2: '147', 3: '148', 4: '149', 5: '150', 6: '151', 7: '152', 8: '153', 9: '154', 10: '155', 11: '156', 12: '157', 13: '158', 14: '160', 15: '162', 16: '165', 17: '167', 18: '168', 19: '169', 20: '170', 21: '171', 22: '173', 23: '174', 24: '176', 25: '356', 26: '360', 27: '361', 28: '362', 29: '364', 30: '375', 31: '376', 32: '394', 33: '408', 34: '409', 35: '685', 36: '686', 37: '689', 38: '756', 39: '758', 40: '760', 41: '761'}\n",
            "42 ['142', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '160', '162', '165', '167', '168', '169', '170', '171', '173', '174', '176', '356', '360', '361', '362', '364', '375', '376', '394', '408', '409', '685', '686', '689', '756', '758', '760', '761']\n"
          ]
        }
      ],
      "source": [
        "labels = [label for label in dataset['train'].features.keys() if label not in ['id', 'text']]\n",
        "labels.sort()\n",
        "\n",
        "print(len(labels), list(enumerate(labels)))\n",
        "id2label = {idx:label for idx, label in enumerate(labels)}\n",
        "print(id2label)\n",
        "label2id = {label:idx for idx, label in enumerate(labels)}\n",
        "print(len(labels), labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJ3Teyjmank2"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub.\n",
        "\n",
        "What's a bit tricky is that we also need to provide labels to the model. For multi-label text classification, this is a matrix of shape (batch_size, num_labels). Also important: this should be a tensor of floats rather than integers, otherwise PyTorch' `BCEWithLogitsLoss` (which the model will use) will complain, as explained [here](https://discuss.pytorch.org/t/multi-label-binary-classification-result-type-float-cant-be-cast-to-the-desired-output-type-long/117915/3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFWlSsbZaRLc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# examples and not example because batched=True => examples is a batch\n",
        "def preprocess_data(examples, indices):\n",
        "  # take a batch of texts\n",
        "  text = examples[\"text\"]\n",
        "  #print(\"Indices:\", indices, \"Batch size:\", len(text), \"Num labels:\", len(labels))\n",
        "\n",
        "  # encode them\n",
        "  encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "  labels_batch = {label: np.zeros(len(text)) for label in labels}                                                # validation: 42 rows: 'label': 18 x 0.0\n",
        "  #print(f\"labels_batch: zeros: {type(labels_batch)} {len(labels_batch)} {labels_batch}\")\n",
        "  #print(f\"examples.keys(): {examples.keys()}\")\n",
        "  # examples.keys(): all the column names (keys) in the batch dict \"examples\"\n",
        "  # for each k in labels, a new key-value pair k: examples[k] is added to labels_batch\n",
        "  labels_batch.update({k: [1.0 if val else 0.0 for val in examples[k]] for k in examples.keys() if k in labels}) # validation: 42 rows: 'label': 1.0 or 0.0\n",
        "\n",
        "  #print(f\"labels_batch: updated: {type(labels_batch)} {len(labels_batch)} {labels_batch}\")\n",
        "\n",
        "  # create numpy array of shape (batch_size, num_labels)\n",
        "  labels_matrix = np.zeros((len(text), len(labels)))                                                             # validation: 18 rows 42 columns\n",
        "  #print(f\"labels_matrix:{type(labels_matrix)} {labels_matrix.shape}\")\n",
        "  # fill numpy array\n",
        "  for idx, label in enumerate(labels):\n",
        "    #print(f\"idx:{idx} label:{label}\")                                                                            # labels are sorted\n",
        "    labels_matrix[:, idx] = labels_batch[label] # for each row, sets the idx-th column of labels_matrix with the values from labels_batch[label]\n",
        "\n",
        "  #print(\"First row of labels_matrix:\", labels_matrix[0])\n",
        "\n",
        "  # Add labels to encoding\n",
        "  encoding[\"labels\"] = labels_matrix.tolist()\n",
        "  print(f\"encoding['labels']: {encoding['labels']}\")\n",
        "\n",
        "\n",
        "  return encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4ENBTdulBEI"
      },
      "outputs": [],
      "source": [
        "encoded_dataset = dataset.map(preprocess_data, batched=True, remove_columns=dataset['train'].column_names, with_indices=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0enAb0W9o25W"
      },
      "outputs": [],
      "source": [
        "example = encoded_dataset['validation'][0]\n",
        "print(f\"example.keys(): {example.keys()}\")\n",
        "print(f\"example['input_ids']: {example['input_ids']}\")\n",
        "print(f\"example['token_type_ids']: {example['token_type_ids']}\")\n",
        "print(f\"example['attention_mask']: {example['attention_mask']}\")\n",
        "print(f\"example['labels']: {example['labels']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0McCtJ8HRJY"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(example['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4Dx95t2o6N9"
      },
      "outputs": [],
      "source": [
        "example = encoded_dataset['validation'][0]\n",
        "print(f\"example['labels']: {example['labels']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LAyThO7Jnvj"
      },
      "outputs": [],
      "source": [
        "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgpKXDfvKBxn"
      },
      "source": [
        "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk6Cq9duKBkA"
      },
      "outputs": [],
      "source": [
        "encoded_dataset.set_format(\"torch\")\n",
        "example = encoded_dataset['validation'][0]\n",
        "print(f\"example['labels']:  {type(example['labels'])} {example['labels'].shape}\\n{example['labels']}\")\n",
        "\n",
        "#raise Exception(\"STOP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5qSmCgWefWs"
      },
      "source": [
        "## Define model\n",
        "\n",
        "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
        "\n",
        "This is also printed by the warning.\n",
        "\n",
        "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XPL1Z_RegBF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                           problem_type=\"multi_label_classification\",\n",
        "                                                           num_labels=len(labels),\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgsREtKnMA50"
      },
      "outputs": [],
      "source": [
        "#raise Exception(\"STOP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjJGEXShp7te"
      },
      "source": [
        "## Train the model!\n",
        "\n",
        "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things:\n",
        "\n",
        "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
        "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5a8_vIKqr7P"
      },
      "outputs": [],
      "source": [
        "batch_size = 8\n",
        "metric_name = \"f1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR2GmpvDqbuZ"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir = r'C:\\tmp\\BERT_results\\output',\n",
        "    overwrite_output_dir=True,\n",
        "    logging_dir= r'C:\\tmp\\BERT_results\\logs',\n",
        "    logging_steps=50,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    eval_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=5,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=metric_name,\n",
        "    #push_to_hub=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_v2fPFFJ3-v"
      },
      "source": [
        "We are also going to compute metrics while training. For this, we need to define a `compute_metrics` function, that returns a dictionary with the desired metric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "797b2WHJqUgZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, accuracy_score, average_precision_score\n",
        "from transformers import EvalPrediction\n",
        "import torch\n",
        "\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def multi_label_metrics(predictions, labels, threshold=0.2):\n",
        "    _average = 'micro'    # 'micro' or 'weighted'\n",
        "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # next, use threshold to turn them into integer predictions\n",
        "    y_pred = np.zeros(probs.shape)\n",
        "    y_pred[np.where(probs >= threshold)] = 1\n",
        "    # finally, compute metrics\n",
        "    y_true               = labels\n",
        "\n",
        "    f1                   = f1_score               (y_true=y_true, y_pred=y_pred, average=_average)    #, zero_division=1)\n",
        "    precision            = precision_score        (y_true=y_true, y_pred=y_pred, average=_average)    #, zero_division=1)\n",
        "    recall               = recall_score           (y_true=y_true, y_pred=y_pred, average=_average)    #, zero_division=1)\n",
        "    roc_auc              = roc_auc_score          (y_true=y_true, y_score=probs, average=_average)\n",
        "    precision_recall_auc = average_precision_score(y_true=y_true, y_score=probs, average=_average)\n",
        "    accuracy             = accuracy_score         (y_true=y_true, y_pred=y_pred)\n",
        "\n",
        "    # return as dictionary\n",
        "    metrics = {'f1'                  : f1,\n",
        "               'precision'           : precision,\n",
        "               'recall'              : recall,\n",
        "               'roc_auc'             : roc_auc,\n",
        "               'precision_recall_auc': precision_recall_auc,\n",
        "               'accuracy'            : accuracy}\n",
        "    return metrics\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    result = multi_label_metrics(\n",
        "        predictions=preds,\n",
        "        labels=p.label_ids)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxNo4_TsvzDm"
      },
      "source": [
        "Let's verify a batch as well as a forward pass:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlOgGiojuWwG"
      },
      "outputs": [],
      "source": [
        "encoded_dataset['train'][0]['labels'].type()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y41Kre_jvD7x"
      },
      "outputs": [],
      "source": [
        "encoded_dataset['train']['input_ids'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxWcnZ8ku12V"
      },
      "outputs": [],
      "source": [
        "#forward pass\n",
        "print(f\"inputids: {type(encoded_dataset['train']['input_ids'][0])} {encoded_dataset['train']['input_ids'][0].shape}\")\n",
        "print(f\"attention_mask: {type(encoded_dataset['train']['attention_mask'][0])} {encoded_dataset['train']['attention_mask'][0].shape}\")\n",
        "print(f\"labels: {type(encoded_dataset['train'][0]['labels'])} {encoded_dataset['train'][0]['labels'].shape}\")\n",
        "\n",
        "outputs = model(input_ids=encoded_dataset['train']['input_ids'][0].unsqueeze(0),\n",
        "                attention_mask=encoded_dataset['train']['attention_mask'][0].unsqueeze(0),\n",
        "                labels=encoded_dataset['train'][0]['labels'].unsqueeze(0))\n",
        "outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-X2brZcv0X6"
      },
      "source": [
        "Let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chq_3nUz73ib"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXmFds8js6P8"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiloh9eMK91o"
      },
      "source": [
        "## Evaluate\n",
        "\n",
        "After training, we evaluate our model on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMlebJ83LRYG"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nmvJp0pLq-3"
      },
      "source": [
        "## Inference\n",
        "\n",
        "Let's test the model on a new sentence:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHY6-zJ1YVDb"
      },
      "source": [
        "id: 323697\n",
        "\"Voor een klant van Talencia ben ik opzoek naar een Senior Full Stack Developer (Java & Angular) Job beschrijving Als Developer zal je een bestaand team toevoegen en meewerken aan de buitbouw van webapplicaties op Azure. Dit is om bestaande applicaties te vervangen die end-of-live zijn. Het project is al in volle realisatie. Profiel Zeer goede kennis van Java en Angular Goede kennis van Azure DevOps, AKS,.. is een grote pluspunt Kennis van Docker/ SQL/ OAuth/PWA/ RESTful API is vereist Taal: Nederlands met kennis van Engels Extra informatie Teamspeler met ervaring in Agile methodiek is vereist. Als je meer informatie wilt en dit klinkt interessant voor u, aarzel dan niet om uw meest recente CV door te sturen. Het kan zijn dat ik niet beschik over uw meest recente CV en dat ik daarom u deze opportuniteit doorstuur dat niet geschikt is voor u. Als u iemand kent dat deze missie interessant zou vinden mag u deze vacature doorsturen. Met vriendelijke groeten,\"\n",
        "\n",
        "['142', '147', '149', '154', '156', '157', '173', '409', '685', '689']\n",
        "\n",
        "---\n",
        "\n",
        "id: 323611,\"Atcon Global - Project Management Officer / PMO team management Atcon Global For one of our clients, we are looking for an experienced Project Management Officer (PMO) / Project Manager (PM) for permanent employment in the Flanders region. Your role? As a PMO, you will play a crucial role in setting up and improving our project management processes. You will not only be responsible for developing PM standards, but also for carrying out projects independently as a Project Manager. Your duties and responsibilities will include: Developing PMO and project management standards Executing and managing complex digital projects Oversee project progress and report to senior management Follow-up of project budgets, project selection, capacity planning and resource management Coaching and training project managers Identifying and managing project risks Promote continuous improvement in the project management domain Collaborate with stakeholders and external partners Who are we looking for? Bachelor's or master's degree 5+ years in a similar role in a dynamic organization Expertise in project management methods (Agile, Scrum, Lean, Kanban) Strong analytical and problem-solving skills Excellent communication and stakeholder management Experience in team management with clear objectives Proactive, Hands-on mentality and result-oriented Fluent in Dutch and English; French is a plus What's on offer? A dynamic and varied role in a growing, ambitious and innovative company Numerous opportunities for personal growth and career development A competitive salary with customizable benefits A friendly, collegial working atmosphere Flexible working hours, possibility to work from home\",\"171,170,794,800,798,797,138,139,352\"\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fxjfr8PLD42"
      },
      "outputs": [],
      "source": [
        "text = \"Voor een klant van Talencia ben ik opzoek naar een Senior Full Stack Developer (Java & Angular) Job beschrijving Als Developer zal je een bestaand team toevoegen en meewerken aan de buitbouw van webapplicaties op Azure. Dit is om bestaande applicaties te vervangen die end-of-live zijn. Het project is al in volle realisatie. Profiel Zeer goede kennis van Java en Angular Goede kennis van Azure DevOps, AKS,.. is een grote pluspunt Kennis van Docker/ SQL/ OAuth/PWA/ RESTful API is vereist Taal: Nederlands met kennis van Engels Extra informatie Teamspeler met ervaring in Agile methodiek is vereist. Als je meer informatie wilt en dit klinkt interessant voor u, aarzel dan niet om uw meest recente CV door te sturen. Het kan zijn dat ik niet beschik over uw meest recente CV en dat ik daarom u deze opportuniteit doorstuur dat niet geschikt is voor u. Als u iemand kent dat deze missie interessant zou vinden mag u deze vacature doorsturen. Met vriendelijke groeten\"\n",
        "#text = \"Atcon Global - Project Management Officer / PMO team management Atcon Global For one of our clients, we are looking for an experienced Project Management Officer (PMO) / Project Manager (PM) for permanent employment in the Flanders region. Your role? As a PMO, you will play a crucial role in setting up and improving our project management processes. You will not only be responsible for developing PM standards, but also for carrying out projects independently as a Project Manager. Your duties and responsibilities will include: Developing PMO and project management standards Executing and managing complex digital projects Oversee project progress and report to senior management Follow-up of project budgets, project selection, capacity planning and resource management Coaching and training project managers Identifying and managing project risks Promote continuous improvement in the project management domain Collaborate with stakeholders and external partners Who are we looking for? Bachelor's or master's degree 5+ years in a similar role in a dynamic organization Expertise in project management methods (Agile, Scrum, Lean, Kanban) Strong analytical and problem-solving skills Excellent communication and stakeholder management Experience in team management with clear objectives Proactive, Hands-on mentality and result-oriented Fluent in Dutch and English; French is a plus What's on offer? A dynamic and varied role in a growing, ambitious and innovative company Numerous opportunities for personal growth and career development A competitive salary with customizable benefits A friendly, collegial working atmosphere Flexible working hours, possibility to work from home\"\n",
        "encoding = tokenizer(text, return_tensors=\"pt\")\n",
        "encoding = {k: v.to(trainer.model.device) for k,v in encoding.items()}\n",
        "\n",
        "outputs = trainer.model(**encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8THm5-XgNHPm"
      },
      "source": [
        "The logits that come out of the model are of shape (batch_size, num_labels). As we are only forwarding a single sentence through the model, the `batch_size` equals 1. The logits is a tensor that contains the (unnormalized) scores for every individual label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOBosj4UL2tU"
      },
      "outputs": [],
      "source": [
        "logits = outputs.logits\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC4XdDaHNVcd"
      },
      "source": [
        "To turn them into actual predicted labels, we first apply a sigmoid function independently to every score, such that every score is turned into a number between 0 and 1, that can be interpreted as a \"probability\" for how certain the model is that a given class belongs to the input text.\n",
        "\n",
        "Next, we use a threshold (typically, 0.5) to turn every probability into either a 1 (which means, we predict the label for the given example) or a 0 (which means, we don't predict the label for the given example)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2ojrqxoerup"
      },
      "outputs": [],
      "source": [
        "# apply sigmoid + threshold\n",
        "import torch\n",
        "\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs = sigmoid(logits.squeeze().cpu())\n",
        "predictions = np.zeros(probs.shape)\n",
        "predictions[np.where(probs >= 0.2)] = 1\n",
        "# turn predicted id's into actual label names\n",
        "predicted_labels = [id2label[idx] for idx, label in enumerate(predictions) if label == 1.0]\n",
        "print(predicted_labels)\n",
        "\n",
        "raise Exception(\"STOP\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdg0HQ5LcKkE"
      },
      "source": [
        "**id**: 323697\n",
        "\n",
        "**MySQL**: \"142,189,190,754,208,794,676,811,812,139,138\" (only 142=\"Developer / Analyst Programmer\") is a 7-skill)\n",
        "\n",
        "**predicted_labels**: ['148', '152', '154', '409'] : all are 7-skills: 148=\"Technical Analyst\", 152=\"Technical Writer\", 154=\"Database Admininistrator\"\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**id**: 323611\n",
        "\n",
        "**MySQL**: \"171,170,794,800,798,797,138,139,352\"            \n",
        "           171: Project Mgmt Officer (PMO)  \n",
        "           170: Project Manager / Coordinator\n",
        "\n",
        "**predicted labels**: 409:  \n",
        "                      409: \"SOA Specialist\" (SOA: Service Oriented Architecture)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZJG-hcc_dzD"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"my_model\")    # Save the trained model and tokenizer: saves the model weights, the tokenizer, the model configuration file (\"config.json\")\n",
        "\n",
        "import json\n",
        "\n",
        "with open(\"training_metrics.json\", 'w') as f:\n",
        "    json.dump(trainer.state.log_history,f)\n",
        "\n",
        "with open(\"eval_metrics.json\", 'w') as f:\n",
        "    json.dump(eval_results, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNJ8nrkP5dz3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy files to your Google Drive\n",
        "!cp -r my_model /content/drive/MyDrive/\n",
        "!cp training_metrics.json /content/drive/MyDrive/\n",
        "!cp eval_metrics.json /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGdHS6CHCoWH"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "#!zip -r my_model.zip my_model\n",
        "#!split -b 100M my_model.zip my_model_part_\n",
        "#!unzip - my_model.zip\n",
        "\n",
        "# for part in ['my_model_part_aa', 'my_model_part_ab', 'my_model_part_ac']:  # Adjust based on number of parts\n",
        "#    files.download(part)\n",
        "#files.download(\"my_model_part_aa\")\n",
        "#files.download(\"my_model_part_ab\")\n",
        "#files.download(\"my_model_part_ac\")\n",
        "#files.download(\"my_model_part_ad\")\n",
        "#!md5sum my_model.zip\n",
        "#files.download(\"training_metrics.json\")\n",
        "#files.download(\"eval_metrics.json\")\n",
        "\n",
        "#uploaded = files.upload()\n",
        "#!md5sum my_model.zip\n",
        "#!md5sum training_metrics.json\n",
        "#!md5sum eval_metrics.json\n",
        "\n",
        "#!unzip my_model.zip -d my_model_unzip\n",
        "\n",
        "#raise Exception(\"STOP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "MNNg-HJE93lq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/my_model_unzip/my_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/my_model_unzip/my_model\")\n",
        "\n",
        "import json\n",
        "with open(\"/content/training_metrics.json\", 'r') as f:\n",
        "    training_metrics = json.load(f)\n",
        "with open(\"/content/eval_metrics.json\", 'r') as f:\n",
        "    eval_metrics = json.load(f)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "#text = \"Voor een klant van Talencia ben ik opzoek naar een Senior Full Stack Developer (Java & Angular) Job beschrijving Als Developer zal je een bestaand team toevoegen en meewerken aan de buitbouw van webapplicaties op Azure. Dit is om bestaande applicaties te vervangen die end-of-live zijn. Het project is al in volle realisatie. Profiel Zeer goede kennis van Java en Angular Goede kennis van Azure DevOps, AKS,.. is een grote pluspunt Kennis van Docker/ SQL/ OAuth/PWA/ RESTful API is vereist Taal: Nederlands met kennis van Engels Extra informatie Teamspeler met ervaring in Agile methodiek is vereist. Als je meer informatie wilt en dit klinkt interessant voor u, aarzel dan niet om uw meest recente CV door te sturen. Het kan zijn dat ik niet beschik over uw meest recente CV en dat ik daarom u deze opportuniteit doorstuur dat niet geschikt is voor u. Als u iemand kent dat deze missie interessant zou vinden mag u deze vacature doorsturen. Met vriendelijke groeten\"\n",
        "text = \"Atcon Global - Project Management Officer / PMO team management Atcon Global For one of our clients, we are looking for an experienced Project Management Officer (PMO) / Project Manager (PM) for permanent employment in the Flanders region. Your role? As a PMO, you will play a crucial role in setting up and improving our project management processes. You will not only be responsible for developing PM standards, but also for carrying out projects independently as a Project Manager. Your duties and responsibilities will include: Developing PMO and project management standards Executing and managing complex digital projects Oversee project progress and report to senior management Follow-up of project budgets, project selection, capacity planning and resource management Coaching and training project managers Identifying and managing project risks Promote continuous improvement in the project management domain Collaborate with stakeholders and external partners Who are we looking for? Bachelor's or master's degree 5+ years in a similar role in a dynamic organization Expertise in project management methods (Agile, Scrum, Lean, Kanban) Strong analytical and problem-solving skills Excellent communication and stakeholder management Experience in team management with clear objectives Proactive, Hands-on mentality and result-oriented Fluent in Dutch and English; French is a plus What's on offer? A dynamic and varied role in a growing, ambitious and innovative company Numerous opportunities for personal growth and career development A competitive salary with customizable benefits A friendly, collegial working atmosphere Flexible working hours, possibility to work from home\"\n",
        "encoding = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Define the device based on availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Move the model to the device\n",
        "model.to(device)\n",
        "# Move encoding to the device of the model\n",
        "encoding = {k: v.to(device) for k,v in encoding.items()}\n",
        "\n",
        "# Perform inference\n",
        "with torch.no_grad():    # no gradients needed for inference. Forward pass\n",
        "    outputs = model(**encoding)\n",
        "\n",
        "# Get logits from the model's output\n",
        "logits = outputs.logits\n",
        "\n",
        "# Apply softmax/sigmoid based on the type of classification\n",
        "if model.config.num_labels == 1:\n",
        "    probs = torch.sigmoid(logits.squeeze())\n",
        "else:\n",
        "    #probs = torch.softmax(logits, dim=1).squeeze()\n",
        "    probs = torch.sigmoid(logits)\n",
        "\n",
        "\n",
        "\n",
        "# To get predictions\n",
        "threshold = 0.5\n",
        "#predictions = torch.where(probs >= threshold, torch.ones_like(probs), torch.zeros_like(probs))\n",
        "#predictions = torch.argmax(probs, dim=-1) if model.config.num_labels > 1 else torch.where(probs >= threshold, torch.ones_like(probs), torch.zeros_like(probs))\n",
        "predictions = (probs > threshold).float()\n",
        "print(\"Predictions:\", predictions)\n",
        "print()\n",
        "\n",
        "# Turn predicted id's into actual label names\n",
        "print(\"Probabilites:\", probs)\n",
        "\n",
        "#[id2label[idx] for idx, label in enumerate(predictions['labels']) if label == 1.0]\n",
        "\n",
        "#predicted_labels = [id2label[idx.item()] for idx in predictions]\n",
        "#print(predicted_labels)\n",
        "\n",
        "for label, prob, pred in zip(labels, probs.squeeze(), predictions.squeeze()):\n",
        "  print(f\"Label: {label}: Probability: {prob.item():.4f} {int(pred.item())}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzwcmVVvXgXR",
        "outputId": "55135479-7654-424f-ed3f-6e41d4845045"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Predictions: tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
            "         0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0.]])\n",
            "\n",
            "Probabilites: tensor([[0.4818, 0.5289, 0.4301, 0.4996, 0.4285, 0.4274, 0.4943, 0.4929, 0.4709,\n",
            "         0.4609, 0.5082, 0.4695, 0.5016, 0.4690, 0.5050, 0.5239, 0.3841, 0.4697,\n",
            "         0.4594, 0.4367, 0.5199, 0.4801, 0.5259, 0.5017, 0.5355, 0.3862, 0.5289,\n",
            "         0.4051, 0.4268, 0.5097, 0.3299, 0.4068, 0.4356, 0.3321, 0.4390, 0.3705,\n",
            "         0.4716, 0.4263, 0.2948, 0.3964, 0.3601, 0.3954]])\n",
            "Label: 142: Probability: 0.4818 0\n",
            "Label: 146: Probability: 0.5289 1\n",
            "Label: 147: Probability: 0.4301 0\n",
            "Label: 148: Probability: 0.4996 0\n",
            "Label: 149: Probability: 0.4285 0\n",
            "Label: 150: Probability: 0.4274 0\n",
            "Label: 151: Probability: 0.4943 0\n",
            "Label: 152: Probability: 0.4929 0\n",
            "Label: 153: Probability: 0.4709 0\n",
            "Label: 154: Probability: 0.4609 0\n",
            "Label: 155: Probability: 0.5082 1\n",
            "Label: 156: Probability: 0.4695 0\n",
            "Label: 157: Probability: 0.5016 1\n",
            "Label: 158: Probability: 0.4690 0\n",
            "Label: 160: Probability: 0.5050 1\n",
            "Label: 162: Probability: 0.5239 1\n",
            "Label: 165: Probability: 0.3841 0\n",
            "Label: 167: Probability: 0.4697 0\n",
            "Label: 168: Probability: 0.4594 0\n",
            "Label: 169: Probability: 0.4367 0\n",
            "Label: 170: Probability: 0.5199 1\n",
            "Label: 171: Probability: 0.4801 0\n",
            "Label: 173: Probability: 0.5259 1\n",
            "Label: 174: Probability: 0.5017 1\n",
            "Label: 176: Probability: 0.5355 1\n",
            "Label: 356: Probability: 0.3862 0\n",
            "Label: 360: Probability: 0.5289 1\n",
            "Label: 361: Probability: 0.4051 0\n",
            "Label: 362: Probability: 0.4268 0\n",
            "Label: 364: Probability: 0.5097 1\n",
            "Label: 375: Probability: 0.3299 0\n",
            "Label: 376: Probability: 0.4068 0\n",
            "Label: 394: Probability: 0.4356 0\n",
            "Label: 408: Probability: 0.3321 0\n",
            "Label: 409: Probability: 0.4390 0\n",
            "Label: 685: Probability: 0.3705 0\n",
            "Label: 686: Probability: 0.4716 0\n",
            "Label: 689: Probability: 0.4263 0\n",
            "Label: 756: Probability: 0.2948 0\n",
            "Label: 758: Probability: 0.3964 0\n",
            "Label: 760: Probability: 0.3601 0\n",
            "Label: 761: Probability: 0.3954 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YvipL3S0g8EL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}