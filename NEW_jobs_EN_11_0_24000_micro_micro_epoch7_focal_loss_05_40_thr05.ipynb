{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudelepere/ML_GitHub/blob/main/NEW_jobs_EN_11_0_24000_micro_micro_epoch7_focal_loss_05_40_thr05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OIjOPWowcJq",
        "outputId": "484bf777-c3b3-44db-d9f4-fe20ffbd1c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q accelerate\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q scikit-learn\n",
        "!pip install -q transformers datasets  # 2 Hugging Face libraries\n",
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ync6uXy-wcJs"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "\n",
        "from contextlib             import suppress\n",
        "from datasets               import DatasetDict\n",
        "from google.colab           import auth, drive, files, userdata\n",
        "from huggingface_hub        import create_branch, create_repo, HfApi, login, upload_file, hf_hub_download, whoami\n",
        "from huggingface_hub.errors import RepositoryNotFoundError\n",
        "from sklearn.metrics        import f1_score, precision_score, recall_score, roc_auc_score, average_precision_score, accuracy_score, hamming_loss, classification_report,  precision_recall_fscore_support\n",
        "from torch.optim            import AdamW\n",
        "from torch.utils.data       import DataLoader\n",
        "from tqdm.auto              import tqdm\n",
        "from transformers           import EvalPrediction, LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainerCallback, TrainingArguments\n",
        "#from transformers           import logging as transformers_logging\n",
        "from torch.nn               import BCEWithLogitsLoss, Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQJHNH0zeS41",
        "outputId": "cd74e339-aa4a-41ca-e199-067f3acb5ba9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content\n"
          ]
        }
      ],
      "source": [
        "# Is /content the current directory?\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Ensure the logs directory exists\n",
        "os.makedirs('/content/logs', exist_ok=True)\n",
        "\n",
        "# Create handlers for both file and console output\n",
        "file_handler = logging.FileHandler('/content/logs/training.log')\n",
        "file_handler.setLevel(logging.INFO)                               # Log level for file\n",
        "\n",
        "#console_handler = logging.StreamHandler()\n",
        "#console_handler.setLevel(logging.INFO)                            # Log level for console\n",
        "\n",
        "# Create a formatter and attach it to both handlers\n",
        "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "file_handler.setFormatter(formatter)\n",
        "#console_handler.setFormatter(formatter)\n",
        "\n",
        "# Add the handlers to the root logger\n",
        "logger = logging.getLogger()\n",
        "#logger.setLevel(logging.INFO)\n",
        "logger.addHandler(file_handler)\n",
        "#logger.addHandler(console_handler)\n",
        "\n",
        "#transformers_logging.set_verbosity_error()  # Only show errors, suppress info\n",
        "\n",
        "# Remove all existing handlers of type StreamHandler\n",
        "#for handler in logger.handlers[:]:\n",
        "#    if isinstance(handler, logging.StreamHandler):\n",
        "#        logger.removeHandler(handler)\n",
        "\n",
        "# Verify by printing current handlers\n",
        "#print(\"handlers\", logger.handlers)  # Should only show FileHandler\n",
        "\n",
        "# Test logging to ensure both file and console work\n",
        "logging.info(\"Testing log before training starts.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXMnrvto55rW"
      },
      "source": [
        "## Google Cloud Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dLG2EnRQ53G4"
      },
      "outputs": [],
      "source": [
        "#auth.authenticate_user()  # user = c.lepere@ictjob.be"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nkZXVHOruti"
      },
      "source": [
        "## Get skills and jobs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCDIh_QXrmdI",
        "outputId": "14132fbc-087e-4e01-d9de-9b750a8b119b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasetDict_zip_file_name: dataset_EN_11_0_24000.zip\n",
            "datasetDict_dir_name     : dataset_EN_11_0_24000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "skills         = 11\n",
        "all_rows_low   = 0\n",
        "all_rows_high  = 24000 # 120 1200 12000 24000 48000\n",
        "num_datapoints = all_rows_high - all_rows_low\n",
        "\n",
        "datasetDict_zip_file_name = f\"dataset_EN_{skills}_{all_rows_low}_{all_rows_high}.zip\"\n",
        "datasetDict_dir_name      = os.path.splitext(datasetDict_zip_file_name)[0]\n",
        "\n",
        "print(f\"datasetDict_zip_file_name: {datasetDict_zip_file_name}\")\n",
        "print(f\"datasetDict_dir_name     : {datasetDict_dir_name}\")\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjjlUtVRMc_R"
      },
      "source": [
        "## Averages\n",
        "<pre>\n",
        "- per sample: metrics are computed for each sample (= for each instance, = for each row of y_true and y_pred), and then averaged across all samples.\n",
        "- per label : metrics are computed for each label separately, and then averaged across all labels.\n",
        "- per batch : metrics are computed for each batch, and then averaged across all batches.\n",
        "\n",
        "- 'micro': Calculate metrics globally by counting the total true positives, false negatives and false positives.\n",
        "           Gives more weight to frequent labels → best for imbalanced datasets where frequent labels are more important.\n",
        "- 'macro': Calculate metrics for each label separately, and find their unweighted mean.\n",
        "           This does not take label imbalance into account. This is fine for balanced datasets but not for imbalanced datasets since rare labels are given equal weights.\n",
        "           Averages the metric for each label without considering their imbalance, without considering label frequency.\n",
        "           When to use: when wanting equal importance for all labels, including rare ones.\n",
        "           Treats all labels equally → best when you care about rare labels as much as frequent ones.\n",
        "- 'weighted': Calculate metrics for each label separately, and find their average weighted by support (= the number of true instances for each label). This alters ‘macro’ to account for label imbalance;\n",
        "              it can result in an F-score that is not between precision and recall.\n",
        "              Averages per label weighted by their support, without considering label frequency.\n",
        "              When to use: when wanting to reflect label imbalance (common labels contribute more).\n",
        "              Like macro but considers label frequency → best if you want a compromise between macro and micro.\n",
        "- 'samples': Calculate metrics per sample instead of per label, and find their average (only meaningful for multilabel-classification where this differs from accuracy_score).\n",
        "             Computes the metric per sample and then averages across all samples.\n",
        "             When to use: when each sample has multiple correct labels.\n",
        "\n",
        "- 'macro' or 'weighted' AUC is often best because AUC isn't as affected by class imbalance as F1/Precision/Recall\n",
        "- 'macro'      AUC: usually the best because it treats all labels equally, avoiding the dominance of frequent labels\n",
        "- 'weighted'   AUC: similar to macro but considers label frequency\n",
        "- 'macro'   PR AUC: best for imbalanced datasets because it treats rare labels fairly\n",
        "- 'weighted PR AUC: also good, but slightly biased toward frequent labels\n",
        "\n",
        "PR AUC is better than ROC AUC when you care about positive examples in imbalanced data.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EBSQ6pLkMmhI"
      },
      "outputs": [],
      "source": [
        "training_average   = 'micro'             # 'weighted' (best) or 'samples\n",
        "evaluation_average = 'micro'             # 'macro'    (best) or 'weighted'\n",
        "test_average       = evaluation_average  #\n",
        "prediction_average = 'micro'             # 'micro'    (best) or 'samples' (prediction of unseen datapoints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgxRu9m4Kb4_"
      },
      "source": [
        "## Tune thresholds?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1KUJss-mKmRw"
      },
      "outputs": [],
      "source": [
        "threshold_tuning = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBe6WmEbwq2W"
      },
      "source": [
        "## Upload to HF Hub?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "riGK-dwYr1kw"
      },
      "outputs": [],
      "source": [
        "upload_to_HF = True\n",
        "repo_id      = ''\n",
        "timestamp    = ''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98L73sydik95"
      },
      "source": [
        "## Hugging Face Hub (HF Hub) authenticate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNxYo9txwcJs",
        "outputId": "8e6ac065-9e1d-4e8d-d752-db2c104304cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user: {'type': 'user', 'id': '66ec3d5f61228b02f8780beb', 'name': 'claudelepere', 'fullname': 'Claude Lepère', 'isPro': False, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/66ec3d5f61228b02f8780beb/gvnf9pvm2KvE90ETMUQo3.jpeg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'jobs_token', 'role': 'fineGrained', 'createdAt': '2025-01-04T17:44:35.493Z', 'fineGrained': {'canReadGatedRepos': False, 'global': [], 'scoped': [{'entity': {'_id': '66ec3d5f61228b02f8780beb', 'type': 'user', 'name': 'claudelepere'}, 'permissions': ['repo.content.read', 'repo.write']}]}}}}\n"
          ]
        }
      ],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "  os.environ[\"HF_TOKEN\"] = userdata.get(\"HF_TOKEN\")    # Store the key in os.environ\n",
        "  hf_token               = os.environ.get('HF_TOKEN')\n",
        "\n",
        "  login(token=hf_token)\n",
        "\n",
        "  # Check\n",
        "  user = whoami(token=hf_token)\n",
        "  assert user['name'] == 'claudelepere', f\"{user['name']} is not claudelepere\"\n",
        "  print(f\"user: {user}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPBlVmE3wcJv"
      },
      "source": [
        "## repo_id, branch, model and dataset repos on HF Hub\n",
        "**1 repo = 1 model and 1 tokenizer**\n",
        "\n",
        "**branch = revision**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1haRyaUwcJv",
        "outputId": "f7a0837e-19ce-419a-cc2a-1ed028b57a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Repo Url: https://huggingface.co/claudelepere/jobs_EN_9_0_1200_micro_micro_epoch5_tuned_thresholds created successfully as a private repo\n",
            "Dataset Repo Url: https://huggingface.co/datasets/claudelepere/jobs_EN_9_0_1200_micro_micro_epoch5_tuned_thresholds created successfully as a private repo\n"
          ]
        }
      ],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "  if threshold_tuning:\n",
        "    repo_id   = 'claudelepere/jobs_EN_9_0_1200_micro_micro_epoch5_tuned_thresholds'\n",
        "    #repo_id   = 'claudelepere/jobs_EN_11_0_12000_tuned_thresholds'\n",
        "  else:\n",
        "    repo_id   = 'claudelepere/jobs_EN_9_0_1200_micro_micro_epoch5'\n",
        "    #repo_id   = 'claudelepere/jobs_EN_11_0_12000'\n",
        "  timestamp = f\"{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
        "\n",
        "  model_repoUrl   = create_repo(repo_id=repo_id, repo_type=\"model\",   private=True, exist_ok=True)\n",
        "  dataset_repoUrl = create_repo(repo_id=repo_id, repo_type=\"dataset\", private=True, exist_ok=True)\n",
        "\n",
        "  #create_branch(repo_id=repo_id, repo_type=\"model\",   branch=branch, exist_ok=True)\n",
        "  #create_branch(repo_id=repo_id, repo_type=\"dataset\", branch=branch, exist_ok=True)\n",
        "\n",
        "  print(f\"Model Repo Url: {model_repoUrl} created successfully as a private repo\")\n",
        "  print(f\"Dataset Repo Url: {dataset_repoUrl} created successfully as a private repo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Ct9Ki6fLLL"
      },
      "source": [
        "## HF model card\n",
        "Model card here => README.md on the HF Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G8Wn7JfxfFI0"
      },
      "outputs": [],
      "source": [
        "model_card = \"\"\"\n",
        "---\n",
        "tags:\n",
        "- \"24000\"\n",
        "---\n",
        "# Model\n",
        "Model fine-tuned on higly-imbalanced multilabel classification.\n",
        "\n",
        "## Model details\n",
        "- Language: English\n",
        "- Task: Multilabel classification\n",
        "- Architecture: Longformer\n",
        "- Pretrained model: [allenai/longformer-base-4096](https://huggingface.co/allenai/longformer-base-4096)\n",
        "- Framework: Pytorch\n",
        "- Version 1.0.0\n",
        "\n",
        "## Training Data\n",
        "- skills: 11\n",
        "- 24000 job datapoints\n",
        "\n",
        "## Fine-tuning parameters\n",
        "- batch size: 8\n",
        "- gradient accumulation: 4\n",
        "- fp16 precision\n",
        "- input tokens max length: 1024\n",
        "- epochs: 7\n",
        "- learning rate: 1e-5\n",
        "- tuned thresholds\n",
        "- attention window size: 1024\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l8mrGaAqt3a"
      },
      "source": [
        "## Save locally and upload model card to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY4jxVl1qnEy",
        "outputId": "94c988f2-d125-42a6-8161-f8e14cf144e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_card results successfully uploaded to HF Hub as model_card.md\n"
          ]
        }
      ],
      "source": [
        "if upload_to_HF is True:\n",
        "    name            = \"model_card\"\n",
        "    model_card_path = f\"{name}.md\"\n",
        "\n",
        "    with open(model_card_path, \"w\") as f:\n",
        "        f.write(model_card)\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = model_card_path,\n",
        "        path_in_repo    = 'README.md',\n",
        "        repo_id         = repo_id,\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} results successfully uploaded to HF Hub as {model_card_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhAd6EZJwcJt",
        "outputId": "07af42f4-5559-42a0-e366-ecd55c178f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Check the Python version\n",
        "print(sys.version)\n",
        "print()\n",
        "\n",
        "# Get the installed packages (you can see that conda is not installed (do not install it))\n",
        "!pip list\n",
        "print()\n",
        "\n",
        "# Check system information\n",
        "!cat /etc/os-release\n",
        "!uname -m\n",
        "print()\n",
        "\n",
        "# Check the GPU details (only if the runtime type is T4 GPU)\n",
        "#!nvidia-smi\n",
        "#print()\n",
        "\n",
        "# Check RAM\n",
        "!free -h\n",
        "print()\n",
        "\n",
        "# Check disk space\n",
        "!df -h\n",
        "print()\n",
        "\n",
        "# Get environment variables\n",
        "for key, value in os.environ.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\"\"\"\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUTMN8SSwcJt",
        "outputId": "73ddaed1-ffdb-45c2-c408-fdeda10eb768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "currentdir: /content\n"
          ]
        }
      ],
      "source": [
        "print(f\"currentdir: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIUfehpkwcJt",
        "outputId": "14d14565-621c-48f0-874f-dc60f8cb9f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr4xZXGSXsEx"
      },
      "source": [
        "## Out Of Memory (OOM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvigdvJgp8V9"
      },
      "source": [
        "### OOM: reduce batch size\n",
        "      small sizes (1 to 32):            PROs: better generalization in some cases\n",
        "                                        CONs: may produce noisier gradients\n",
        "      large sizes (128, 256, or higer): PROs: gradients are smoother, leading to more stable training\n",
        "                                        CONs: poorer generalization (overfitting) in some cases\n",
        "      intermediate sizes (32, 64):      combines the benefits of small and large sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bq0JDT07wcJt"
      },
      "outputs": [],
      "source": [
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPERKMpOqa8X"
      },
      "source": [
        "### OOM: enable gradient accumulation\n",
        "\n",
        "* compensate for smaller batch sizes by accumulating gradients over several steps\n",
        "* **effective batch size** = per-device batch size x gradient acumulation steps\n",
        "* in each iteration, the model computes the gradients, these gradients are immediately used to update the model parameters\n",
        "\n",
        "WARNING: gradient_accumulation_steps may not be None => comment it in TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nG0pflXGwcJt"
      },
      "outputs": [],
      "source": [
        "gradient_accumulation_steps = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yOaxNG3rzUt"
      },
      "source": [
        "### OOM: use PYTORCH_CUDA_ALLOC_CONF to handle memory fragmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VXrPvSWAwcJt"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmIswaWGsBBV"
      },
      "source": [
        "### OOM: check for and kill zombie processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKeGyFYHwcJu",
        "outputId": "d9312992-e677-4d12-b583-211d3a6b94a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root          85  5.4  0.0      0     0 ?        Z    18:54   0:13 [python3] <defunct>\n",
            "root          86  0.1  0.0  63780 50112 ?        S    18:54   0:00 python3 /usr/local/bin/colab-file\n",
            "root         135  1.5  0.1 779548 122944 ?       Sl   18:54   0:03 /usr/bin/python3 /usr/local/bin/j\n",
            "root         720 18.2  1.5 12386792 1349376 ?    Ssl  18:56   0:21 /usr/bin/python3 -m colab_kernel_\n",
            "root         758  0.6  0.0 544864 20200 ?        Sl   18:56   0:00 /usr/bin/python3 /usr/local/lib/p\n",
            "root        1422  0.0  0.0   7376  3456 ?        S    18:58   0:00 /bin/bash -c ps aux | grep python\n",
            "root        1424  0.0  0.0   6484  2324 ?        S    18:58   0:00 grep python\n",
            "/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n",
            "/bin/bash: -c: line 1: `kill -9 <PID>'\n",
            "Wed Mar 19 18:58:43 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0             50W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!ps aux | grep python\n",
        "!kill -9 <PID>\n",
        "if torch.cuda.is_available():\n",
        "  !nvidia-smi\n",
        "  print(torch.cuda.memory_summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpKIEUjjsO-i"
      },
      "source": [
        "### OOM: use fp16 (half precision) mixed precision training\n",
        "reduces memory requirements by up to 50%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BbyMivrEwcJu"
      },
      "outputs": [],
      "source": [
        "fp = 'fp16'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVhoxNtUwcJu"
      },
      "source": [
        "### OOM: limit the number of GPU workers:\n",
        "* 0 (default) or 1\n",
        "* in Colab dataloader_num_workers = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-elhl5Pkssq8"
      },
      "source": [
        "### OOM: reduce model size or input tokens\n",
        "* LongformerTokenizer.from_pretrained('allenai/longformer-base/large-4096'): large/base: 435M/149M parameters\n",
        "* max_length: 4096 max for Longformer\n",
        "* a single word can be equal to several tokens; stop words are **NOT discarded**!\n",
        "* word_text_length_counts_sorted:\n",
        "      jobs count                 : 50000\n",
        "      jobs count under  512 words: 44794  89.59%\n",
        "      jobs count under  640 words: 47894  95.79%\n",
        "      jobs count under  768 words: 49123  98.25%\n",
        "      jobs count under  896 words: 49691  99.38%\n",
        "      jobs count under 1024 words: 49917  99.83%\n",
        "      jobs count under 2048 words: 50000 100.00%\n",
        "      jobs count under 4096 words: 50000 100.00%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oZOpDR5JwcJu"
      },
      "outputs": [],
      "source": [
        "#max_length =  768    #      37 min    #\n",
        "max_length = 1024    #      38 min    # GPU RAM: 12.2 / 40 GB\n",
        "#max_length = 2048    # 1 hr 10 min    # GPU RAM: 21.4 / 40 GB\n",
        "#max_length = 4096    # 2 hr 10 min    # GPU RAM: 39.5 / 40 GB => OutOfMemoryError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4v9XcFLuudV"
      },
      "source": [
        "### OOM: free up GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WJNB5_2HwcJu"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVi2_ymCwcJu"
      },
      "source": [
        "### OOM: reduce the number of transformers layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "VBu-UPkq0Rq0"
      },
      "outputs": [],
      "source": [
        "# hidden_layers = 6  # default:12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qizOQRXNu54F"
      },
      "source": [
        "## epoch\n",
        "* 1 epoch is a complete pass through the entire training dataset\n",
        "* with n datapoints and batch size = b, n/b iterations to complete 1 epoch\n",
        "* 1 iteration is a single update of the model's parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KORJtBl7wcJu"
      },
      "outputs": [],
      "source": [
        "epochs = 7  #11 ou 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBRPtOsqvm2P"
      },
      "source": [
        "## learning rate\n",
        "* A common rule is to scale the learning rate proportionaly with the effective batch size\n",
        "* **note: get_linear_schedule_with_warmup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "EaoQWRXYwcJu"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-5  # 1e-5 x 32/8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1j87eP0wCR7"
      },
      "source": [
        "## threshold\n",
        "default: 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "c2Dfm6lvwcJu"
      },
      "outputs": [],
      "source": [
        "threshold = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNDt1EVUwOWE"
      },
      "source": [
        "## attention window size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "P-CmoMf9wcJ0"
      },
      "outputs": [],
      "source": [
        "attention_window = 1024 #512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPt8yoHMsksM"
      },
      "source": [
        "## Upload and unzip job dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "ggSY4TBWXfvS",
        "outputId": "39faee30-4436-45b8-b9a2-ed94a38e75c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 'dataset_EN_11_0_24000' and 'dataset_EN_11_0_24000.zip' if they were present in /content.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-20ca797a-1e5b-4ca9-b9b7-8d60b4fc5d0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-20ca797a-1e5b-4ca9-b9b7-8d60b4fc5d0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dataset_EN_11_0_24000.zip to dataset_EN_11_0_24000.zip\n",
            "'dataset_EN_11_0_24000.zip' successfully uploaded to /content.\n",
            "Unzipped to '/content/dataset_EN_11_0_24000'.\n"
          ]
        }
      ],
      "source": [
        "def upload_unzip_dataset(filename):\n",
        "    \"\"\"Upload and unzip the dataset to /content, ensuring correct placement.\"\"\"\n",
        "\n",
        "    # Get the expected directory name (same as the zip filename without extension)\n",
        "    expected_dir = os.path.splitext(filename)[0]\n",
        "\n",
        "    # Check if the file and the directory exist in /content and delete them\n",
        "    with suppress(FileNotFoundError):\n",
        "        if os.path.isdir(expected_dir):\n",
        "            shutil.rmtree(expected_dir)  # Remove directory if it exists\n",
        "        if os.path.isfile(filename):\n",
        "            os.remove(filename)          # Remove file if it exists\n",
        "\n",
        "    print(f\"Removed '{expected_dir}' and '{filename}' if they were present in /content.\")\n",
        "\n",
        "    # Upload the zip file\n",
        "    uploaded_files = files.upload()  # Prompt file upload dialog\n",
        "\n",
        "    if filename not in uploaded_files:\n",
        "        raise FileNotFoundError(f\"'{filename}' was not uploaded.\")\n",
        "\n",
        "    print(f\"'{filename}' successfully uploaded to /content.\")\n",
        "\n",
        "    # Unzip the file to /content\n",
        "    shutil.unpack_archive(filename, \"/content\")\n",
        "\n",
        "    print(f\"Unzipped to '/content/{expected_dir}'.\")\n",
        "\n",
        "# Usage\n",
        "upload_unzip_dataset(datasetDict_zip_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T90_cKa4wcJv"
      },
      "source": [
        "## W&B initialization (not used now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gweGUl--FNsZ",
        "outputId": "4adfb66b-cba6-44e0-9803-d80245df3a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run_name: EN_11_0_24000_ml1024_ep7_lr1e-05_th0.5_at1024_fp16_ba8x4\n"
          ]
        }
      ],
      "source": [
        "run_name = f\"EN_{skills}_{all_rows_low}_{all_rows_high}_ml{max_length}_ep{epochs}_lr{learning_rate}_th{threshold}_at{attention_window}_{fp}\"\n",
        "\n",
        "if 'gradient_accumulation_steps' not in globals():\n",
        "  run_name = f\"{run_name}_ba{batch_size}\"\n",
        "else:\n",
        "  run_name = f\"{run_name}_ba{batch_size}x{gradient_accumulation_steps}\"\n",
        "\n",
        "print(f\"run_name: {run_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giGsdqlUwcJz",
        "outputId": "2dfc45bb-b0bf-4720-f1a0-7bde5af7f1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclaudelepere\u001b[0m (\u001b[33mclaudelepere-c-cile-cy\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = userdata.get(\"WANDB_API_KEY\")        # Store the key in os.environ\n",
        "wandb_api_key               = os.environ.get('WANDB_API_KEY')\n",
        "wandb.login(key=wandb_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "JYJMUPCONEiD",
        "outputId": "f7023c64-fe45-4159-d4a7-bfef343793ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250319_185950-tusyq99j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification/runs/tusyq99j' target=\"_blank\">EN_11_0_24000_ml1024_ep7_lr1e-05_th0.5_at1024_fp16_ba8x4</a></strong> to <a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification' target=\"_blank\">https://wandb.ai/claudelepere-c-cile-cy/skill_classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/claudelepere-c-cile-cy/skill_classification/runs/tusyq99j' target=\"_blank\">https://wandb.ai/claudelepere-c-cile-cy/skill_classification/runs/tusyq99j</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "try:\n",
        "  wandb.init(\n",
        "      project = \"skill_classification\",\n",
        "      name    = run_name,\n",
        "      entity  = \"claudelepere-c-cile-cy\",\n",
        "      config  = {\n",
        "          \"learning_rate\": learning_rate,\n",
        "          \"epochs\"       : epochs,\n",
        "          \"batch_size\"   : batch_size\n",
        "      }\n",
        "  )\n",
        "except wandb.CommError as err:\n",
        "  print(f\"CommError: {err}\")\n",
        "except Exception as exc:\n",
        "  print(f\"Exception: {exc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfBhdTN9wcJz"
      },
      "source": [
        "## Create datasetDict (HF DatasetDict) = 3 HF Dataset, train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Fh_SgQD9wcJz"
      },
      "outputs": [],
      "source": [
        "datasetDict = DatasetDict.load_from_disk(datasetDict_dir_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcF4Gm8GFNsc",
        "outputId": "b5afe46c-aa1a-4de9-e61e-acd8b52fc5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasetDict: <class 'datasets.dataset_dict.DatasetDict'> {'train': (19200, 8), 'validation': (2400, 8), 'test': (2400, 8)}\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'text', '390', '135', '136', '137', '138', '139'],\n",
            "        num_rows: 19200\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'text', '390', '135', '136', '137', '138', '139'],\n",
            "        num_rows: 2400\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'text', '390', '135', '136', '137', '138', '139'],\n",
            "        num_rows: 2400\n",
            "    })\n",
            "})\n",
            "datasetDict.keys(): dict_keys(['train', 'validation', 'test'])\n",
            "datasetDict['train']:      <class 'datasets.arrow_dataset.Dataset'>      (19200, 8)\n",
            "datasetDict['validation']: <class 'datasets.arrow_dataset.Dataset'> (2400, 8)\n",
            "datasetDict['test']:       <class 'datasets.arrow_dataset.Dataset'>       (2400, 8)\n"
          ]
        }
      ],
      "source": [
        "print(f\"datasetDict: {type(datasetDict)} {datasetDict.shape}\\n{datasetDict}\")\n",
        "print(f\"datasetDict.keys(): {datasetDict.keys()}\")\n",
        "print(f\"datasetDict['train']:      {type(datasetDict['train'])}      {datasetDict['train'].shape}\")\n",
        "print(f\"datasetDict['validation']: {type(datasetDict['validation'])} {datasetDict['validation'].shape}\")\n",
        "print(f\"datasetDict['test']:       {type(datasetDict['test'])}       {datasetDict['test'].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unjuTtKUjZI3",
        "outputId": "905311f1-5b05-4b74-d935-e4b9ae8440a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasetDict['train'][0]: <class 'dict'> dict_keys(['id', 'text', '390', '135', '136', '137', '138', '139'])\n",
            "{'id': 196243, 'text': \"Vivid Resourcing - Software Engineer   React.JS Node.js Vue.js Nest.JS   Vivid Resourcing   I'm partnered with a startup based in Brussels who are looking for an experienced Software Engineer to strengthen it's development team. The client created an AI-enabled Intelligence Platform for business enterprises. This platform analyses significant competitors, industry trends, market dynamics, new technologies, and business ecosystem evolutions to ensure that companies remain constantly up date. You'll be responsible for managing the interchange of data between the server and the users. Your key tasks will be developing the server-side logic, defining and maintaining the core database, and guaranteeing front-end performance and responsiveness. You'll work closely with other teams such as Product Managers and Data Engineers. Your profile At least 3+ Years of experience with JavaScript. Extensive experience developing frontend applications using React and related libraries. Experience with Node.js is a bonus Experience working in a high-growth, (SaaS) startup, and scale-up environment. Expertise in RESTful API's and relational databases. Fluent English (Dutch or French is a plus) Degree in IT or Equivalent. The offer €3500- 6,500 Gross (dependent on experience) Hybrid work location (on-site/remote). Company Car. Group & Health insurances Stock Options NET allowances. Phone & subscription. A fun team to be in, with high standards and a culture of transparency and collaboration?? If this role could interest you, contact me.\", '390': False, '135': False, '136': False, '137': True, '138': True, '139': True}\n"
          ]
        }
      ],
      "source": [
        "example = datasetDict['train'][0]\n",
        "print(f\"datasetDict['train'][0]: {type(example)} {example.keys()}\\n{example}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEgARWcywcJz"
      },
      "source": [
        "## Create labels (list), id2label (dict) and label2id (dict).\n",
        "* dataset 7_1000_125_125  ,  48 labels\n",
        "* dataset 7_128_18_54     ,  42 labels\n",
        "* dataset 8910_1087_68_204, 206 labels\n",
        "* dataset 11_1000         ,   6 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv6FWVzRwcJz",
        "outputId": "8bce35f7-68c6-4dae-abdf-3dac1784684c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels: <class 'list'> 6\n",
            "['390', '135', '136', '137', '138', '139']\n",
            "id2label: <class 'dict'> 6\n",
            "{0: '390', 1: '135', 2: '136', 3: '137', 4: '138', 5: '139'}\n",
            "label2id: <class 'dict'> 6\n",
            "{'390': 0, '135': 1, '136': 2, '137': 3, '138': 4, '139': 5}\n"
          ]
        }
      ],
      "source": [
        "labels = [label for label in datasetDict['train'].features.keys() if label not in ['id', 'text']]\n",
        "print(f\"labels: {type(labels)} {len(labels)}\\n{labels}\")\n",
        "\n",
        "num_labels = len(labels)\n",
        "\n",
        "id2label = {idx: label for idx, label in enumerate(labels)}\n",
        "print(f\"id2label: {type(id2label)} {len(id2label)}\\n{id2label}\")\n",
        "\n",
        "label2id = {label: idx for idx, label in enumerate(labels)}\n",
        "print(f\"label2id: {type(label2id)} {len(label2id)}\\n{label2id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_TdBZOGwcJ0"
      },
      "source": [
        "## Load the pretrained tokenizer and the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tL1IlzvfwcJ0"
      },
      "outputs": [],
      "source": [
        "model_name = \"allenai/longformer-base-4096\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "9eeb1118bee8461f91d8c156ed3f270f",
            "f703be34c38d48349e74d7a1660123d5",
            "3629050037d5487488ca0338b4d4a306",
            "75c90dd61a5e4d47beb5693aa119245a",
            "191530e94c524e5da7f3c899da8e0442",
            "d6ceef31e9d043f19f13e5460810ac3f",
            "beedfe692f2844199fec5f69e6c2f9c6",
            "7a7bcf90a7594d018f9742759beb7e3a",
            "7272b2c4bc874beb8f9f45d9a8a59895",
            "18ab4b0f21af431aadc337e2abeca5e8",
            "ac09aaad47184e39bb201abf08bf209c",
            "2e15bc8f3e584504ad58fd03c99d82bc",
            "31a2fed1c7504dd081c70b18cde44adc",
            "b255639f84e1448690c8bb2b6fce67eb",
            "38de7e3458be45a4aff66a3497bf718c",
            "96af2a331f6e410cb183fb576ef64418",
            "c879cf63f4144908b757b7f3f4858ddb",
            "9a875ff1ff194104a25aae3c764643de",
            "891d72ed989b4790a90b7f6c8ec9923e",
            "f3907f0cf0c040ce80a2bcc06c72ac69",
            "515ffb9db6114705bd366c194e495d60",
            "bba590745cfa4f86b93677184300b4ee",
            "c0a727faa87f49a2acf755fb70ee6312",
            "13381aeed3db4ac08e0f52106e86f196",
            "af54ce7f889d483b909e5d6038a27103",
            "fddae10fac8f428384e31df0d9c3949d",
            "bd1977ea00a54dcd81e5b5ec249c39f1",
            "738094b56a5b4ea9beaa29cb2a25bffa",
            "1dc90bee080d4c8c8b6f159db2413d99",
            "a73d3b6aaf224d32a99a78b13c434b71",
            "8a9e82da6d924e2899ef456c50d1133a",
            "3e3f4469d2b54849ad2348bb1cc15b36",
            "e713c03a042c4195a332cecf9b45ba6f",
            "6398ae9fbb5340218d336db314f68858",
            "4adc21d1beb84b488d9e7a3a0222c722",
            "e3deedb0897449849e22060dafb2dcc2",
            "0eadb18dc1ef4ea6ba6b70002da54d2e",
            "b060794f339e4211bfc21db75cdf5d39",
            "c09c23cf16e042d38a6d8ea2eaea90f3",
            "28c12f474a1844388680280509144e5d",
            "25f0d589f7d2442580a652538f9d739f",
            "991f45ebdc2745ce9cb87f6e557d7cde",
            "1d25b65b6873446eb0e31a2754fda727",
            "a79af92810e14343ae43a8ee1a4f5e7e"
          ]
        },
        "id": "mwKcOR8GwcJ0",
        "outputId": "b9c071b2-04f3-4a6d-dcf9-afb378e39db5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9eeb1118bee8461f91d8c156ed3f270f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e15bc8f3e584504ad58fd03c99d82bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0a727faa87f49a2acf755fb70ee6312"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6398ae9fbb5340218d336db314f68858"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = LongformerTokenizerFast.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "7192533171b64a38bd77441aec920aea",
            "fb645757c2ee446c9d1e53ab0fd252e0",
            "b8451f2af4894df08a5d60130ddb4a58",
            "59c67ee553944b188a41d250ed5ae05b",
            "10236bb8de4f4ecc9fb6f28b3c60c6c4",
            "2ee1fb31abe440d197bc39eaed3fb52f",
            "ca385acc53de4c7cad85f003d55a1f44",
            "2b0de8bfa51e426cbc9c6fbbf4925f98",
            "e64a31e5c387412596497eb1b60fec57",
            "7591344a75de4c96b4f8186087337d08",
            "e06aad979b784b188823b8584cbe28c3"
          ]
        },
        "id": "HTZ61-RUwcJ0",
        "outputId": "ab0f48ff-0b52-40fa-9bdb-1204b66ab86f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7192533171b64a38bd77441aec920aea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = LongformerForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels   = num_labels,\n",
        "    id2label     = id2label,\n",
        "    label2id     = label2id,\n",
        "    problem_type = 'multi_label_classification'\n",
        ")\n",
        "\n",
        "# Configure attention window size\n",
        "model.config.attention_window = attention_window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "PjLO31SssqAM"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTYt0hM5wcJ0"
      },
      "source": [
        "## Tokenize ('input_ids' and 'attention_mask'), add 'global_attention_mask' (for Longformer), add 'labels'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AFWlSsbZaRLc"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(examples, indices):\n",
        "  # Step 1: Extract text and tokenize\n",
        "  text = examples['text']             # Batch of texts\n",
        "  encoding = tokenizer(\n",
        "      text,                           # Tokenize text\n",
        "      truncation     = True,\n",
        "      padding        = 'max_length',\n",
        "      max_length     = max_length,\n",
        "      return_tensors = 'pt'           # Return PyTorch tensors\n",
        "  )\n",
        "\n",
        "  # Step 2: Create and add the global attention mask\n",
        "  global_attention_mask             = torch.zeros_like(encoding['input_ids'])  # Initialize global attention mask with zeros (same shape as input_ids)\n",
        "  global_attention_mask[:, 0]       = 1                                        # Set global attention on the first token ([CLS], token ID=0) in each sequence\n",
        "  encoding['global_attention_mask'] = global_attention_mask                    # Add the global_attention_mask to the batch\n",
        "\n",
        "  # Step 3: Create and populate the label matrix\n",
        "  labels_matrix = torch.zeros((len(text), len(labels)), dtype=torch.float32)   # Create an empty label matrix\n",
        "  #print(f\"labels_matrix: {type(labels_matrix)} {labels_matrix.shape}\")\n",
        "  #---------Populate label matrix\n",
        "  for idx, label in enumerate(labels):\n",
        "    #print(f\"idx:{idx} label:{label}\")\n",
        "    if label in examples:\n",
        "      labels_matrix[:, idx] = torch.tensor(\n",
        "          [1.0 if val else 0.0 for val in examples[label]],\n",
        "          dtype=torch.float32\n",
        "          )\n",
        "  print(f\"labels_matrix: {type(labels_matrix)} {labels_matrix.shape}\")\n",
        "\n",
        "  encoding['labels'] = labels_matrix                                           # Add labels to the encoding\n",
        "  print(f\"encoding['labels']: {type(encoding['labels'])} {encoding['labels'].shape}\")\n",
        "\n",
        "  # encoding: <class 'transformers.tokenization_utils_base.BatchEncoding'> dict_keys(['input_ids', 'attention_mask', 'global_attention_mask', 'labels'])\n",
        "  #   'input_ids': tensor([[\n",
        "  #   'attention_mask': tensor([[\n",
        "  #   'global_attention_mask': tensor([[\n",
        "  #   'labels': tensor([[\n",
        "  #print(f\"1 preprocess_data call: encoding: {type(encoding)} {encoding.keys()}\")\n",
        "\n",
        "  return encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm9REDT_wcJ0"
      },
      "source": [
        "## Create encoded_dataset (datasets.dataset_dict.DatasetDict) = 3 encoded datasets.arrow_dataset.Dataset, train, validation and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "16089e833fcf4253a422569e372d2406",
            "e67b900c418a4580a7bcacbf1ef0ff69",
            "f397977ae3e34508a127eb269f16dee4",
            "9e34df589a364b419a76368a51e7ebfa",
            "dcb0d0b121ee4c528595a09378c5c5f9",
            "dc20ae9fa2da4306b540ef2a3f1f1dc9",
            "d6a20e0b230345f4a6d4685e166f9e7f",
            "11438e55d65848218cb230cde0917cd0",
            "27f44c13afe448498cd646b6b33149b0",
            "8bb37db4a489462d8a83250e819bad59",
            "cfbd38315b52409e957d88a630c14242",
            "f35540d4e3094f29b48fc50b2bf897ae",
            "54ae25edef9e43d4ab00330683114359",
            "54d04337e8e046039d8cec2bef6e769b",
            "adae9a2d04194606aedf4520dc52ed93",
            "f3061075ebf2423dab6d9891fe293932",
            "8dd1ebaef4c24afc8085d486dd67471d",
            "2a7352ed42dc40d8b7a7133680e09800",
            "a74310decae7432aaf37be7dd22fcd20",
            "78ef9c1196ae4b868b1b7b3734298577",
            "9f20168d05f9455fbb3964ad47e8d964",
            "a8b0d50c99df43e18f52563be2843f0d",
            "0d2fd9073e6d493e8d4a550750a528f2",
            "01c1cd3e6ff74c3a85767c3fec4663e4",
            "7086e6c8501e490e9c812385dd6a91b7",
            "469668f917b54feeb6edcd9ab67963a1",
            "8f06f49fbe4e4f8ca7a1c91fcf30dc6b",
            "e70c2bf7f38043f8813478a86329f63e",
            "a6382359c74640b5af593dc696523869",
            "8df64eaa67164e4189397ce4219e5086",
            "b6c3a4d72cb54f87a93bdb8d430e1749",
            "3265c8c56c7d4685aaf944f1749252d1",
            "2acf7229cdc4490b943805e41b526fc2",
            "63f577da670e479cb6a86c3b675091cf",
            "4b406f53e8054eb084fde89625f28037",
            "95f73633c2dd47dfbaa6758490881324",
            "f833b6f83d6346419c684c619bc1bd70",
            "61b05a0b134248ae857b9e6b6fdc8a7b",
            "b091e894de3a4d3a970953763197762d",
            "f3c076334ba04d14b3a0d350f1773ea8",
            "2874efadf4cb468596702b614b1977d5",
            "2d1e6c6cc68f4ff096197c1ecdd5c6b6",
            "8a913e6da8224217954eb2b10184c4cd",
            "834266902966416081293692fe62137e"
          ]
        },
        "id": "mxLcO0XDwcJ0",
        "outputId": "6a187b32-011c-4532-b920-bf7cb076cbef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/19200 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16089e833fcf4253a422569e372d2406"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/597M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f35540d4e3094f29b48fc50b2bf897ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([200, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([200, 6])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d2fd9073e6d493e8d4a550750a528f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([400, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([400, 6])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2400 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63f577da670e479cb6a86c3b675091cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([1000, 6])\n",
            "labels_matrix: <class 'torch.Tensor'> torch.Size([400, 6])\n",
            "encoding['labels']: <class 'torch.Tensor'> torch.Size([400, 6])\n",
            "encoded_dataset: <class 'datasets.dataset_dict.DatasetDict'> shape={'train': (19200, 4), 'validation': (2400, 4), 'test': (2400, 4)}\n"
          ]
        }
      ],
      "source": [
        "encoded_dataset = datasetDict.map(\n",
        "    preprocess_data,\n",
        "    batched        = True,\n",
        "    remove_columns = datasetDict['train'].column_names,\n",
        "    with_indices   = True\n",
        ")\n",
        "\n",
        "print(f\"encoded_dataset: {type(encoded_dataset)} shape={encoded_dataset.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuft8rJe2Q03",
        "outputId": "1e176f0e-839b-41e4-ad08-f6fbe39a157f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_dataset_tensor:                          <class 'datasets.arrow_dataset.Dataset'>                              (19200, 4) {'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'global_attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None)}\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'global_attention_mask', 'labels'],\n",
            "    num_rows: 19200\n",
            "})\n",
            "train_dataset_tensor['input_ids']:             <class 'torch.Tensor'>             len=19200             shape=torch.Size([19200, 1024])            \n",
            "train_dataset_tensor['attention_mask']:        <class 'torch.Tensor'>        len=19200        shape=torch.Size([19200, 1024])       \n",
            "train_dataset_tensor['global_attention_mask']: <class 'torch.Tensor'> len=19200 shape=torch.Size([19200, 1024])\n",
            "train_dataset_tensor['labels']:                <class 'torch.Tensor'>                len=19200                shape=torch.Size([19200, 6])               \n"
          ]
        }
      ],
      "source": [
        "encoded_dataset.set_format('torch')\n",
        "train_dataset      = encoded_dataset['train']\n",
        "validation_dataset = encoded_dataset['validation']\n",
        "test_dataset       = encoded_dataset['test']\n",
        "\n",
        "print(f\"train_dataset_tensor:                          {type(train_dataset)}                              {train_dataset.shape} {train_dataset.features}\\n{train_dataset}\")\n",
        "print(f\"train_dataset_tensor['input_ids']:             {type(train_dataset['input_ids'])}             len={len(train_dataset['input_ids'])}             shape={train_dataset['input_ids'].shape}            \") #\\n{train_dataset['input_ids']}\")\n",
        "print(f\"train_dataset_tensor['attention_mask']:        {type(train_dataset['attention_mask'])}        len={len(train_dataset['attention_mask'])}        shape={train_dataset['attention_mask'].shape}       \") #\\n{train_dataset['attention_mask']}\")\n",
        "print(f\"train_dataset_tensor['global_attention_mask']: {type(train_dataset['global_attention_mask'])} len={len(train_dataset['global_attention_mask'])} shape={train_dataset['global_attention_mask'].shape}\") #\\n{train_dataset['global_attention_mask']}\")\n",
        "print(f\"train_dataset_tensor['labels']:                {type(train_dataset['labels'])}                len={len(train_dataset['labels'])}                shape={train_dataset['labels'].shape}               \") #\\n{train_dataset['labels']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynwZnA55wcJ1"
      },
      "source": [
        "## Truncated part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "brkRdqdjN-Ur"
      },
      "outputs": [],
      "source": [
        "def get_truncated_part(text):\n",
        "  tokens = tokenizer(\n",
        "      text,\n",
        "      truncation                = True,\n",
        "      padding                   = 'max_length',\n",
        "      max_length                = max_length,\n",
        "      return_overflowing_tokens = True,\n",
        "      return_tensors            = None\n",
        "  )\n",
        "  print(f\"tokens.keys(): {tokens.keys()}\")\n",
        "\n",
        "  # Get the truncated tokens\n",
        "  truncated_ids = tokens[\"input_ids\"][0]\n",
        "  print(f\"truncated_ids: {type(truncated_ids)} {truncated_ids}\")\n",
        "  #overflow_ids  = tokens[\"overflow_to_sample_mapping\"][0]\n",
        "  #print(f\"overflow_ids: {type(overflow_ids)} {overflow_ids}\")\n",
        "\n",
        "  # Decode the tokens back to text\n",
        "  truncated_text = tokenizer.decode(truncated_ids, skip_special_tokens=True)\n",
        "  #overflow_text  = tokenizer.decode(overflow_ids, skip_special_tokens=True)\n",
        "\n",
        "  print(f\"original_text :\\n{text}\")\n",
        "  print(f\"truncated_text:\\n{truncated_text}\")\n",
        "  #print(f\"overflow_text:\\n{overflow_text}\")\n",
        "\n",
        "  original_tokens  = tokenizer.tokenize(text)\n",
        "  truncated_tokens = tokenizer.tokenize(truncated_text)\n",
        "  #overflow_tokens  = tokenizer.tokenize(overflow_text)\n",
        "\n",
        "  print(f\"original_tokens count : {len(original_tokens)}\")\n",
        "  print(f\"truncated_tokens count: {len(truncated_tokens)}\")\n",
        "  #print(f\"overflow_tokens count: {len(overflow_tokens)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DD_bjwTfRiQO"
      },
      "outputs": [],
      "source": [
        "example_text = datasetDict['train'][0]['text']\n",
        "#get_truncated_part(example_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xFiZ4mYmwcJ1"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    example_text,\n",
        "    truncation     = True,\n",
        "    padding        = 'max_length',\n",
        "    max_length     = max_length,\n",
        "    return_tensors = 'pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTh2E_8iwcJ1"
      },
      "source": [
        "## Forward pass for multi-label classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_aIPMHuwcJ1",
        "outputId": "53a46172-4566-42b8-bc74-593028009085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Initializing global attention on CLS token...\n"
          ]
        }
      ],
      "source": [
        "outputs = model(\n",
        "    input_ids      = inputs.input_ids,\n",
        "    attention_mask = inputs.attention_mask\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxWcnZ8ku12V",
        "outputId": "8a52b677-28cf-4565-9d51-2c95d42df031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs: <class 'transformers.models.longformer.modeling_longformer.LongformerSequenceClassifierOutput'> odict_keys(['logits'])\n",
            "LongformerSequenceClassifierOutput(loss=None, logits=tensor([[ 0.1345, -0.1992, -0.1251,  0.0507,  0.0607,  0.2225]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None, global_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "islk-kFSs0t8",
        "outputId": "d879347a-3327-44ab-c1a9-9054c1bc8534"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits: <class 'torch.Tensor'> torch.Size([1, 6])\n",
            "tensor([[ 0.1345, -0.1992, -0.1251,  0.0507,  0.0607,  0.2225]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Logits (= raw model outputs)\n",
        "logits = outputs.logits\n",
        "print(f\"logits: {type(logits)} {logits.shape}\\n{logits}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMscqNTXuY8o",
        "outputId": "247f2143-babf-4481-b73e-8fbd7d1ea839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probs: <class 'torch.Tensor'> torch.Size([1, 6])\n",
            "tensor([[0.5336, 0.4504, 0.4688, 0.5127, 0.5152, 0.5554]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Convert logits to probabilities\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "probs   = sigmoid(logits)\n",
        "print(f\"probs: {type(probs)} {probs.shape}\\n{probs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "BZtO3uQkwcJ2"
      },
      "outputs": [],
      "source": [
        "example = encoded_dataset['train'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0enAb0W9o25W",
        "outputId": "4d759834-9c2b-46f4-f631-9087632d8338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example: <class 'dict'> dict_keys(['input_ids', 'attention_mask', 'global_attention_mask', 'labels'])\n",
            "{'input_ids': tensor([   0,  846, 6837,  ...,    1,    1,    1]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'global_attention_mask': tensor([1, 0, 0,  ..., 0, 0, 0]), 'labels': tensor([0., 0., 0., 1., 1., 1.])}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"example: {type(example)} {example.keys()}\\n{example}\")\n",
        "print()\n",
        "#print(f\"example['input_ids']: {type(example['input_ids'])} {len(example['input_ids'])}\\n{example['input_ids']}\")\n",
        "#print(f\"example['attention_mask']: {type(example['attention_mask'])} {len(example['attention_mask'])}\\n{example['attention_mask']}\")\n",
        "#print(f\"example['labels']:  {type(example['labels'])} {len(example['labels'])}\\n{example['labels']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "D0McCtJ8HRJY",
        "outputId": "f4d07672-b60f-41ac-b720-817c6bc73ab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<s>Vivid Resourcing - Software Engineer   React.JS Node.js Vue.js Nest.JS   Vivid Resourcing   I'm partnered with a startup based in Brussels who are looking for an experienced Software Engineer to strengthen it's development team. The client created an AI-enabled Intelligence Platform for business enterprises. This platform analyses significant competitors, industry trends, market dynamics, new technologies, and business ecosystem evolutions to ensure that companies remain constantly up date. You'll be responsible for managing the interchange of data between the server and the users. Your key tasks will be developing the server-side logic, defining and maintaining the core database, and guaranteeing front-end performance and responsiveness. You'll work closely with other teams such as Product Managers and Data Engineers. Your profile At least 3+ Years of experience with JavaScript. Extensive experience developing frontend applications using React and related libraries. Experience with Node.js is a bonus Experience working in a high-growth, (SaaS) startup, and scale-up environment. Expertise in RESTful API's and relational databases. Fluent English (Dutch or French is a plus) Degree in IT or Equivalent. The offer €3500- 6,500 Gross (dependent on experience) Hybrid work location (on-site/remote). Company Car. Group & Health insurances Stock Options NET allowances. Phone & subscription. A fun team to be in, with high standards and a culture of transparency and collaboration?? If this role could interest you, contact me.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "tokenizer.decode(example['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LAyThO7Jnvj",
        "outputId": "1e504779-3a60-4ccd-bd57-9231696c7574"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['137', '138', '139']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "[id2label[idx] for idx, label in enumerate(example['labels']) if label == 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHCJcLKGwcJ2"
      },
      "source": [
        "## Set PyTorch format to ensures correctness and compatibility with PyTorch pipelines\n",
        "The 3 Hugging Face Dataset are formatted as PyTorch Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "i4ENBTdulBEI"
      },
      "outputs": [],
      "source": [
        "encoded_dataset.set_format('torch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8aGgHN-BQrO"
      },
      "source": [
        "## Workflow\n",
        "\n",
        "- 3 steps: training, evaluation, test\n",
        "- 3 datasets: train, validation, test\n",
        "- 3 Trainer functions: train, evaluate, predict\n",
        "---\n",
        "* training uses train_dataset\n",
        "* evaluation uses validation_dataset\n",
        "* test uses test_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hy7jlzubwcJ6"
      },
      "source": [
        "## Training step\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "K5a8_vIKqr7P"
      },
      "outputs": [],
      "source": [
        "batch_size  = batch_size\n",
        "metric_name = \"f1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adTwB7XvFNsj",
        "outputId": "36183ee1-95fc-4bef-fed1-56f26439f892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids:              <class 'torch.Tensor'>\ttorch.Size([1024])\n",
            "attention_mask:         <class 'torch.Tensor'>\ttorch.Size([1024])\n",
            "global_attention_mask:  <class 'torch.Tensor'>\ttorch.Size([1024])\n",
            "labels:                 <class 'torch.Tensor'>\ttorch.Size([6])\n"
          ]
        }
      ],
      "source": [
        "print(f\"input_ids:              {type(encoded_dataset['train']['input_ids'][0])}\\t{encoded_dataset['train']['input_ids'][0].shape}\")\n",
        "print(f\"attention_mask:         {type(encoded_dataset['train']['attention_mask'][0])}\\t{encoded_dataset['train']['attention_mask'][0].shape}\")\n",
        "print(f\"global_attention_mask:  {type(encoded_dataset['train']['global_attention_mask'][0])}\\t{encoded_dataset['train']['global_attention_mask'][0].shape}\")\n",
        "print(f\"labels:                 {type(encoded_dataset['train'][0]['labels'])}\\t{encoded_dataset['train'][0]['labels'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCGdbfNJwcJ4"
      },
      "source": [
        "### Execute a forward pass for debugging or verification purposes (cf. BERT_3_1 in Notion BERT database)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VN-sEDggwcJ4"
      },
      "outputs": [],
      "source": [
        "outputs = model(\n",
        "    input_ids      = encoded_dataset['train']['input_ids'][0].unsqueeze(0),\n",
        "    attention_mask = encoded_dataset['train']['attention_mask'][0].unsqueeze(0),\n",
        "    labels         = encoded_dataset['train'][0]['labels'].unsqueeze(0)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtEd6KmRwcJ4",
        "outputId": "304e5a89-2e41-44fd-a8f0-a4ba6da8fd18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outputs: <class 'transformers.models.longformer.modeling_longformer.LongformerSequenceClassifierOutput'> odict_keys(['loss', 'logits'])\n",
            "LongformerSequenceClassifierOutput(loss=tensor(0.6522, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), logits=tensor([[ 0.1345, -0.1992, -0.1251,  0.0507,  0.0607,  0.2225]],\n",
            "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None, global_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYiSTBw_1Kdj"
      },
      "source": [
        "### Weighted loss function\n",
        "**weight and pos_weight**:\n",
        "- torch.nn.BCEWithLogitsLoss function is a commonly used loss function for binary classification problems, where model output is a probability value between 0 and 1. It combines a sigmoid activation function with a binary cross-entropy loss.\n",
        "- For imbalanced datasets, where number of a class is significantly smaller than other, BCEWithLogitsLoss can be modified by adding a weight parameter to loss function.<br/>\n",
        "BCEWithLogitsLoss also has a pos_weight parameter, which is a simpler way to specify weight for positive class (equivalent to weight parameter = [ 1, pos_weight], where weight for negative class = 1.<br>\n",
        "Negative samples (0s) are not weighted explicitly because the loss function already balances them implicitly.\n",
        "- pos_weights stands for positive weights in the BCEWithLogitsLoss function.<br/>\n",
        "In multi-label classification, each label is a separate binary classification problem.<br/>\n",
        "Each label has positive sample (1s) and negative samples (0s) in the dataset.\n",
        "    - If a label is rare (fewer 1s), its weight will be higher -> encourages the model to predict it more often\n",
        "    - If a label is common (many 1s), its weight will be lower -> prevents the model to overpredicting it\n",
        "\n",
        "**Normalization**:\n",
        "Without normalization, pos_weights might have huge variations across labels, that could destabilize training.\n",
        "- Min-Max Scaling:\n",
        "    - Rescales values between 0 and 1\n",
        "    - Reduces large variations but keeps relative ranking\n",
        "- Z-Score Normalization:\n",
        "    - Centers values around 0 with a standard deviation of 1\n",
        "    - Handles outliers better than min-max\n",
        "- Sum-to-One Scaling:\n",
        "    - Makes weights sum to 1, preventing extremely large values\n",
        "- Recommended approach: try sum-to-one normalization first. If performance is unstable, test z-score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d89HI1SjJNkO"
      },
      "source": [
        "### Weighted BCEWithLogitsLoss\n",
        "Assigns higher weights to rare labels using class weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YqMipSpowcJ5"
      },
      "outputs": [],
      "source": [
        "def class_weights(labels):\n",
        "    print(f\"labels: {type(labels)} len={len(labels)} shape={labels.shape}\\n{labels}\")\n",
        "\n",
        "    num_samples, num_labels = labels.shape\n",
        "    print(f\"num_samples: {type(num_samples)} {num_samples}\")\n",
        "    print(f\"num_labels:  {type(num_labels)}  {num_labels}\")\n",
        "\n",
        "    # class_counts = how many times each label appears (i.e. number of 1s per label)\n",
        "    # (dim=0 means summing across all samples; equivalent to axis = 0 for Pandas DataFrame)\n",
        "    class_counts = labels.sum(dim=0)\n",
        "    print(f\"class_counts: {type(class_counts)} len={len(class_counts)}\\n{class_counts}\")\n",
        "\n",
        "    # pos_weights = negative samples (0s) per label / positive samples (1s) per label\n",
        "    pos_weights = (num_samples-class_counts) / (class_counts + 1e-6)  # Avoid division by zero\n",
        "    print(f\"pos_weights: {type(pos_weights)} len={len(pos_weights)}\\n{pos_weights}\")\n",
        "\n",
        "    # Normalization\n",
        "    normalized_pos_weights_minmax = (pos_weights-pos_weights.min()) / (pos_weights.max()-pos_weights.min())\n",
        "    print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\n",
        "\n",
        "    normalized_pos_weights_zscore = (pos_weights-pos_weights.mean()) / pos_weights.std()\n",
        "    print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\n",
        "\n",
        "    normalized_pos_weights_sum1 = pos_weights / pos_weights.sum()\n",
        "    print(f\"normalized_pos_weights_sum1: {type(normalized_pos_weights_sum1)} {len(normalized_pos_weights_sum1)} {normalized_pos_weights_sum1}\")\n",
        "\n",
        "    #return pos_weights\n",
        "    #return normalized_pos_weights_minmax\n",
        "    #return normalized_pos_weights_zscore\n",
        "    return normalized_pos_weights_sum1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Bh-gAHGwcJ5",
        "outputId": "c4c9ac6f-c36f-439c-f53c-14689c11ee97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels: <class 'torch.Tensor'> len=19200 shape=torch.Size([19200, 6])\n",
            "tensor([[0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1.],\n",
            "        [0., 0., 1., 1., 1., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 1., 1.]])\n",
            "num_samples: <class 'int'> 19200\n",
            "num_labels:  <class 'int'>  6\n",
            "class_counts: <class 'torch.Tensor'> len=6\n",
            "tensor([ 1560.,  1153.,  4075., 13850., 17561., 13651.])\n",
            "pos_weights: <class 'torch.Tensor'> len=6\n",
            "tensor([11.3077, 15.6522,  3.7117,  0.3863,  0.0933,  0.4065])\n",
            "normalized_pos_weights_minmax: <class 'torch.Tensor'> 6 tensor([0.7208, 1.0000, 0.2326, 0.0188, 0.0000, 0.0201])\n",
            "normalized_pos_weights_zscore: <class 'torch.Tensor'> 6 tensor([ 0.9098,  1.5633, -0.2328, -0.7331, -0.7771, -0.7300])\n",
            "normalized_pos_weights_sum1: <class 'torch.Tensor'> 6 tensor([0.3583, 0.4960, 0.1176, 0.0122, 0.0030, 0.0129])\n"
          ]
        }
      ],
      "source": [
        "pos_weights = class_weights(encoded_dataset['train']['labels'])\n",
        "bce_loss_fn = BCEWithLogitsLoss(pos_weight=pos_weights.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_lLw3Er1WGj"
      },
      "source": [
        "### Focal Loss\n",
        "Reduces the impact of easy examples (majority class) and focuses on difficult cases.\n",
        "\n",
        "- α (alpha): Adjusts class weighting (0.5 means equal weight). Higher α gives more weight to minority classes.\n",
        "- γ (gamma): Controls how much hard-to-classify samples are emphasized. Higher γ reduces the influence of easy samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "OPRpdL8fwcJ5"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(Module):\n",
        "    \"\"\"\n",
        "    Focal Loss implementation for handling class imbalance.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=1.0, gamma=2.0, logits=True, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha     = alpha\n",
        "        self.gamma     = gamma\n",
        "        self.logits    = logits     # True if inputs are logits, False if probabilies\n",
        "        self.reduction = reduction  # 'mean' or 'none'\n",
        "\n",
        "    # inputs  = model's predictions: PyTorch tensor, shape=(batch_size, num_classes)\n",
        "    # targets = ground truth labels: PyTorch tensor, shape=same as inputs shape\n",
        "    def forward(self, inputs, targets):\n",
        "        targets = targets.to(inputs.device)  # Ensure labels are on the same device\n",
        "\n",
        "        #print(f\"inputs: {type(inputs)} {inputs.shape}\\ntargets: {type(targets)} {targets.shape}\"\n",
        "        # Here, we check if input is probability or logits\n",
        "        if self.logits:\n",
        "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
        "        else:\n",
        "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
        "\n",
        "        pt         = torch.exp(-BCE_loss)  # Probability of the correct class\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
        "\n",
        "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"FocalLoss(alpha={self.alpha}, gamma={self.gamma}, logits={self.logits}, reduction={self.reduction})\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.__repr__()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zknwQWsEb7oP",
        "outputId": "b8d52875-9de2-4c0b-fe87-e4c8abd6d360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "focal_loss_fn: <class '__main__.FocalLoss'> FocalLoss(alpha=0.5, gamma=4.0, logits=True, reduction=mean)\n"
          ]
        }
      ],
      "source": [
        "#focal_loss_fn = FocalLoss(alpha=0.5, gamma=3.0, logits=True, reduction='mean')\n",
        "focal_loss_fn = FocalLoss(alpha=0.5, gamma=4.0, logits=True, reduction='mean')\n",
        "print(f\"focal_loss_fn: {type(focal_loss_fn)} {focal_loss_fn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Du0yNyrN2xad"
      },
      "outputs": [],
      "source": [
        "class LossLoggerCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        # Retrieve loss from logs\n",
        "        logs       = kwargs.get(\"logs\", {})\n",
        "        epoch_loss = logs.get(\"logs\", None)  # Loss from the Trainer logs\n",
        "\n",
        "        if epoch_loss is not None:\n",
        "            logging.info(f\"Epoch {state.epoch:.0f} - Average Loss: {epoch_loss:.6f}\")\n",
        "            #print(f\"Epoch {state.epoch:.0f} - Average Loss: {epoch_loss:.6f}\", flush=True)\n",
        "        else:\n",
        "            logging.warning(f\"Epoch {state.epoch:.0f} - No loss logged!\")\n",
        "            #print(f\"Epoch {state.epoch:.0f} - No loss logged!\", flush=True)\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uFUPLYtS5Aik"
      },
      "outputs": [],
      "source": [
        "class MetricsLoggerCallback(TrainerCallback):\n",
        "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
        "        if metrics is None:\n",
        "            metrics = kwargs.get(\"metrics\")  # Ensure we get the metrics if passed in kwargs\n",
        "        if metrics:                          # Check if metrics exist\n",
        "            logging.info(f\"Epoch {state.epoch:.0f} - \"\n",
        "                         f\"Precision: {metrics.get('precision', float('nan')):.4f} - \"\n",
        "                         f\"Recall: {metrics.get('recall', float('nan')):.4f} - \"\n",
        "                         f\"F1: {metrics.get('f1', float('nan')):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "obiPikg4UMk9"
      },
      "outputs": [],
      "source": [
        "class ProgressLoggerCallback(TrainerCallback):\n",
        "    def on_epoch_end(self, args, state, control, **kwargs):\n",
        "        logs       = kwargs.get(\"logs\", {})  # Extract from logs\n",
        "        epoch_loss = logs.get(\"loss\", None)  # Get loss value\n",
        "\n",
        "        if epoch_loss is not None:\n",
        "            logging.info(f\"Epoch {state.epoch:.0f} - Average Loss: {epoch_loss:.6f}\")\n",
        "            #print(f\"Epoch {state.epoch:.0f} - Average Loss: {epoch_loss:.6f}\", flush=True)\n",
        "        else:\n",
        "            logging.warning(f\"Epoch {state.epoch:.0f} - No loss logged!\")\n",
        "            #rint(f\"Epoch {state.epoch:.0f} - No loss logged!\", flush=True)\n",
        "\n",
        "    def on_train_end(self, args, state, control, **kwargs):\n",
        "        logging.info(\"Training Completed!\")\n",
        "        #print(\"=== Training Completed! ===\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UVmqyLTDcBQ"
      },
      "source": [
        "### Training Metrics\n",
        "  source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZleLBD1NXyo"
      },
      "source": [
        "#### UndefinedMetricWarning\n",
        "Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
        "\n",
        "This warning typically arises when you're trying to calculate the ROC AUC score for a label where either all true values are 0 or all are 1 in a particular batch.\n",
        "\n",
        "The ROC AUC score is calculated by comparing the true positive rate (TPR) against the false positive rate (FPR) at various thresholds. If a label is only ever predicted as 0 or 1, you cannot generate a meaningful ROC curve and thus the AUC is undefined.\n",
        "\n",
        "AUC scores rely on the presence of both positive and negative samples for each label.\n",
        "\n",
        "Solution:\n",
        "\n",
        "- Check Label Distribution: Add a check at the start to see if either true_labels or preds for a particular label contain only one unique value (0 or 1). If so, for that label, either skip the ROC AUC calculation or set the ROC AUC to a default value (like 0 or NaN).\n",
        "- Ignore the warning (not recommended):\n",
        "- **Stratified sampling: While you did split into train/validation/test, the warning may indicate you didn't maintain the label balance during the splitting process. Stratified sampling would do this.**\n",
        "\n",
        "#### TPR (True Positive Rate) and FPR (False Positive Rate)\n",
        "TPR = Sensitivity = Recall = TP / (TP + FN)\n",
        "- TPR close to 1: the model identifies most positives\n",
        "- TPR close to 0: the model is missing many positives\n",
        "\n",
        "FPR = FP / (FP + TN)\n",
        "- FPR close to 1: the model produces many false alarms\n",
        "- FPR close to 0: the model makes few false alarms\n",
        "\n",
        "The ROC curve plots TPR (y-axis) vs. FPR (x-axis) at different thresholds.\n",
        "A perfect model has:\n",
        "- TPR = 1 (detect all positives)\n",
        "- FPR = 0 (no false alarms)\n",
        "\n",
        "The ideal ROC curve is a steep rise towards the top-left corner.\n",
        "\n",
        "#### zero_division=0\n",
        "\n",
        "- only for f1, precision and recall because they involve division where the denominator can be zero: some labels might never       be predicted (y_pred = 0 for all samples), or they might not appear in the true_labels (y_true = 0 for all samples)\n",
        "- ROC AUC: works with probabilities and does not involve division by zero\n",
        "- Precision-Recall AUC: also based on ranking, so no zero division issue\n",
        "- Accuracy: just compares exact matches, so no zero division issue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-smu3fYrIybT"
      },
      "outputs": [],
      "source": [
        "#def multi_label_metrics(logits, true_labels, threshold=0.5):\n",
        "def multi_label_metrics(logits, true_labels, threshold):\n",
        "    \"\"\"\n",
        "    Compute multi-label classification metrics.\n",
        "\n",
        "    Parameters:\n",
        "    - logits     : raw, unnormalized scores from the model  (numpy ndarray of shape (batch_size, num_labels))\n",
        "    - true_labels: actual labels                            (numpy ndarray of shape (batch_size, num_labels))\n",
        "    - threshold  : decision threshold for converting probabilities to binary predictions\n",
        "\n",
        "    Returns:\n",
        "    - metrics: dictionary of scores\n",
        "    \"\"\"\n",
        "    #print(\">>>>>>>>>>multi_label_metrics called!<<<<<<<<<<\", flush=True)\n",
        "    print(f\"threshold: {type(threshold)} {threshold}\")\n",
        "    #print(f\"ZZZlogits: {type(logits)} {logits.shape}\\n{logits}\")                      # <class 'numpy.ndarray'> (12, 6)\n",
        "    #print(f\"ZZZtrue_labels: {type(true_labels)} {true_labels.shape}\\n{true_labels}\")  # <class 'numpy.ndarray'> (12, 6)\n",
        "\n",
        "    # Ensure logits is a PyTorch tensor before applying sigmoid\n",
        "    if isinstance(logits, np.ndarray):\n",
        "        logits = torch.as_tensor(logits)\n",
        "    #print(f\"ZZZlogits: {type(logits)} {logits.shape}\\n{logits}\")                      # <class 'torch.Tensor'> torch.Size([12, 6])\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probs = torch.sigmoid(logits).detach().cpu().numpy()  # Convert to NumPy safely:\n",
        "                                                          # - detach() remove the tensor from the computation graph,\n",
        "                                                          #   making it a regular tensor without gradients\n",
        "                                                          # - cpu() moves the tensor from the GPU to the CPU before converting to NumPy\n",
        "    #print(f\"ZZZprobs: {type(probs)} {probs.shape}\\n{probs}\")  # <class 'numpy.ndarray'> (12, 6)\n",
        "\n",
        "    # Apply threshold to get binary predictions\n",
        "    preds = (probs > threshold).astype(int)\n",
        "    #print(f\"ZZZpreds: {type(preds)} {preds.shape}\\n{preds}\")  # <class 'numpy.ndarray'> (12, 6)\n",
        "\n",
        "    # Compute metrics\n",
        "    f1                   = f1_score               (y_true=true_labels, y_pred=preds, average=training_average, zero_division=0)\n",
        "    precision            = precision_score        (y_true=true_labels, y_pred=preds, average=training_average, zero_division=0)\n",
        "    recall               = recall_score           (y_true=true_labels, y_pred=preds, average=training_average, zero_division=0)\n",
        "\n",
        "    # Identify valid labels (those with both 0s and 1s in 'y_true')\n",
        "    valid_labels = np.where((true_labels.sum(axis=0) > 0) & (true_labels.sum(axis=0) < true_labels.shape[0]))[0]\n",
        "\n",
        "    if len(valid_labels) > 0:\n",
        "        roc_auc              = np.mean([roc_auc_score          (y_true=true_labels[:, i], y_score=probs[:, i]) for i in valid_labels])\n",
        "        precision_recall_auc = np.mean([average_precision_score(y_true=true_labels[:, i], y_score=probs[:, i]) for i in valid_labels])\n",
        "    else:\n",
        "        roc_auc              = np.nan  # Set to NaN if no valid labels exist\n",
        "        precision_recall_auc = np.nan  # Set to NaN if no valid labels exist\n",
        "\n",
        "    subset_acc = accuracy_score(true_labels, preds)  # Subset accuracy (requires exact match per sample)\n",
        "    hamming    = hamming_loss(true_labels, preds)    # Better for imbalanced multi-label tasks\n",
        "\n",
        "    metrics = {\n",
        "        'f1'                  : f1,\n",
        "        'precision'           : precision,\n",
        "        'recall'              : recall,\n",
        "        'roc_auc'             : roc_auc,               # Avoid warning by checking valid labels\n",
        "        'precision_recall_auc': precision_recall_auc,  # Avoid warning by checking valid labels\n",
        "        'subset_accuracy'     : subset_acc,\n",
        "        'hamming_loss'        : hamming\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "HIORbGwIDH-x"
      },
      "outputs": [],
      "source": [
        "# Evaluation batch per batch\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    #print(f\"p.predictions: {type(p.predictions)} {p.predictions.shape}\\n{p.predictions[:5]}\")\n",
        "    #print(f\"p.label_ids: {type(p.label_ids)} {p.label_ids.shape}\\n{p.label_ids[:5]}\")\n",
        "    print(f\"threshold: {type(threshold)} {threshold}\")\n",
        "\n",
        "    preds  = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    result = multi_label_metrics(preds,p.label_ids, threshold)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2elPEoowcJ6"
      },
      "source": [
        "### HF transformer Trainer and CustomTrainer\n",
        "Abstracts the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "dR2GmpvDqbuZ"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir                  = './training_results',  # where model predictions and checkpoints will be written during training\n",
        "    overwrite_output_dir        = True,\n",
        "    save_steps                  = 500,\n",
        "    save_total_limit            = 2,\n",
        "    eval_strategy               = 'epoch',               # Evaluate at the end of each epoch\n",
        "    save_strategy               = 'epoch',               # Save checkpoints every epoch\n",
        "    learning_rate               = learning_rate,\n",
        "    per_device_train_batch_size = batch_size,\n",
        "    per_device_eval_batch_size  = batch_size,\n",
        "    gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "    num_train_epochs            = epochs,\n",
        "    weight_decay                = 0.01,\n",
        "    load_best_model_at_end      = True,\n",
        "    metric_for_best_model       = metric_name,\n",
        "    fp16                        = fp,\n",
        "    run_name                    = run_name,\n",
        "    report_to                   = 'none'                 # Disable wandb if not needed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Isb6aMV2bWJ8"
      },
      "outputs": [],
      "source": [
        "class CustomTrainer(Trainer):\n",
        "\n",
        "    def __init__(self, model, *args, loss_fn=None, **kwargs):\n",
        "        super().__init__(model, *args, **kwargs)\n",
        "        self.loss_fn = loss_fn\n",
        "        #print(f\">>>>>>>>>>CustomTrainer initialized with loss_fn: {loss_fn}<<<<<<<<<<\")\n",
        "\n",
        "    \"\"\"\n",
        "    # No print in compute_loss because out of memory because prints are batch per batch\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "\n",
        "    #print(f\"inputs passed to compute_loss: {inputs.keys()}\")\n",
        "    #input_ids             = inputs['input_ids']                        # shape: batch_size, sequence_length\n",
        "    #attention_mask        = inputs['attention_mask']                   # shape: batch_size, sequence_length\n",
        "    #global_attention_mask = inputs.get('global_attention_mask', None)  # shape: batch_size, sequence_length; optional as LongFormer specific\n",
        "    labels                = inputs.pop('labels', None)                 # shape: batch_size, num_labels; needed for loss computation, not required by the model\n",
        "\n",
        "    #outputs = model(**inputs, global_attention_mask=global_attention_mask)  # Forward pass\n",
        "    # Forward pass\n",
        "    #outputs = model(\n",
        "    #    input_ids             = input_ids,\n",
        "    #    attention_mask        = attention_mask,\n",
        "    #    global_attention_mask = global_attention_mask,\n",
        "    #    labels                = labels\n",
        "    #)\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    #print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")\n",
        "    logits = outputs.logits  # shape: (batch_size, num_labels)\n",
        "\n",
        "    # If labels are provided, compute loss\n",
        "    if labels is not None:\n",
        "      # Use the custom loss function if provided\n",
        "      if self.loss_fn is not None:\n",
        "        loss = self.loss_fn(logits, labels)  # Compute weighted loss\n",
        "      else:\n",
        "        # Default loss: BCEWithLogitsLoss\n",
        "        loss_fn = BCEWithLogitsLoss()\n",
        "        loss    = loss_fn(logits, labels)    # Compute loss\n",
        "      return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    # If no labels, return outputs only, for evaluation or prediction\n",
        "    return outputs\n",
        "    \"\"\"\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        #print(f\">>>>>>>>>>compute_loss called!<<<<<<<<<<\", flush=True)\n",
        "        labels  = inputs.get('labels')\n",
        "        outputs = model(**inputs)\n",
        "        logits  = outputs.logits  # (batch_size, num_labels)\n",
        "\n",
        "        if labels is not None:\n",
        "            labels = labels.to(logits.device).float()  # Ensure same device\n",
        "\n",
        "            if self.loss_fn is not None:\n",
        "                loss = self.loss_fn(logits, labels)\n",
        "                logging.info(f\"Step Loss ({self.loss_fn.__class__.__name__}): {loss.item():.6f}\")  # Log loss value\n",
        "                #print(f\"Epoch {self.state.epoch:.0f}, Step {self.state.global_step}: Loss ({self.loss_fn.__class__.__name__}): {loss.item():.6f}\", flush=True)\n",
        "            else:\n",
        "                loss_fn = BCEWithLogitsLoss()\n",
        "                loss    = loss_fn(logits, labels)\n",
        "                logging.info(f\"Step Loss (BCEWithLogitsLoss): {loss.item():.6f}\")                  # Log loss value\n",
        "                #print(f\"Epoch {self.state.epoch:.0f}, Step {self.state.global_step}: Loss (BCEWithLogitsLoss): {loss.item():.6f}\", flush=True)\n",
        "\n",
        "            return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chq_3nUz73ib",
        "outputId": "e8c5cff5-ca82-40c3-b928-3649db436c10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer: <class '__main__.CustomTrainer'> <__main__.CustomTrainer object at 0x7e46a1274310>\n"
          ]
        }
      ],
      "source": [
        "trainer = CustomTrainer(\n",
        "    model           = model,\n",
        "    args            = training_args,\n",
        "    train_dataset   = encoded_dataset[\"train\"],\n",
        "    eval_dataset    = encoded_dataset[\"validation\"],\n",
        "    compute_metrics = compute_metrics,\n",
        "    loss_fn         = focal_loss_fn,  # bce_loss_fn or focal_loss_fn\n",
        "    #callbacks       = [LossLoggerCallback(), MetricsLoggerCallback(), ProgressLoggerCallback()]  # Attach logging callbacks\n",
        ")\n",
        "\n",
        "#trainer = Trainer(\n",
        "#    model           = model,\n",
        "#    args            = training_args,\n",
        "#    train_dataset   = encoded_dataset[\"train\"],\n",
        "#    eval_dataset    = encoded_dataset[\"validation\"],\n",
        "#    compute_metrics = compute_metrics,\n",
        "#)\n",
        "\n",
        "print(f\"trainer: {type(trainer)} {trainer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3kPFNOG-3vL"
      },
      "source": [
        "### trainer.train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V_k5uxpKwcJ6",
        "outputId": "99f5f86f-5580-4839-98fe-082aab6f70ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3131' max='4200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3131/4200 1:22:35 < 28:12, 0.63 it/s, Epoch 5.22/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Roc Auc</th>\n",
              "      <th>Precision Recall Auc</th>\n",
              "      <th>Subset Accuracy</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>0.010215</td>\n",
              "      <td>0.866118</td>\n",
              "      <td>0.866911</td>\n",
              "      <td>0.865326</td>\n",
              "      <td>0.877243</td>\n",
              "      <td>0.785202</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.121944</td>\n",
              "      <td>35.614700</td>\n",
              "      <td>67.388000</td>\n",
              "      <td>8.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.009900</td>\n",
              "      <td>0.009466</td>\n",
              "      <td>0.878181</td>\n",
              "      <td>0.868116</td>\n",
              "      <td>0.888483</td>\n",
              "      <td>0.896961</td>\n",
              "      <td>0.813552</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.112361</td>\n",
              "      <td>35.597500</td>\n",
              "      <td>67.420000</td>\n",
              "      <td>8.428000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.009497</td>\n",
              "      <td>0.877217</td>\n",
              "      <td>0.884347</td>\n",
              "      <td>0.870201</td>\n",
              "      <td>0.899063</td>\n",
              "      <td>0.825090</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.111042</td>\n",
              "      <td>35.699800</td>\n",
              "      <td>67.227000</td>\n",
              "      <td>8.403000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.008800</td>\n",
              "      <td>0.009661</td>\n",
              "      <td>0.880194</td>\n",
              "      <td>0.874568</td>\n",
              "      <td>0.885893</td>\n",
              "      <td>0.900846</td>\n",
              "      <td>0.827061</td>\n",
              "      <td>0.537083</td>\n",
              "      <td>0.109931</td>\n",
              "      <td>35.759300</td>\n",
              "      <td>67.115000</td>\n",
              "      <td>8.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.009895</td>\n",
              "      <td>0.877435</td>\n",
              "      <td>0.883534</td>\n",
              "      <td>0.871420</td>\n",
              "      <td>0.901698</td>\n",
              "      <td>0.830249</td>\n",
              "      <td>0.531667</td>\n",
              "      <td>0.110972</td>\n",
              "      <td>35.744500</td>\n",
              "      <td>67.143000</td>\n",
              "      <td>8.393000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4200' max='4200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4200/4200 1:51:10, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Roc Auc</th>\n",
              "      <th>Precision Recall Auc</th>\n",
              "      <th>Subset Accuracy</th>\n",
              "      <th>Hamming Loss</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "      <th>Steps Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>0.010215</td>\n",
              "      <td>0.866118</td>\n",
              "      <td>0.866911</td>\n",
              "      <td>0.865326</td>\n",
              "      <td>0.877243</td>\n",
              "      <td>0.785202</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.121944</td>\n",
              "      <td>35.614700</td>\n",
              "      <td>67.388000</td>\n",
              "      <td>8.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.009900</td>\n",
              "      <td>0.009466</td>\n",
              "      <td>0.878181</td>\n",
              "      <td>0.868116</td>\n",
              "      <td>0.888483</td>\n",
              "      <td>0.896961</td>\n",
              "      <td>0.813552</td>\n",
              "      <td>0.535000</td>\n",
              "      <td>0.112361</td>\n",
              "      <td>35.597500</td>\n",
              "      <td>67.420000</td>\n",
              "      <td>8.428000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.009497</td>\n",
              "      <td>0.877217</td>\n",
              "      <td>0.884347</td>\n",
              "      <td>0.870201</td>\n",
              "      <td>0.899063</td>\n",
              "      <td>0.825090</td>\n",
              "      <td>0.537500</td>\n",
              "      <td>0.111042</td>\n",
              "      <td>35.699800</td>\n",
              "      <td>67.227000</td>\n",
              "      <td>8.403000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.008800</td>\n",
              "      <td>0.009661</td>\n",
              "      <td>0.880194</td>\n",
              "      <td>0.874568</td>\n",
              "      <td>0.885893</td>\n",
              "      <td>0.900846</td>\n",
              "      <td>0.827061</td>\n",
              "      <td>0.537083</td>\n",
              "      <td>0.109931</td>\n",
              "      <td>35.759300</td>\n",
              "      <td>67.115000</td>\n",
              "      <td>8.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.009895</td>\n",
              "      <td>0.877435</td>\n",
              "      <td>0.883534</td>\n",
              "      <td>0.871420</td>\n",
              "      <td>0.901698</td>\n",
              "      <td>0.830249</td>\n",
              "      <td>0.531667</td>\n",
              "      <td>0.110972</td>\n",
              "      <td>35.744500</td>\n",
              "      <td>67.143000</td>\n",
              "      <td>8.393000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.007800</td>\n",
              "      <td>0.009978</td>\n",
              "      <td>0.878742</td>\n",
              "      <td>0.876478</td>\n",
              "      <td>0.881018</td>\n",
              "      <td>0.901138</td>\n",
              "      <td>0.828845</td>\n",
              "      <td>0.539167</td>\n",
              "      <td>0.110833</td>\n",
              "      <td>35.622100</td>\n",
              "      <td>67.374000</td>\n",
              "      <td>8.422000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>0.010103</td>\n",
              "      <td>0.880024</td>\n",
              "      <td>0.879489</td>\n",
              "      <td>0.880561</td>\n",
              "      <td>0.901242</td>\n",
              "      <td>0.829911</td>\n",
              "      <td>0.547500</td>\n",
              "      <td>0.109444</td>\n",
              "      <td>35.782300</td>\n",
              "      <td>67.072000</td>\n",
              "      <td>8.384000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "trainer_train: <class 'transformers.trainer_utils.TrainOutput'> len=3\n",
            "TrainOutput(global_step=4200, training_loss=0.0089496477161135, metrics={'train_runtime': 6673.5432, 'train_samples_per_second': 20.139, 'train_steps_per_second': 0.629, 'total_flos': 8.82833966235648e+16, 'train_loss': 0.0089496477161135, 'epoch': 7.0})\n",
            "\n",
            "trainer_train.metrics: <class 'dict'> len=6\n",
            "{\n",
            "    \"train_runtime\": 6673.5432,\n",
            "    \"train_samples_per_second\": 20.139,\n",
            "    \"train_steps_per_second\": 0.629,\n",
            "    \"total_flos\": 8.82833966235648e+16,\n",
            "    \"train_loss\": 0.0089496477161135,\n",
            "    \"epoch\": 7.0\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "trainer_train = trainer.train()\n",
        "\n",
        "print(f\"trainer_train: {type(trainer_train)} len={len(trainer_train)}\\n{trainer_train}\")\n",
        "print()\n",
        "print(f\"trainer_train.metrics: {type(trainer_train.metrics)} len={len(trainer_train.metrics)}\\n{json.dumps(trainer_train.metrics, indent=4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2SMR-lI8Y8r",
        "outputId": "c91aa32e-8d2e-4108-a49b-55283316d532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer.train successfully completed\n"
          ]
        }
      ],
      "source": [
        "print(\"trainer.train successfully completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uai-d2z2IMaZ"
      },
      "source": [
        "### trainer.train: save locally and upload to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvhT1c_h_oul",
        "outputId": "ee7f61fb-0a4f-4a78-bc14-3fa0ae58b17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainer_train results successfully saved locally to trainer_train.json\n",
            "trainer_train results successfully uploaded to HF Hub as trainer_train.json\n"
          ]
        }
      ],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    name               = \"trainer_train\"\n",
        "    trainer_train_path = f\"{name}.json\"\n",
        "\n",
        "    with open(trainer_train_path, \"w\") as f:\n",
        "        json.dump(trainer_train, f)\n",
        "\n",
        "    print(f\"{name} results successfully saved locally to {trainer_train_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = trainer_train_path,\n",
        "        path_in_repo    = trainer_train_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} results successfully uploaded to HF Hub as {trainer_train_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "as2omZpPJNO6"
      },
      "source": [
        "### trainer.train: check that the uploaded file can be downloaded\n",
        "File locally downloaded to:\n",
        "/root/.cache/huggingface/hub/datasets-claudelepere-skill_classification/snapshots/full_commit_hash/trainer_train_results.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ2D28X2-GfV",
        "outputId": "41a4838d-c2d6-42b6-a125-55340ba15566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file_path: /root/.cache/huggingface/hub/datasets--claudelepere--jobs_EN_9_0_1200_micro_micro_epoch5_tuned_thresholds/snapshots/49275dc3cc08e22cf949d13853196be29e29841d/trainer_train.json\n"
          ]
        }
      ],
      "source": [
        "if upload_to_HF is True:\n",
        "  file_path = hf_hub_download(repo_type=\"dataset\", repo_id=repo_id, filename=trainer_train_path)\n",
        "\n",
        "  print(f\"file_path: {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVozoTnW1Mt9"
      },
      "source": [
        "## Evaluation step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05FkezueB6_J"
      },
      "source": [
        "### Evaluation 1: trainer.evaluate\n",
        "trainer.evaluate uses a fixed threshold of 0.5 to convert logits into binary labels, which is often suboptimal for imbalanced data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "HMKEjsRk5ah6",
        "outputId": "a116ca11-0e40-4879-fe68-49979a4ef077"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [300/300 00:35]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold: <class 'float'> 0.5\n",
            "threshold: <class 'float'> 0.5\n",
            "evaluation_trainer_evaluate_metrics: <class 'dict'> len=12\n",
            "{\n",
            "    \"eval_loss\": 0.009661308489739895,\n",
            "    \"eval_f1\": 0.880193748580943,\n",
            "    \"eval_precision\": 0.8745676041510001,\n",
            "    \"eval_recall\": 0.8858927483241925,\n",
            "    \"eval_roc_auc\": 0.9008456832395274,\n",
            "    \"eval_precision_recall_auc\": 0.8270608515205763,\n",
            "    \"eval_subset_accuracy\": 0.5370833333333334,\n",
            "    \"eval_hamming_loss\": 0.10993055555555556,\n",
            "    \"eval_runtime\": 35.6677,\n",
            "    \"eval_samples_per_second\": 67.288,\n",
            "    \"eval_steps_per_second\": 8.411,\n",
            "    \"epoch\": 7.0\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "evaluation_trainer_evaluate_metrics = trainer.evaluate(\n",
        "    #eval_dataset = encoded_dataset[\"validation\"],  # by default, trainer.evaluate() evaluates the dataset passed as eval_dataset during training\n",
        "    metric_key_prefix=\"eval\"                       # prefix for the evaluation metrics\n",
        ")\n",
        "\n",
        "print(f\"evaluation_trainer_evaluate_metrics: {type(evaluation_trainer_evaluate_metrics)} len={len(evaluation_trainer_evaluate_metrics)}\\n{json.dumps(evaluation_trainer_evaluate_metrics, indent=4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O-_tVHg-lUe"
      },
      "outputs": [],
      "source": [
        "print(\"evaluation 1: trainer.evaluate: successfully completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w5BmumZ6tDS"
      },
      "source": [
        "### Evaluation 1: trainer.evaluate: save locally and upload to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMlebJ83LRYG"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    name                             = \"evaluation_trainer_evaluate\"\n",
        "    evaluation_trainer_evaluate_path = f\"{name}.json\"\n",
        "\n",
        "    with open(evaluation_trainer_evaluate_path, \"w\") as f:\n",
        "        json.dump(evaluation_trainer_evaluate_metrics, f)\n",
        "\n",
        "    print(f\"{name} successfully saved locally to {evaluation_trainer_evaluate_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = evaluation_trainer_evaluate_path,\n",
        "        path_in_repo    = evaluation_trainer_evaluate_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} successfully uploaded to HF Hub as {evaluation_trainer_evaluate_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxYFDrB57nM3"
      },
      "source": [
        "### Evaluation 2: trainer.predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvBaTA62X7xV"
      },
      "outputs": [],
      "source": [
        "def predict_with_optimized_thresholds(trainer, dataset, id2label, threshold_tuning=False, thresholds=None):\n",
        "    \"\"\"\n",
        "    Predicts using trainer.predict(), with optional threshold tuning, using NumPy arrays, and not PyTorch tensors\n",
        "\n",
        "    Parameters:\n",
        "    - trainer                         : Hugging Face Trainer or CustomTrainer instance\n",
        "    - dataset                         : Dataset to predict on\n",
        "    - id2label                        : Dictionary mapping label indices (int) to label names (string)\n",
        "    - threshold_tuning                : Boolean to enable threshold tuning per class (aka per label)\n",
        "    - thresholds       (numpy.ndarray): Custom thresholds for classification\n",
        "\n",
        "    Returns:\n",
        "    if threshold_tuning:\n",
        "        - best_thresholds      (numpy.ndarray): optimized threshold per class (aka per label)\n",
        "        - best_thresholds_dict (dict)         : optimized threshold per class (aka per label)\n",
        "        - best_metrics         (dict)         : best F1, best precision, best recall per class (aka per label)\n",
        "        - best_preds           (numpy.ndarray): best predictions per class (aka per label)\n",
        "    else:\n",
        "        - thresholds      (numpy.ndarray): fixed threshold per class (aka per label)\n",
        "        - thresholds_dict (dict)         : fixed threshold per class (aka per label)\n",
        "        - metrics         (dict)         : computed with provided thresholds or default to 0.5\n",
        "        - preds           (numpy.ndarray): predictions with provided thresholds or default to 0.5\n",
        "    \"\"\"\n",
        "    # Predict\n",
        "    predictions_output = trainer.predict(dataset)\n",
        "    logits             = predictions_output.predictions\n",
        "    true_labels        = predictions_output.label_ids\n",
        "\n",
        "    # Convert logits to probabilities (with np, not with torch)\n",
        "    probs = 1 / (1 + np.exp(-logits))  # Sigmoid function\n",
        "\n",
        "    num_labels           = len(id2label)\n",
        "    best_thresholds      = None\n",
        "    best_thresholds_dict = None\n",
        "    best_metrics         = None\n",
        "    best_preds           = None\n",
        "\n",
        "    if threshold_tuning:\n",
        "        threshold_candidates = np.linspace(0.05, 0.95, 19)\n",
        "        best_thresholds      = np.zeros(num_labels)\n",
        "        best_metrics         = {label: {'f1': 0.0, 'precision': 0.0, 'recall': 0.0} for label in id2label.values()}\n",
        "\n",
        "        # Iterate over each label to find the best threshold\n",
        "        for label_idx, label in id2label.items():\n",
        "            # Predictions for the current label across all threshold candidates\n",
        "            preds = probs[:, label_idx][:, None] > threshold_candidates  # Create a matrix of shape (num_samples, num_thresholds)\n",
        "\n",
        "            # Compute precision, recall, F1 for all thresholds at once for the current label\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                np.tile(true_labels[:, label_idx], (len(threshold_candidates), 1)).T, preds, average=None, zero_division=0\n",
        "            )\n",
        "\n",
        "            # Find the best threshold based on F1 for the current label\n",
        "            best_idx                   = np.argmax(f1)\n",
        "            best_thresholds[label_idx] = threshold_candidates[best_idx]\n",
        "            best_metrics[label]        = {'f1': f1[best_idx], 'precision': precision[best_idx], 'recall': recall[best_idx]}\n",
        "\n",
        "        best_thresholds_dict = {id2label[i]: best_thresholds[i].item() for i in range(len(best_thresholds))}\n",
        "\n",
        "        # Generate predictions using the optimized threshold for each label\n",
        "        best_preds = np.zeros_like(true_labels, dtype=int)\n",
        "        for label_idx, label in id2label.items():\n",
        "            best_preds[:, label_idx] = (probs[:, label_idx] > best_thresholds[label_idx]).astype(int)\n",
        "\n",
        "        #print(\"==== best_thresholds, best_threshold_dict and best_metrics ====\")\n",
        "        #print(f\"best_thresholds:      {type(best_thresholds)} shape={best_thresholds.shape}\\n{best_thresholds}\")                # <class 'numpy.ndarray'> shape=(6,)\n",
        "        #print(f\"best_thresholds_dict: {type(best_thresholds_dict)} len={len(best_thresholds_dict)}\\n{best_thresholds_dict}\")    # <class 'dict'> len=6\n",
        "        #print(f\"best_metrics:         {type(best_metrics)} len={len(best_metrics)}\\n{json.dumps(best_metrics, indent=4)}\")      # <class 'dict'> len=6\n",
        "        #print(\"===============================================================\")\n",
        "        #print()\n",
        "\n",
        "    # ==== If not threshold_tuning ====\n",
        "\n",
        "    # Apply provided thresholds or default to 0.5\n",
        "    thresholds_fixed = thresholds if thresholds is not None else np.full(num_labels, 0.5)\n",
        "\n",
        "    # Compute predictions with fixed thresholds\n",
        "    preds_fixed = (probs > thresholds_fixed).astype(int)\n",
        "\n",
        "    # Compute metrics in one step (no loop)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, preds_fixed, average=None, zero_division=0)\n",
        "\n",
        "    # Convert to dict format\n",
        "    metrics_fixed         = {id2label[i]: {'f1': f1[i], 'precision': precision[i], 'recall': recall[i]} for i in range(num_labels)}\n",
        "    thresholds_fixed_dict = {id2label[i]: thresholds_fixed[i].item() for i in range(num_labels)}\n",
        "\n",
        "    #print(\"==== provided thresholds and metrics ====\")\n",
        "    #print(f\"thresholds_fixed     : {type(thresholds_fixed)} shape={thresholds_fixed.shape}\\n{thresholds_fixed}\")              # <class 'numpy.ndarray'> shape=(6,)\n",
        "    #print(f\"thresholds_fixed_dict: {type(thresholds_fixed_dict)} len={len(thresholds_fixed_dict)}\\n{thresholds_fixed_dict}\")  # <class 'dict'> len=6\n",
        "    #print(f\"metrics_fixed        : {type(metrics_fixed)} len={len(metrics_fixed)}\\n{json.dumps(metrics_fixed, indent=4)}\")    # <class 'dict'> len=6\n",
        "    #print(\"===============================================================\")\n",
        "    #print()\n",
        "\n",
        "    thresholds      = best_thresholds      if threshold_tuning else thresholds_fixed\n",
        "    thresholds_dict = best_thresholds_dict if threshold_tuning else thresholds_fixed_dict\n",
        "    metrics         = best_metrics         if threshold_tuning else metrics_fixed\n",
        "    preds           = best_preds           if threshold_tuning else preds_fixed\n",
        "\n",
        "    # Compute micro average\n",
        "    #   compute metrics globally by summing all TP, FP, FN across all labels\n",
        "    #   good for overall performance assessment\n",
        "    #   dominated by frequent labels: if most samples belong to a few labels, if favors them\n",
        "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, preds, average='micro', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Compute macro average\n",
        "    #   each label is treated equally, regardless of how often it appears\n",
        "    #   good for evaluating rare labels\n",
        "    #   sensitive to rare labels: if rare labels perform poorly, macro F1 will drop\n",
        "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, preds, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Compute weighted average\n",
        "    #   like macro, but weights each label's F1 based on its frequency\n",
        "    #   balances between micro and macro by considering both label importance and prevalence\n",
        "    #   useful if class imbalance exists but you still want per-label influence\n",
        "    weighted_precision, weighted_recall, weighted_f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, preds, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    global_metrics = {\n",
        "        'micro':    {'f1': micro_f1,    'precision': micro_precision,    'recall': micro_recall},\n",
        "        'macro':    {'f1': macro_f1,    'precision': macro_precision,    'recall': macro_recall},\n",
        "        'weighted': {'f1': weighted_f1, 'precision': weighted_precision, 'recall': weighted_recall}\n",
        "    }\n",
        "\n",
        "    return thresholds, thresholds_dict, metrics, global_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YZ2WcwI7IBl"
      },
      "source": [
        "### Evaluation 2: calculate metrics and optimized thresholds\n",
        "\n",
        "- First, to **calculate** the optimized thresholds, threshold_tuning = True and thresholds = None.\n",
        "- After, to **use** these optimized thresholds, threshold_tuning = False and thresholds = the optimized thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TphO3ifmBLDf"
      },
      "outputs": [],
      "source": [
        "# with best_thresholds (threshold_tuning = True and thresholds = None)\n",
        "optimized_thresholds, optimized_thresholds_dict, evaluation_trainer_predict_metrics, evaluation_trainer_predict_global_metrics = predict_with_optimized_thresholds(\n",
        "    trainer, validation_dataset, id2label, threshold_tuning=True, thresholds=None)\n",
        "\n",
        "print(\"==== with best thresholds ====\")\n",
        "print(f\"optimized_thresholds                     : {type(optimized_thresholds)} shape={optimized_thresholds.shape} {optimized_thresholds}\")\n",
        "print(f\"optimized_thresholds_dict                : {type(optimized_thresholds_dict)} len={len(optimized_thresholds_dict)}\\n{optimized_thresholds_dict}\")\n",
        "print(f\"evaluation_trainer_predict_metrics       : {type(evaluation_trainer_predict_metrics)} len={len(evaluation_trainer_predict_metrics)}\\n{json.dumps(evaluation_trainer_predict_metrics, indent=4)}\")\n",
        "print(f\"evaluation_trainer_predict_global_metrics: {type(evaluation_trainer_predict_global_metrics)} len={len(evaluation_trainer_predict_global_metrics)}\\n{json.dumps(evaluation_trainer_predict_global_metrics, indent=4)}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# with thresholds_fixed=0.5 (threshold_tuning = False and thresholds = None)\n",
        "thresholds, thresholds_dict, evaluation_trainer_predict_metrics_thr05, evaluation_trainer_predict_global_metrics_thr05 = predict_with_optimized_thresholds(\n",
        "    trainer, validation_dataset, id2label, threshold_tuning=False, thresholds=None)\n",
        "\n",
        "print(\"==== with default fixed thresholds = 0.5 ====\")\n",
        "print(f\"thresholds                                     : {type(thresholds)} shape={thresholds.shape} {thresholds}\")\n",
        "print(f\"thresholds_dict                                : {type(thresholds_dict)} len={len(thresholds_dict)}\\n{thresholds_dict}\")\n",
        "print(f\"evaluation_trainer_predict_metrics_thr05       : {type(evaluation_trainer_predict_metrics_thr05)} len={len(evaluation_trainer_predict_metrics_thr05)}\\n{json.dumps(evaluation_trainer_predict_metrics_thr05, indent=4)}\")\n",
        "print(f\"evaluation_trainer_predict_global_metrics_thr05: {type(evaluation_trainer_predict_global_metrics_thr05)} len={len(evaluation_trainer_predict_global_metrics_thr05)}\\n{json.dumps(evaluation_trainer_predict_global_metrics_thr05, indent=4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc9XZPkpDFdR",
        "outputId": "d21ddc83-2579-4b16-f1d2-e12c9ebc3963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation 2: trainer.predict: successfully completed\n"
          ]
        }
      ],
      "source": [
        "print(\"evaluation 2: trainer.predict: successfully completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwV60_UQ-HXd"
      },
      "source": [
        "### Evaluation 2: trainer.predict: save locally and upload to HF Hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14zP2d72-WXk"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "    name                            = \"evaluation_trainer_predict\"\n",
        "    evaluation_trainer_predict_path = f\"{name}.json\"\n",
        "\n",
        "    with open(evaluation_trainer_predict_path, \"w\") as f:\n",
        "        json.dump(evaluation_trainer_predict_metrics, f)\n",
        "\n",
        "    print(f\"{name} successfully saved locally to {evaluation_trainer_predict_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = evaluation_trainer_predict_path,\n",
        "        path_in_repo    = evaluation_trainer_predict_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} successfully uploaded to HF Hub as {evaluation_trainer_predict_path}\")\n",
        "\n",
        "    name_thr05                            = \"evaluation_trainer_predict_thr05\"\n",
        "    evaluation_trainer_predict_path_thr05 = f\"{name_thr05}.json\"\n",
        "\n",
        "    with open(evaluation_trainer_predict_path_thr05, \"w\") as f:\n",
        "        json.dump(evaluation_trainer_predict_metrics_thr05, f)\n",
        "\n",
        "    print(f\"{name_thr05} successfully saved locally to {evaluation_trainer_predict_path_thr05}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = evaluation_trainer_predict_path_thr05,\n",
        "        path_in_repo    = evaluation_trainer_predict_path_thr05,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name_thr05}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name_thr05} successfully uploaded to HF Hub as {evaluation_trainer_predict_path_thr05}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f127duCt-Nhg"
      },
      "source": [
        "### Evaluation 2: optimized thresholds: save locally (as a dict) and upload to HF Hub (as a JSON file in repo 'model')\n",
        "optimized_thresholds: <class 'numpy.ndarray'> shape=(6,) but JSON doesn't support NumPy types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZjQfyNP-J46"
      },
      "outputs": [],
      "source": [
        "if threshold_tuning is True and upload_to_HF is True:\n",
        "    name                      = \"optimized_thresholds\"\n",
        "    optimized_thresholds_path = f\"{name}.json\"\n",
        "\n",
        "    with open(optimized_thresholds_path, \"w\") as f:\n",
        "        json.dump(optimized_thresholds_dict, f, indent=4)\n",
        "\n",
        "    print(f\"{optimized_thresholds_dict} successfully saved locally to {optimized_thresholds_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = optimized_thresholds_path,\n",
        "        path_in_repo    = optimized_thresholds_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'model',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "        )\n",
        "\n",
        "    print(f\"{name} successfully uploaded to HF Hub as {optimized_thresholds_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noWOBOOd9hP7"
      },
      "source": [
        "### Evaluation 3: model.eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XGQ4QNv9LsL"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_with_threshold(model, dataset, optimized_thresholds, id2label, batch_size=8):\n",
        "    \"\"\"\n",
        "    Compute metrics during evaluation or test, by applying tuned thresholds\n",
        "\n",
        "    Parameters:\n",
        "    - model                                               : Hugging Face model\n",
        "    - dataset                                             : Dataset to predict on\n",
        "    - optimized_thresholds (list or NumPy array of floats): Optimized thresholds for each label\n",
        "    - id2label                                            : Dictionary mapping label indices (int) to label names (string)\n",
        "    - batch_size                                          : Batch size for prediction. Defaults to 8\n",
        "    Returns:\n",
        "    - metrics (dict)\n",
        "\n",
        "    Compute metrics during evaluation or test, by applying optimized thresholds\n",
        "    \"\"\"\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)    # Move model to GPU/CPU\n",
        "    model.eval()        # Set model to evaluation mode\n",
        "\n",
        "    all_logits, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            labels  = batch.pop('labels')                           # Keep labels on CPU\n",
        "            inputs  = {k: v.to(device) for k, v in batch.items()}   # Move inputs to device\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "            all_logits.append(outputs.logits.cpu())     # Keep logits as tensors, move to CPU\n",
        "            all_labels.append(labels)                   # Labels remain on CPU\n",
        "\n",
        "    # Stack tensors\n",
        "    logits = torch.cat(all_logits, dim=0).to(device)   # shape = (num_samples, num_labels), move to device\n",
        "    labels = torch.cat(all_labels, dim=0).to(device)   # shape = (num_samples, num_labels), move to device\n",
        "\n",
        "    # Convert logits to probabilities\n",
        "    probs = torch.sigmoid(logits)           # shape = (num_samples, num_labels)\n",
        "\n",
        "    # Apply per-class tuned thresholds (element-wise comparison)\n",
        "    thresholds = torch.tensor(optimized_thresholds, dtype=torch.float32, device=device)  # Convert tuned_thresholds to tensor\n",
        "    preds      = (probs > thresholds).int()                                              # Convert to binary predictions (1 or 0)\n",
        "\n",
        "    # Compute TP, FP, FN, TN\n",
        "    TP = ((preds == 1) & (labels == 1)).sum(dim=0).float()\n",
        "    TN = ((preds == 0) & (labels == 0)).sum(dim=0).float()\n",
        "    FP = ((preds == 1) & (labels == 0)).sum(dim=0).float()\n",
        "    FN = ((preds == 0) & (labels == 1)).sum(dim=0).float()\n",
        "\n",
        "    # Compute per-class metrics\n",
        "    precision_per_class = TP / (TP + FP + 1e-8)\n",
        "    recall_per_class    = TP / (TP + FN + 1e-8)\n",
        "    f1_per_class        = 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class + 1e-8)\n",
        "\n",
        "    # Compute averaged metrics\n",
        "    precision = precision_per_class.mean()\n",
        "    recall    = recall_per_class.mean()\n",
        "    f1        = f1_per_class.mean()\n",
        "\n",
        "    # Compute accuracy\n",
        "    accuracy = (preds == labels).float().mean()\n",
        "\n",
        "    # Convert to NumPy for ROC-AUC and PR-AUC\n",
        "    labels_np = labels.cpu().numpy()  # Move to CPU before converting\n",
        "    probs_np  = probs.cpu().numpy()   # Move to CPU before converting\n",
        "\n",
        "    # Compute ROC-AUC and PR-AUC\n",
        "    roc_auc = torch.tensor(roc_auc_score(labels_np, probs_np, average=evaluation_average, multi_class='ovr'))\n",
        "    pr_auc  = torch.tensor(average_precision_score(labels_np, probs_np, average=evaluation_average))\n",
        "\n",
        "    # Convert predictions to Numpy for classification_report\n",
        "    preds_np = preds.cpu().numpy()  # Move to CPU before converting\n",
        "\n",
        "    # Generate classification report\n",
        "    class_names  = [id2label[i] for i in range(len(id2label))]\n",
        "    class_report = classification_report(labels_np, preds_np, target_names=class_names, zero_division=0)\n",
        "\n",
        "    #print(f\"\\nClassification Report:\\n{class_report}\")\n",
        "\n",
        "    # Store metrics\n",
        "    metrics = {\n",
        "        'accurary'             : accuracy.item(),\n",
        "        'precision'            : precision.item(),\n",
        "        'recall'               : recall.item(),\n",
        "        'f1'                   : f1.item(),\n",
        "        'roc_auc'              : roc_auc.item(),\n",
        "        'pr_auc'               : pr_auc.item(),\n",
        "        'per_class_precision'  : {id2label[i]: precision_per_class[i].item() for i in range(len(id2label))},\n",
        "        'per_class_recall'     : {id2label[i]: recall_per_class[i].item() for i in range(len(id2label))},\n",
        "        'per_class_f1'         : {id2label[i]: f1_per_class[i].item() for i in range(len(id2label))},\n",
        "        'classification_report': class_report,\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehquE8Ii2yNT"
      },
      "outputs": [],
      "source": [
        "evaluation_model_eval_metrics = compute_metrics_with_threshold(model, validation_dataset, optimized_thresholds, id2label, batch_size=16)\n",
        "\n",
        "except_report = {k: v for k, v in evaluation_model_eval_metrics.items() if k!='classification_report'}\n",
        "report        = evaluation_model_eval_metrics['classification_report']\n",
        "print(f\"evaluation_model_eval_metrics: {type(except_report)} len={len(except_report)}\\n{json.dumps(except_report, indent=4)}\")\n",
        "print(f\"evaluation_model_eval_metrics['classification_report']: {type(report)} len={len(report)}\\n{report}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu5iSiinCUOh",
        "outputId": "9ecae1dd-395f-46bb-ef7b-649aa880a580"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "evaluation 3: model.eval: successfully completed\n"
          ]
        }
      ],
      "source": [
        "print(\"evaluation 3: model.eval: successfully completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFwAT0oWHawd"
      },
      "source": [
        "### Evaluation 3: model.eval: save locally and upload to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilEmnR5jHeYs"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    name                       = \"evaluation_model_eval\"\n",
        "    evaluation_model_eval_path = f\"{name}.json\"\n",
        "\n",
        "    with open(evaluation_model_eval_path, \"w\") as f:\n",
        "        json.dump(evaluation_model_eval_metrics, f)\n",
        "\n",
        "    print(f\"{name} successfully saved locally to {evaluation_model_eval_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = evaluation_model_eval_path,\n",
        "        path_in_repo    = evaluation_model_eval_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} successfully uploaded to HF Hub as {evaluation_model_eval_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYSVoKZDAq4e"
      },
      "source": [
        "## Test step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lCQusokDRda"
      },
      "source": [
        "### Test 1: trainer.evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B6m5pYJM_0e"
      },
      "outputs": [],
      "source": [
        "test_trainer_evaluate_metrics = trainer.evaluate(\n",
        "    eval_dataset = encoded_dataset['test'],\n",
        "    metric_key_prefix='test'\n",
        ")\n",
        "\n",
        "print(f\"test_trainer_evaluate_metrics: {type(test_trainer_evaluate_metrics)} len={len(test_trainer_evaluate_metrics)}\\n{json.dumps(test_trainer_evaluate_metrics, indent=4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JuMtbi6ODIJ"
      },
      "outputs": [],
      "source": [
        "print(\"test_trainer.evaluate successfully completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LosNwpYCOV2F"
      },
      "source": [
        "### Test 1: trainer.evaluate: save locally and upload to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuJvVmF8Oj8M"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    name                       = \"test_trainer_evaluate\"\n",
        "    test_trainer_evaluate_path = f\"{name}.json\"\n",
        "\n",
        "    with open(test_trainer_evaluate_path, \"w\") as f:\n",
        "        json.dump(test_trainer_evaluate_metrics, f)\n",
        "\n",
        "    print(f\"{name} results successfully saved locally to {test_trainer_evaluate_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = test_trainer_evaluate_path,\n",
        "        path_in_repo    = test_trainer_evaluate_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} results successfully uploaded to HF Hub as {test_trainer_evaluate_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJNMb3idDapI"
      },
      "source": [
        "### Test 2: trainer.predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9jKJjJACguS"
      },
      "outputs": [],
      "source": [
        "optimized_thresholds, optimized_thresholds_dict, test_trainer_predict_metrics, test_trainer_predict_global_metrics = predict_with_optimized_thresholds(\n",
        "    trainer, test_dataset, id2label, threshold_tuning=False, thresholds=optimized_thresholds)\n",
        "\n",
        "print(f\"optimized_thresholds: {type(optimized_thresholds)} shape={optimized_thresholds.shape} {optimized_thresholds}\")\n",
        "print(f\"optimized_thresholds_dict: {type(optimized_thresholds_dict)} len={len(optimized_thresholds_dict)}\\n{optimized_thresholds_dict}\")\n",
        "print(f\"test_trainer_predict_metrics: {type(test_trainer_predict_metrics)} len={len(test_trainer_predict_metrics)}\\n{json.dumps(test_trainer_predict_metrics, indent=4)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "R9lfg-tYjaWC"
      },
      "outputs": [],
      "source": [
        "#test_trainer_predict_results = predict_with_optimized_thresholds(\n",
        "#    trainer, test_dataset, id2label, threshold_tuning=False, thresholds=optimized_thresholds)\n",
        "\n",
        "#except_report = {k: v for k, v in test_trainer_predict_results.items() if k!='classification_report'}\n",
        "#report        = test_trainer_predict_results['classification_report']\n",
        "#print(f\"test_trainer_predict_results: {type(except_report)} len={len(except_report)}\\n{json.dumps(except_report, indent=4)}\")\n",
        "#print(f\"test_trainer_predict_results['classification_report']: {type(report)} len={len(report)}\\n{report}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fs3FWd4mfUu"
      },
      "outputs": [],
      "source": [
        "print(\"test_trainer.predict successfully completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr9L2hoGoQF-"
      },
      "source": [
        "### Test 2: trainer.predict: save locally and upload to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq1WgCmgoioR"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    name                      = \"test_trainer_predict\"\n",
        "    test_trainer_predict_path = f\"{name}.json\"\n",
        "\n",
        "    with open(test_trainer_predict_path, \"w\") as f:\n",
        "        json.dump(test_trainer_predict_metrics, f)\n",
        "\n",
        "    print(f\"{name} results successfully saved locally to {test_trainer_predict_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = test_trainer_predict_path,\n",
        "        path_in_repo    = test_trainer_predict_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} results successfully uploaded to HF Hub as {test_trainer_predict_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAvjnQsiPvA3"
      },
      "source": [
        "### Test 3: model.eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEmK1IiGPBQ5"
      },
      "outputs": [],
      "source": [
        "test_model_eval_metrics = compute_metrics_with_threshold(model, test_dataset, optimized_thresholds, id2label, batch_size=16)\n",
        "\n",
        "except_report = {k: v for k, v in test_model_eval_metrics.items() if k!='classification_report'}\n",
        "report        = test_model_eval_metrics['classification_report']\n",
        "print(f\"test_model_eval_metrics: {type(except_report)} len={len(except_report)}\\n{json.dumps(except_report, indent=4)}\")\n",
        "print(f\"test_model_eval_metrics['classification_report']: {type(report)} len={len(report)}\\n{report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xsR393boVNL"
      },
      "source": [
        "### Test 3: model.eval: save locally and upload to HF Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjInlLbeoSw3"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    name                 = \"test_model_eval\"\n",
        "    test_model_eval_path = f\"{name}.json\"\n",
        "\n",
        "    with open(test_model_eval_path, \"w\") as f:\n",
        "        json.dump(test_model_eval_metrics, f)\n",
        "\n",
        "    print(f\"{name} successfully saved locally to {test_model_eval_path}\")\n",
        "\n",
        "    upload_file(\n",
        "        path_or_fileobj = test_model_eval_path,\n",
        "        path_in_repo    = test_model_eval_path,\n",
        "        repo_id         = repo_id,\n",
        "        repo_type       = 'dataset',\n",
        "        commit_message  = f\"{name}_{timestamp}\"\n",
        "    )\n",
        "\n",
        "    print(f\"{name} successfully uploaded to HF Hub as {test_model_eval_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVQXo7SvwcJ7"
      },
      "source": [
        "## Upload tokenizer and model to HF Hub and check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSAz3pspFNsm"
      },
      "outputs": [],
      "source": [
        "if upload_to_HF is True:\n",
        "\n",
        "    # Upload\n",
        "    commit_message = f\"'24000_micro_micro_model_tokenizer'_{timestamp}\"\n",
        "\n",
        "    tokenizer.push_to_hub(repo_id, commit_message=commit_message)  # commit_message as named parameter\n",
        "    model.push_to_hub(    repo_id, commit_message=commit_message)  # commit_message as named parameter\n",
        "\n",
        "    print(f\"tokenizer and model successfully uploaded to HF Hub at {repo_id}\")\n",
        "\n",
        "    # Check\n",
        "    def check_upload(repo_id):\n",
        "        print()\n",
        "        print(\"Tokenizer\")\n",
        "        tokenizer = LongformerTokenizerFast.from_pretrained(repo_id)\n",
        "        print()\n",
        "        print(\"Model\")\n",
        "        model = LongformerForSequenceClassification.from_pretrained(repo_id)\n",
        "        print()\n",
        "\n",
        "        inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        print(f\"outputs: {type(outputs)} {outputs.keys()}\\n{outputs}\")\n",
        "\n",
        "    # To check if the upload was successful, download the tokenizer and the model\n",
        "    check_upload(repo_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvh_jDvdBt26"
      },
      "outputs": [],
      "source": [
        "print(\"It's the end\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Q9ThLZFflK7v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "f9dc9ba5-d4fc-4bfe-a9cc-95bfc0703d00"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "I stop here",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-53b8a3cc861f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I stop here\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mException\u001b[0m: I stop here"
          ]
        }
      ],
      "source": [
        " raise Exception(\"I stop here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9CetqX9zAM3"
      },
      "source": [
        "=========================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqxhHkT1wcJ4"
      },
      "outputs": [],
      "source": [
        "# Define the weighted loss function\n",
        "\n",
        "class_weights = torch.tensor([7.68, 2.15, 0.61, 0.47, 0.68, 6.26], dtype=torch.float32).to(device)\n",
        "loss_fn       = BCEWithLogitsLoss(pos_weight=class_weights)  # For multi-label classification (binary classification per label)\n",
        "\n",
        "## Class supports, class weigths, weighted loss function\n",
        "\n",
        "#Reminder:\n",
        "#*   df_jobs      : <class 'pandas.core.frame.DataFrame'>\n",
        "#*   df_jobs['id']: <class 'pandas.core.series.Series'>\n",
        "\n",
        "#dataset = Dataset.from_pandas(df_jobs)\n",
        "#*   dataset      : <class 'datasets.arrow_dataset.Dataset'>\n",
        "#*   dataset['id']: <class 'list'>\n",
        "\n",
        "#*   dataset_dict_jobs : <class 'datasets.dataset_dict.DatasetDict'>\n",
        "#*   train_dataset     : <class 'datasets.arrow_dataset.Dataset'>\n",
        "#*   validation_dataset: <class 'datasets.arrow_dataset.Dataset'>\n",
        "#*   test_dataset      : <class 'datasets.arrow_dataset.Dataset'>\n",
        "\n",
        "\n",
        "#We calculate the class supports for the train, validation and test datasets; the class weights and the weighted loss function are used for training only; the class supports of validation_dataset and test_dataset are calculated for information only.\n",
        "# function B\n",
        "def get_train_class_weights(datasetDict, labels):\n",
        "  print(f\"datasetDict: {type(datasetDict)} shape={datasetDict.shape}\\n{datasetDict}\")\n",
        "  print(f\"labels: {type(labels)} len={len(labels)}\\n{labels}\")\n",
        "\n",
        "  dataset_train      = datasetDict['train']\n",
        "  dataset_validation = datasetDict['validation']\n",
        "  dataset_test       = datasetDict['test']\n",
        "\n",
        "  def calculate_class_supports(dataset, labels):\n",
        "    class_supports = dataset.map(\n",
        "        lambda example: {col: example[col] for col in labels},\n",
        "        batched=True\n",
        "    ).to_pandas()[labels].sum(axis=0)\n",
        "    return class_supports\n",
        "\n",
        "  class_supports = {}\n",
        "\n",
        "  for split_name, split_dataset in datasetDict.items():\n",
        "    class_supports[split_name] = calculate_class_supports(split_dataset, labels)\n",
        "\n",
        "  for split_name, split_class_supports in class_supports.items():\n",
        "    print(f\"{split_name}: {type(split_class_supports)} len={len(split_class_supports)}\\n{split_class_supports}\")\n",
        "\n",
        "  train_class_supports_list = class_supports['train'].tolist()\n",
        "  print(f\"train_class_supports_list: {type(train_class_supports_list)} len={len(train_class_supports_list)} {train_class_supports_list}\")\n",
        "\n",
        "  train_class_supports_tensor = torch.tensor(train_class_supports_list, dtype=torch.float32)\n",
        "  print(f\"train_class_supports_tensor: {type(train_class_supports_tensor)} len={len(train_class_supports_tensor)} {train_class_supports_tensor}\")\n",
        "\n",
        "  train_total_samples = dataset_train.num_rows\n",
        "  print(f\"train_total_samples: {train_total_samples}\")\n",
        "\n",
        "  number_of_classes = len(labels)\n",
        "  print(f\"number_of_classes: {number_of_classes}\")\n",
        "\n",
        "  train_class_weights = train_total_samples / (number_of_classes * train_class_supports_tensor)\n",
        "  print(f\"train_class_weights: {type(train_class_weights)} len={len(train_class_weights)} {train_class_weights}\")\n",
        "\n",
        "  train_class_weights_sum = train_class_weights.sum()\n",
        "  print(f\"train_class_weights_sum: {train_class_weights_sum}\")\n",
        "\n",
        "  normalized_train_class_weights = (train_class_weights / train_class_weights_sum) * number_of_classes\n",
        "  print(f\"normalized_train_class_weights: {type(normalized_train_class_weights)} len={len(normalized_train_class_weights)} {normalized_train_class_weights}\")\n",
        "\n",
        "  # Positives samples per label\n",
        "  supports = train_class_supports_tensor\n",
        "  print(f\"supports: {type(supports)} {len(supports)} {supports}\")\n",
        "\n",
        "  # Negatives samples per label\n",
        "  negatives = train_total_samples - supports\n",
        "  print(f\"negatives: {type(negatives)} {len(negatives)} {negatives}\")\n",
        "\n",
        "  # pos_weights = negative to positive ratios\n",
        "  pos_weights = negatives/supports\n",
        "  print(f\"pos_weights: {type(pos_weights)} {len(pos_weights)} {pos_weights}\")\n",
        "\n",
        "  # Normalize using min-max scaling\n",
        "  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\n",
        "  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\n",
        "\n",
        "  # Normalize using z-score standardization\n",
        "  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\n",
        "  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\n",
        "\n",
        "  # Normalize using min-max scaling\n",
        "  normalized_pos_weights_minmax = (pos_weights - pos_weights.min()) / (pos_weights.max() - pos_weights.min())\n",
        "  print(f\"normalized_pos_weights_minmax: {type(normalized_pos_weights_minmax)} {len(normalized_pos_weights_minmax)} {normalized_pos_weights_minmax}\")\n",
        "\n",
        "  # Normalize using z-score standardization\n",
        "  normalized_pos_weights_zscore = (pos_weights - pos_weights.mean()) / pos_weights.std()\n",
        "  print(f\"normalized_pos_weights_zscore: {type(normalized_pos_weights_zscore)} {len(normalized_pos_weights_zscore)} {normalized_pos_weights_zscore}\")\n",
        "\n",
        "  # Normalize using sum-to-one\n",
        "  normalized_pos_weights_sum1 = pos_weights / pos_weights.sum()\n",
        "  print(f\"normalized_pos_weights_sum1: {type(normalized_pos_weights_sum1)} {len(normalized_pos_weights_sum1)} {normalized_pos_weights_sum1}\")\n",
        "\n",
        "  return normalized_pos_weights_minmax\n",
        "  #return normalized_pos_weights_zscore\n",
        "  #return normalized_pos_weights_sum1\n",
        "\n",
        "pos_weights = get_train_class_weights(datasetDict, labels)\n",
        "\n",
        "loss_fn = BCEWithLogitsLoss(pos_weight=pos_weights.to(device))  # For multi-label classification (binary classification per label)\n",
        "print(f\"loss_fn: {type(loss_fn)} {loss_fn}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5BOwuD1RnQe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Data from your training results\n",
        "epochs = np.arange(1, 9)\n",
        "training_loss = [0.3122, 0.2897, 0.2665, 0.2466, 0.2244, 0.2223, 0.2202, 0.2077]\n",
        "validation_loss = [0.303785, 0.293599, 0.278830, 0.275663, 0.280968, 0.280640, 0.279608, 0.282026]\n",
        "f1_score = [0.865113, 0.871222, 0.875554, 0.880279, 0.879128, 0.878554, 0.879872, 0.877893]\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, training_loss, label='Training Loss', marker='o')\n",
        "plt.plot(epochs, validation_loss, label='Validation Loss', marker='s')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# Plot F1 Score\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, f1_score, label='F1 Score', marker='o', color='green')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.title('F1 Score over Epochs')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVn29oBT2n0k"
      },
      "outputs": [],
      "source": [
        "example = datasetDict['test'][0]\n",
        "print(f\"datasetDict['test'][0]: {type(example)} {example.keys()}\\n{example}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spiVOeMhz6Ku"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(\n",
        "    example['text'],\n",
        "    truncation     = True,\n",
        "    padding        = 'max_length',\n",
        "    max_length     = max_length,\n",
        "    return_tensors = 'pt'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2U-0iYO0LWf"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():  # Disable gradient calculation during prediction\n",
        "    outputs = model(\n",
        "        input_ids=inputs.input_ids.to(device),\n",
        "        attention_mask=inputs.attention_mask.to(device)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-VuKUM10dte"
      },
      "outputs": [],
      "source": [
        "probs = torch.sigmoid(outputs.logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMOj7NB11CH8"
      },
      "outputs": [],
      "source": [
        "best_thresholds = [0.4, 0.3, 0.3, 0.3, 0.4, 0.5]\n",
        "preds = np.zeros_like(probs)  # Initialize predictions array\n",
        "for label_idx in range(num_labels):\n",
        "  preds[:, label_idx] = (probs[:, label_idx] > best_thresholds[label_idx])  #.astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICCj8Hm3i_GP"
      },
      "outputs": [],
      "source": [
        "print(f\"probs: {type(probs)} shape={probs.shape}\\n{probs}\")\n",
        "print(f\"preds: {type(preds)} shape={preds.shape}\\n{preds}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiCmBf-kjcfc"
      },
      "outputs": [],
      "source": [
        "print(f\"labels: {type(labels)} {len(labels)}\\n{labels}\")\n",
        "# '390': False, '135': False, '136': True, '137': True, '138': True, '139': False}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJFDabZ41cbP"
      },
      "outputs": [],
      "source": [
        "def tune_thresholds(true_labels, probs, id2label):\n",
        "  \"\"\"\n",
        "  Tune thresholds for each label to maximize F1 alone, as F1 balances precision and recall into a single metric.\n",
        "\n",
        "  Args:\n",
        "    true_labels: actual labels for the data                                      (numpy array of shape (num_samples, num_labels))\n",
        "    probs      : predicted probabilities                                         (numpy array of shape (num_samples, num_labels))\n",
        "    id2label   : dictionary mapping label indices (int) to label names (string)\n",
        "\n",
        "  Returns:\n",
        "    best_thresholds: best threshold for each label                                                      (numpy array of shape (num_labels,))\n",
        "    best_metrics   : dictionary of best F1, precision_for_best_f1 and recall_for_best_f1 for each label (dictionary of numpy arrays)\n",
        "  \"\"\"\n",
        "  thresholds      = np.linspace(0.1, 0.9, 9)\n",
        "  best_thresholds = np.zeros(len(id2label))\n",
        "  best_metrics    = {label: {'f1': 0.0, 'precision': 0.0, 'recall': 0.0} for label in id2label.values()}\n",
        "\n",
        "  for label_idx, label in id2label.items():\n",
        "    for threshold in thresholds:\n",
        "      pred                     = (probs[:, label_idx] > threshold).astype(int)\n",
        "      precision, recall, f1, _ = precision_recall_fscore_support(true_labels[:, label_idx], pred, average='binary', zero_division=0)\n",
        "      if f1 > best_metrics[label]['f1']:\n",
        "        best_thresholds[label_idx]       = threshold\n",
        "        best_metrics[label]['f1']        = f1\n",
        "        best_metrics[label]['precision'] = precision\n",
        "        best_metrics[label]['recall']    = recall\n",
        "\n",
        "  print(\"==== tune_thresholds ====\")\n",
        "  print(f\"best_thresholds: {type(best_thresholds)} shape={best_thresholds.shape}\\n{best_thresholds}\")\n",
        "  print(f\"best_metrics   : {type(best_metrics)}    len={len(best_metrics)}      \\n{json.dumps(best_metrics, indent=4)}\")\n",
        "  print(\"=========================\")\n",
        "  print()\n",
        "\n",
        "  return best_thresholds, best_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBsBg2vL1y6s"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_with_threshold_OLD(probs, label_ids, thresholds, id2label):\n",
        "    \"\"\"\n",
        "    Compute metrics during evaluation or test, by applying tuned thresholds\n",
        "\n",
        "    average:\n",
        "    - 'micro'   : gives more weight to frequent labels     → best for imbalanced datasets where frequent labels are more important\n",
        "    - 'macro'   : treats all labels equally                → best when you care about rare labels as much as frequent ones\n",
        "    - 'weighted': like macro but considers label frequency → best if you want a compromise between macro and micro\n",
        "\n",
        "    - 'macro' or 'weighted' AUC is often best because AUC isn't as affected by class imbalance as F1/Precision/Recall\n",
        "    - 'macro'      AUC: usually the best because it treats all labels equally, avoiding the dominance of frequent labels\n",
        "    - 'weighted'   AUC: similar to macro but considers label frequency\n",
        "    - 'macro'   PR AUC: best for imbalanced datasets because it treats rare labels fairly\n",
        "    - 'weighted PR AUC: also good, but slightly biased toward frequent labels\n",
        "\n",
        "    PR AUC is better than ROC AUC when you care about positive examples in imbalanced data\n",
        "    \"\"\"\n",
        "    average = 'macro'\n",
        "    preds   = np.zeros_like(probs)\n",
        "\n",
        "    # Apply per-label tuned threshold\n",
        "    for label_idx in id2label.keys():\n",
        "        preds[:, label_idx] = (probs[:, label_idx] > thresholds[label_idx]).astype(int)\n",
        "\n",
        "    # Compute metrics\n",
        "    f1        = f1_score       (label_ids, preds, average=average)\n",
        "    precision = precision_score(label_ids, preds, average=average)\n",
        "    recall    = recall_score   (label_ids, preds, average=average)\n",
        "    accuracy  = accuracy_score (label_ids, preds)\n",
        "\n",
        "    # Compute AUC scores with error handling\n",
        "    try:\n",
        "        roc_auc              = roc_auc_score          (label_ids, probs, average=average)\n",
        "    except ValueError:\n",
        "        roc_auc              = 0.0\n",
        "\n",
        "    try:\n",
        "        precision_recall_auc = average_precision_score(label_ids, probs, average=average)\n",
        "    except ValueError:\n",
        "        precision_recall_auc = 0.0\n",
        "\n",
        "    # Compute per-class metrics (average = None)\n",
        "    per_class_f1        = f1_score       (label_ids, preds, average=None)\n",
        "    per_class_precision = precision_score(label_ids, preds, average=None)\n",
        "    per_class_recall    = recall_score   (label_ids, preds, average=None)\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(label_ids, preds, target_names=id2label.values(), zero_division=0)\n",
        "\n",
        "    # Store metrics\n",
        "    metrics = {\n",
        "        'f1'                   : f1,\n",
        "        'precision'            : precision,\n",
        "        'recall'               : recall,\n",
        "        'accuracy'             : accuracy,\n",
        "        'roc_auc'              : roc_auc,\n",
        "        'precision_recall_auc' : precision_recall_auc,\n",
        "        'thresholds'           : thresholds.tolist(),\n",
        "        'classification_report': report,\n",
        "        'per_class_f1'         : per_class_f1,\n",
        "        'per_class_precision'  : per_class_precision,\n",
        "        'per_class_recall'     : per_class_recall\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OYJ-0tP2E7c"
      },
      "outputs": [],
      "source": [
        "def predict_with_optimized_thresholds_cuda(trainer, dataset, threshold_tuning=False, thresholds=None, threshold=threshold):\n",
        "    \"\"\"\n",
        "    Predicts using trainer.predict(), with optional threshold tuning on GPU\n",
        "\n",
        "    Parameters:\n",
        "    - trainer         : Hugging Face Trainer or CustomTrainer instance\n",
        "    - dataset         : dataset to predict on\n",
        "    - id2label        : dictionary mapping label indices (int) to label names (string)\n",
        "    - threshold_tuning: boolean to enable thresholds tuning per class (if evaluation, True, if prediction, False)\n",
        "    - thresholds      : if evaluation, custom thresholds, if prediction, tuned thresholds (from evaluation)\n",
        "\n",
        "    Returns:\n",
        "    - best_thresholds (if threshold_tuning=True): optimized threshold for each label\n",
        "    - best_metrics                              : computed with tuned thresholds whether for evaluation or prediction\n",
        "\n",
        "    - metrics (if threshold_tuning=False): computed with fixed thresholds\n",
        "    - metrics (if threshold_tuning=True): computed with tuned thresholds\n",
        "    - predictions: final binary predictions\n",
        "    - label_ids  : ground true labels from the dataset\n",
        "    - best_thresholds (if threshold_tuning=True): optimized threshold per class\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Auto-detect GPU\n",
        "\n",
        "    # Predict\n",
        "    predictions_output = trainer.predict(dataset)        # <class 'transformers.trainer_utils.PredictionOutput'> len   = 3\n",
        "    predictions_np     = predictions_output.predictions  # <class 'numpy.ndarray'>                               shape = (2400, 6)\n",
        "    label_ids_np       = predictions_output.label_ids    # <class 'numpy.ndarray'>                               shape = (2400, 6)\n",
        "    metrics_dict       = predictions_output.metrics      # <class 'dict'> (= trainer.evaluate results)           len   = 10\n",
        "\n",
        "    print(\"==== predictions_output ====\")\n",
        "    print(f\"predictions_output.predictions: {type(predictions_np)} shape={predictions_np.shape} \\n{predictions_np}\")\n",
        "    print(f\"predictions_output.label_ids  : {type(label_ids_np)}   shape={label_ids_np.shape}   \\n{label_ids_np}\")\n",
        "    print(f\"predictions_output.metrics    : {type(metrics_dict)}   len={len(metrics_dict)}      \\n{json.dumps(metrics_dict, indent=4)}\")\n",
        "\n",
        "    # Convert NumPy arrays to PyTorch tensors (torch.from_numpy() keeps the NumPy array's memory layout, while torch.tensor() creates a new copy)\n",
        "    logits      = torch.tensor(predictions_np, device=device)  # Move to GPU\n",
        "    true_labels = torch.tensor(label_ids_np, device=device)    # Move to GPU\n",
        "\n",
        "    print(f\"logits     : {type(logits)}      shape={logits.shape}     \\n{logits}\")\n",
        "    print(f\"true_labels: {type(true_labels)} shape={true_labels.shape}\\n{true_labels}\")\n",
        "\n",
        "    # Convert logits to probabilities using PyTorch (on GPU)\n",
        "    probs = torch.sigmoid(logits)  # <class 'torch.Tensor'>  shape = (1200, 6)\n",
        "\n",
        "    print(f\"probs: {type(probs)} shape={probs.shape}\\n{probs}\")\n",
        "    print(\"============================\")\n",
        "    print()\n",
        "\n",
        "    num_labels = probs.shape[1]\n",
        "\n",
        "    if threshold_tuning:\n",
        "        best_thresholds = torch.full((num_labels,), threshold, device=device, dtype=torch.float32)  # Default to threshold\n",
        "\n",
        "        # Define candidate thresholds (on GPU)\n",
        "        threshold_candidates = torch.linspace(0.05, 0.95, 19, device=device)\n",
        "\n",
        "        for label_idx in range(num_labels):\n",
        "            best_f1 = 0\n",
        "            for threshold in threshold_candidates:\n",
        "                preds = (probs[:, label_idx] > threshold).int()\n",
        "\n",
        "                # Convert to CPU for sklearn\n",
        "                precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                    true_labels[:, label_idx].cpu().numpy(),\n",
        "                    preds.cpu().numpy(),\n",
        "                    average='binary',\n",
        "                    zero_division=0\n",
        "                )\n",
        "\n",
        "                if f1 > best_f1:\n",
        "                    best_f1                    = f1\n",
        "                    best_thresholds[label_idx] = threshold  # Store best threshold\n",
        "\n",
        "        return probs, true_labels, best_thresholds\n",
        "\n",
        "    # Apply provided thresholds (or default to 0.5)\n",
        "    if thresholds is None:\n",
        "        thresholds = torch.full((num_labels,), 0.5, device=device)  # Default to 0.5\n",
        "    else:\n",
        "        thresholds = torch.tensor(thresholds, device=device)  # Move thresholds to GPU\n",
        "\n",
        "    preds = (probs > thresholds).int()\n",
        "\n",
        "    return preds, true_labels, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwTLn73u1n6m"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_with_threshold_SAV(probs, label_ids, thresholds, id2label):\n",
        "\n",
        "  #Compute metrics during evaluation or test, by applying tuned thresholds\n",
        "\n",
        "  #logits  = eval_preds.predictions\n",
        "  #labels  = eval_preds.label_ids\n",
        "  #sigmoid = torch.nn.Sigmoid  # Sigmoid or numpy?\n",
        "  #probs   = sigmoid(logits).cpu().numpy()\n",
        "  preds   = np.zeros_like(probs)\n",
        "\n",
        "  if threshold_tuning:\n",
        "    # Apply per-label tuned threshold\n",
        "    for label_idx in id2label.keys():\n",
        "        preds[:, label_idx] = (probs[:, label_idx] > thresholds[label_idx]).astype(int)\n",
        "  else:\n",
        "    # threhsolds = None, apply a fixed threshold to all labels\n",
        "    for label_idx in id2label.keys():\n",
        "        preds[:, label_idx] = (probs[:, label_idx] > threshold).astype(int)\n",
        "\n",
        "  # Compute metrics\n",
        "  f1                    = f1_score               (label_ids, preds, average='micro')\n",
        "  precision             = precision_score        (label_ids, preds, average='micro')\n",
        "  recall                = recall_score           (label_ids, preds, average='micro')\n",
        "  accuracy              = accuracy_score         (label_ids, preds)\n",
        "  roc_auc               = roc_auc_score          (label_ids, probs, average='micro')  # multi_class=\"ovr\" <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "  precision_recall_auc  = average_precision_score(label_ids, probs, average='micro')\n",
        "\n",
        "  # Use id2label for target_names\n",
        "  report = classification_report(label_ids, preds, target_names=id2label.values(), zero_division=0)\n",
        "\n",
        "  if threshold_tuning:\n",
        "    _thresholds = thresholds.tolist()\n",
        "  else:\n",
        "    _thresholds = threshold\n",
        "\n",
        "  metrics = {\n",
        "      'f1'                   : f1,\n",
        "      'precision'            : precision,\n",
        "      'recall'               : recall,\n",
        "      'accuracy'             : accuracy,\n",
        "      'roc_auc'              : roc_auc,\n",
        "      'precision_recall_auc' : precision_recall_auc,\n",
        "      'thresholds'           : _thresholds,\n",
        "      'classification_report': report\n",
        "  }\n",
        "\n",
        "  return metrics"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "jupytext": {
      "formats": "ipynb,py:nomarker"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9eeb1118bee8461f91d8c156ed3f270f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f703be34c38d48349e74d7a1660123d5",
              "IPY_MODEL_3629050037d5487488ca0338b4d4a306",
              "IPY_MODEL_75c90dd61a5e4d47beb5693aa119245a"
            ],
            "layout": "IPY_MODEL_191530e94c524e5da7f3c899da8e0442"
          }
        },
        "f703be34c38d48349e74d7a1660123d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ceef31e9d043f19f13e5460810ac3f",
            "placeholder": "​",
            "style": "IPY_MODEL_beedfe692f2844199fec5f69e6c2f9c6",
            "value": "vocab.json: 100%"
          }
        },
        "3629050037d5487488ca0338b4d4a306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a7bcf90a7594d018f9742759beb7e3a",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7272b2c4bc874beb8f9f45d9a8a59895",
            "value": 898823
          }
        },
        "75c90dd61a5e4d47beb5693aa119245a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18ab4b0f21af431aadc337e2abeca5e8",
            "placeholder": "​",
            "style": "IPY_MODEL_ac09aaad47184e39bb201abf08bf209c",
            "value": " 899k/899k [00:00&lt;00:00, 5.37MB/s]"
          }
        },
        "191530e94c524e5da7f3c899da8e0442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ceef31e9d043f19f13e5460810ac3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beedfe692f2844199fec5f69e6c2f9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a7bcf90a7594d018f9742759beb7e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7272b2c4bc874beb8f9f45d9a8a59895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18ab4b0f21af431aadc337e2abeca5e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac09aaad47184e39bb201abf08bf209c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e15bc8f3e584504ad58fd03c99d82bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_31a2fed1c7504dd081c70b18cde44adc",
              "IPY_MODEL_b255639f84e1448690c8bb2b6fce67eb",
              "IPY_MODEL_38de7e3458be45a4aff66a3497bf718c"
            ],
            "layout": "IPY_MODEL_96af2a331f6e410cb183fb576ef64418"
          }
        },
        "31a2fed1c7504dd081c70b18cde44adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c879cf63f4144908b757b7f3f4858ddb",
            "placeholder": "​",
            "style": "IPY_MODEL_9a875ff1ff194104a25aae3c764643de",
            "value": "merges.txt: 100%"
          }
        },
        "b255639f84e1448690c8bb2b6fce67eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_891d72ed989b4790a90b7f6c8ec9923e",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3907f0cf0c040ce80a2bcc06c72ac69",
            "value": 456318
          }
        },
        "38de7e3458be45a4aff66a3497bf718c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515ffb9db6114705bd366c194e495d60",
            "placeholder": "​",
            "style": "IPY_MODEL_bba590745cfa4f86b93677184300b4ee",
            "value": " 456k/456k [00:00&lt;00:00, 41.2MB/s]"
          }
        },
        "96af2a331f6e410cb183fb576ef64418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c879cf63f4144908b757b7f3f4858ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a875ff1ff194104a25aae3c764643de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "891d72ed989b4790a90b7f6c8ec9923e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3907f0cf0c040ce80a2bcc06c72ac69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "515ffb9db6114705bd366c194e495d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba590745cfa4f86b93677184300b4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0a727faa87f49a2acf755fb70ee6312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13381aeed3db4ac08e0f52106e86f196",
              "IPY_MODEL_af54ce7f889d483b909e5d6038a27103",
              "IPY_MODEL_fddae10fac8f428384e31df0d9c3949d"
            ],
            "layout": "IPY_MODEL_bd1977ea00a54dcd81e5b5ec249c39f1"
          }
        },
        "13381aeed3db4ac08e0f52106e86f196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_738094b56a5b4ea9beaa29cb2a25bffa",
            "placeholder": "​",
            "style": "IPY_MODEL_1dc90bee080d4c8c8b6f159db2413d99",
            "value": "tokenizer.json: 100%"
          }
        },
        "af54ce7f889d483b909e5d6038a27103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a73d3b6aaf224d32a99a78b13c434b71",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a9e82da6d924e2899ef456c50d1133a",
            "value": 1355863
          }
        },
        "fddae10fac8f428384e31df0d9c3949d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e3f4469d2b54849ad2348bb1cc15b36",
            "placeholder": "​",
            "style": "IPY_MODEL_e713c03a042c4195a332cecf9b45ba6f",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 36.7MB/s]"
          }
        },
        "bd1977ea00a54dcd81e5b5ec249c39f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "738094b56a5b4ea9beaa29cb2a25bffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc90bee080d4c8c8b6f159db2413d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a73d3b6aaf224d32a99a78b13c434b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a9e82da6d924e2899ef456c50d1133a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e3f4469d2b54849ad2348bb1cc15b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e713c03a042c4195a332cecf9b45ba6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6398ae9fbb5340218d336db314f68858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4adc21d1beb84b488d9e7a3a0222c722",
              "IPY_MODEL_e3deedb0897449849e22060dafb2dcc2",
              "IPY_MODEL_0eadb18dc1ef4ea6ba6b70002da54d2e"
            ],
            "layout": "IPY_MODEL_b060794f339e4211bfc21db75cdf5d39"
          }
        },
        "4adc21d1beb84b488d9e7a3a0222c722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c09c23cf16e042d38a6d8ea2eaea90f3",
            "placeholder": "​",
            "style": "IPY_MODEL_28c12f474a1844388680280509144e5d",
            "value": "config.json: 100%"
          }
        },
        "e3deedb0897449849e22060dafb2dcc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25f0d589f7d2442580a652538f9d739f",
            "max": 694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_991f45ebdc2745ce9cb87f6e557d7cde",
            "value": 694
          }
        },
        "0eadb18dc1ef4ea6ba6b70002da54d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d25b65b6873446eb0e31a2754fda727",
            "placeholder": "​",
            "style": "IPY_MODEL_a79af92810e14343ae43a8ee1a4f5e7e",
            "value": " 694/694 [00:00&lt;00:00, 89.1kB/s]"
          }
        },
        "b060794f339e4211bfc21db75cdf5d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c09c23cf16e042d38a6d8ea2eaea90f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28c12f474a1844388680280509144e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25f0d589f7d2442580a652538f9d739f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991f45ebdc2745ce9cb87f6e557d7cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d25b65b6873446eb0e31a2754fda727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79af92810e14343ae43a8ee1a4f5e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7192533171b64a38bd77441aec920aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb645757c2ee446c9d1e53ab0fd252e0",
              "IPY_MODEL_b8451f2af4894df08a5d60130ddb4a58",
              "IPY_MODEL_59c67ee553944b188a41d250ed5ae05b"
            ],
            "layout": "IPY_MODEL_10236bb8de4f4ecc9fb6f28b3c60c6c4"
          }
        },
        "fb645757c2ee446c9d1e53ab0fd252e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee1fb31abe440d197bc39eaed3fb52f",
            "placeholder": "​",
            "style": "IPY_MODEL_ca385acc53de4c7cad85f003d55a1f44",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b8451f2af4894df08a5d60130ddb4a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b0de8bfa51e426cbc9c6fbbf4925f98",
            "max": 597257159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e64a31e5c387412596497eb1b60fec57",
            "value": 597257159
          }
        },
        "59c67ee553944b188a41d250ed5ae05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7591344a75de4c96b4f8186087337d08",
            "placeholder": "​",
            "style": "IPY_MODEL_e06aad979b784b188823b8584cbe28c3",
            "value": " 597M/597M [00:04&lt;00:00, 130MB/s]"
          }
        },
        "10236bb8de4f4ecc9fb6f28b3c60c6c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee1fb31abe440d197bc39eaed3fb52f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca385acc53de4c7cad85f003d55a1f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b0de8bfa51e426cbc9c6fbbf4925f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64a31e5c387412596497eb1b60fec57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7591344a75de4c96b4f8186087337d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06aad979b784b188823b8584cbe28c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16089e833fcf4253a422569e372d2406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e67b900c418a4580a7bcacbf1ef0ff69",
              "IPY_MODEL_f397977ae3e34508a127eb269f16dee4",
              "IPY_MODEL_9e34df589a364b419a76368a51e7ebfa"
            ],
            "layout": "IPY_MODEL_dcb0d0b121ee4c528595a09378c5c5f9"
          }
        },
        "e67b900c418a4580a7bcacbf1ef0ff69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc20ae9fa2da4306b540ef2a3f1f1dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_d6a20e0b230345f4a6d4685e166f9e7f",
            "value": "Map: 100%"
          }
        },
        "f397977ae3e34508a127eb269f16dee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11438e55d65848218cb230cde0917cd0",
            "max": 19200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27f44c13afe448498cd646b6b33149b0",
            "value": 19200
          }
        },
        "9e34df589a364b419a76368a51e7ebfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb37db4a489462d8a83250e819bad59",
            "placeholder": "​",
            "style": "IPY_MODEL_cfbd38315b52409e957d88a630c14242",
            "value": " 19200/19200 [00:13&lt;00:00, 1490.98 examples/s]"
          }
        },
        "dcb0d0b121ee4c528595a09378c5c5f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc20ae9fa2da4306b540ef2a3f1f1dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a20e0b230345f4a6d4685e166f9e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11438e55d65848218cb230cde0917cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27f44c13afe448498cd646b6b33149b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bb37db4a489462d8a83250e819bad59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfbd38315b52409e957d88a630c14242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f35540d4e3094f29b48fc50b2bf897ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54ae25edef9e43d4ab00330683114359",
              "IPY_MODEL_54d04337e8e046039d8cec2bef6e769b",
              "IPY_MODEL_adae9a2d04194606aedf4520dc52ed93"
            ],
            "layout": "IPY_MODEL_f3061075ebf2423dab6d9891fe293932"
          }
        },
        "54ae25edef9e43d4ab00330683114359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd1ebaef4c24afc8085d486dd67471d",
            "placeholder": "​",
            "style": "IPY_MODEL_2a7352ed42dc40d8b7a7133680e09800",
            "value": "model.safetensors: 100%"
          }
        },
        "54d04337e8e046039d8cec2bef6e769b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74310decae7432aaf37be7dd22fcd20",
            "max": 597241956,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78ef9c1196ae4b868b1b7b3734298577",
            "value": 597241956
          }
        },
        "adae9a2d04194606aedf4520dc52ed93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f20168d05f9455fbb3964ad47e8d964",
            "placeholder": "​",
            "style": "IPY_MODEL_a8b0d50c99df43e18f52563be2843f0d",
            "value": " 597M/597M [00:15&lt;00:00, 51.8MB/s]"
          }
        },
        "f3061075ebf2423dab6d9891fe293932": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dd1ebaef4c24afc8085d486dd67471d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a7352ed42dc40d8b7a7133680e09800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a74310decae7432aaf37be7dd22fcd20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78ef9c1196ae4b868b1b7b3734298577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f20168d05f9455fbb3964ad47e8d964": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b0d50c99df43e18f52563be2843f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d2fd9073e6d493e8d4a550750a528f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01c1cd3e6ff74c3a85767c3fec4663e4",
              "IPY_MODEL_7086e6c8501e490e9c812385dd6a91b7",
              "IPY_MODEL_469668f917b54feeb6edcd9ab67963a1"
            ],
            "layout": "IPY_MODEL_8f06f49fbe4e4f8ca7a1c91fcf30dc6b"
          }
        },
        "01c1cd3e6ff74c3a85767c3fec4663e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e70c2bf7f38043f8813478a86329f63e",
            "placeholder": "​",
            "style": "IPY_MODEL_a6382359c74640b5af593dc696523869",
            "value": "Map: 100%"
          }
        },
        "7086e6c8501e490e9c812385dd6a91b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df64eaa67164e4189397ce4219e5086",
            "max": 2400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6c3a4d72cb54f87a93bdb8d430e1749",
            "value": 2400
          }
        },
        "469668f917b54feeb6edcd9ab67963a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3265c8c56c7d4685aaf944f1749252d1",
            "placeholder": "​",
            "style": "IPY_MODEL_2acf7229cdc4490b943805e41b526fc2",
            "value": " 2400/2400 [00:01&lt;00:00, 1459.51 examples/s]"
          }
        },
        "8f06f49fbe4e4f8ca7a1c91fcf30dc6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70c2bf7f38043f8813478a86329f63e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6382359c74640b5af593dc696523869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8df64eaa67164e4189397ce4219e5086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c3a4d72cb54f87a93bdb8d430e1749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3265c8c56c7d4685aaf944f1749252d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acf7229cdc4490b943805e41b526fc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f577da670e479cb6a86c3b675091cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b406f53e8054eb084fde89625f28037",
              "IPY_MODEL_95f73633c2dd47dfbaa6758490881324",
              "IPY_MODEL_f833b6f83d6346419c684c619bc1bd70"
            ],
            "layout": "IPY_MODEL_61b05a0b134248ae857b9e6b6fdc8a7b"
          }
        },
        "4b406f53e8054eb084fde89625f28037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b091e894de3a4d3a970953763197762d",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c076334ba04d14b3a0d350f1773ea8",
            "value": "Map: 100%"
          }
        },
        "95f73633c2dd47dfbaa6758490881324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2874efadf4cb468596702b614b1977d5",
            "max": 2400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d1e6c6cc68f4ff096197c1ecdd5c6b6",
            "value": 2400
          }
        },
        "f833b6f83d6346419c684c619bc1bd70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a913e6da8224217954eb2b10184c4cd",
            "placeholder": "​",
            "style": "IPY_MODEL_834266902966416081293692fe62137e",
            "value": " 2400/2400 [00:01&lt;00:00, 1481.01 examples/s]"
          }
        },
        "61b05a0b134248ae857b9e6b6fdc8a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b091e894de3a4d3a970953763197762d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c076334ba04d14b3a0d350f1773ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2874efadf4cb468596702b614b1977d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1e6c6cc68f4ff096197c1ecdd5c6b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a913e6da8224217954eb2b10184c4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "834266902966416081293692fe62137e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}