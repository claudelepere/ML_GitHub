{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOxkO57qs134knl+jHcrkVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudelepere/ML_GitHub/blob/main/Longformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install accelerate\n",
        "!pip -q install transformers datasets\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "9CzPfqC8FxdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK3M39N6E8mQ"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict, Dataset, Features, Sequence, Value\n",
        "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "# Step 1: Prepare DatasetDict with train, validation, and test splits\n",
        "data = {\n",
        "    \"train\": {\n",
        "        \"text\": [\"This is a training example.\", \"Another training sample here.\"],\n",
        "        \"labels\": [[1, 0, 0], [0, 1, 1]],  # Multi-label (3 classes in this example)\n",
        "    },\n",
        "    \"validation\": {\n",
        "        \"text\": [\"This is a validation example.\", \"Another validation sample.\"],\n",
        "        \"labels\": [[1, 0, 1], [0, 1, 0]],\n",
        "    },\n",
        "    \"test\": {\n",
        "        \"text\": [\"This is a test example.\", \"Another test sample.\"],\n",
        "        \"labels\": [[1, 0, 0], [0, 1, 1]],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Convert to DatasetDict\n",
        "dataset = DatasetDict({\n",
        "    split: Dataset.from_dict(data_split, features=Features({\n",
        "        'text': Value(dtype='string'),  # Keep the 'text' column\n",
        "        'labels': Sequence(feature=Value(dtype='float32'))\n",
        "    }))\n",
        "    for split, data_split in data.items()\n",
        "})\n",
        "\n",
        "# Step 2: Load Longformer tokenizer\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "\n",
        "# Tokenize datasets\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        max_length=1024, #2048, # 4096,  # Adjust max length for Longformer\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        #return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "def preprocess_labels(examples):\n",
        "    \"\"\"\n",
        "    print(f\"examples['labels']: {len(examples['labels'])} {examples['labels']}\")\n",
        "    print(f\"examples['labels'][0]: {len(examples['labels'][0])} {examples['labels'][0]}\")\n",
        "    # Ensure labels are flattened and converted to float\n",
        "    if isinstance(examples[\"labels\"][0], list):  # Nested lists\n",
        "        print(\"Nested list\")\n",
        "        flattened = [float(label) for sublist in examples[\"labels\"] for label in sublist]\n",
        "    else:  # Single list\n",
        "        print(\"Single list\")\n",
        "        flattened = [float(label) for label in examples[\"labels\"]]\n",
        "\n",
        "    # Validate the length of labels\n",
        "    #expected_length = 2  # Replace with the correct number of labels for your task\n",
        "    #if len(flattened) != expected_length:\n",
        "    #    raise ValueError(f\"Labels length mismatch: Expected {expected_length}, got {len(flattened)}\")\n",
        "\n",
        "    examples[\"labels\"] = flattened\n",
        "    print(f\"examples['labels']: {len(examples['labels'])} {examples['labels']}\")\n",
        "    return examples\n",
        "    \"\"\"\n",
        "    # Convert each label list to a list of floats\n",
        "    examples[\"labels\"] = [[float(label_item) for label_item in label_list] for label_list in examples[\"labels\"]]\n",
        "    return examples\n",
        "\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "print(f\"encoded_dataset['train'][0]: {encoded_dataset['train'][0]}\")  # Inspect a sample\n",
        "encoded_dataset = encoded_dataset.map(preprocess_labels, batched=True)\n",
        "print(f\"encoded_dataset['train'][0]: {encoded_dataset['train'][0]}\")  # Inspect a sample\n",
        "\n",
        "\n",
        "# Step 3: Load Longformer model for sequence classification\n",
        "model = LongformerForSequenceClassification.from_pretrained(\n",
        "    \"allenai/longformer-base-4096\",\n",
        "    num_labels=3,  # Number of labels in your multi-label problem\n",
        "    problem_type=\"multi_label_classification\",\n",
        ")\n",
        "\n",
        "\n",
        "# Step 4: Define Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = (logits > 0).astype(int)  # Convert logits to binary predictions\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"macro\")\n",
        "    roc_auc = roc_auc_score(labels, logits, average=\"macro\", multi_class=\"ovr\")\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"roc_auc\": roc_auc}\n",
        "\n",
        "# Step 5: Set up Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=1,  # Reduce batch size\n",
        "    per_device_eval_batch_size=1,  # Reduce batch size\n",
        "    gradient_accumulation_steps=4,  # Simulate larger batch size\n",
        "    fp16=True,  # Enable mixed precision\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Step 6: Train the Model\n",
        "trainer.train()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the Model\n",
        "results = trainer.evaluate(encoded_dataset[\"test\"])\n",
        "print(\"Test Results:\", results)"
      ],
      "metadata": {
        "id": "WDeMcRb4JHyn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}